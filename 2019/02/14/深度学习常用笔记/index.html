<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"cocofhu.com","root":"/","images":"/images","scheme":"Mist","darkmode":"ture","version":"8.18.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="由于误操作导致丢失的文章，还好markdown有备份。 一、优化手段和常用算法1、使用阿里云镜像加速1-i http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple --trusted-host mirrors.aliyun.com  2、手写数字识别中初始化参数的问题参看例子2-13，最开始我使用了标准的正态分布，收敛速度很慢。 123456w1 &#x3D; tf.Variable(t">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习常用笔记">
<meta property="og:url" content="http://cocofhu.com/2019/02/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="小鸟游六花">
<meta property="og:description" content="由于误操作导致丢失的文章，还好markdown有备份。 一、优化手段和常用算法1、使用阿里云镜像加速1-i http:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;pypi&#x2F;simple --trusted-host mirrors.aliyun.com  2、手写数字识别中初始化参数的问题参看例子2-13，最开始我使用了标准的正态分布，收敛速度很慢。 123456w1 &#x3D; tf.Variable(t">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2019-02-14T17:01:34.000Z">
<meta property="article:modified_time" content="2024-05-29T09:25:22.130Z">
<meta property="article:author" content="cocofhu">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://cocofhu.com/2019/02/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AC%94%E8%AE%B0/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"http://cocofhu.com/2019/02/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AC%94%E8%AE%B0/","path":"2019/02/14/深度学习常用笔记/","title":"深度学习常用笔记"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>深度学习常用笔记 | 小鸟游六花</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">小鸟游六花</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">vanishment this world</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%80%E3%80%81%E4%BC%98%E5%8C%96%E6%89%8B%E6%AE%B5%E5%92%8C%E5%B8%B8%E7%94%A8%E7%AE%97%E6%B3%95"><span class="nav-number">1.</span> <span class="nav-text">一、优化手段和常用算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E9%95%9C%E5%83%8F%E5%8A%A0%E9%80%9F"><span class="nav-number">1.1.</span> <span class="nav-text">1、使用阿里云镜像加速</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E4%B8%AD%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%82%E6%95%B0%E7%9A%84%E9%97%AE%E9%A2%98"><span class="nav-number">1.2.</span> <span class="nav-text">2、手写数字识别中初始化参数的问题</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E3%80%81%E8%AE%A1%E7%AE%97Top-k-Accuracy"><span class="nav-number">1.3.</span> <span class="nav-text">3、计算Top-k Accuracy</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4%E3%80%81TensorFlow%E5%9C%A8%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E6%97%B6%E7%AA%81%E7%84%B6%E5%81%87%E6%AD%BB"><span class="nav-number">1.4.</span> <span class="nav-text">4、TensorFlow在训练模型时突然假死</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5%E3%80%81TensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-number">1.5.</span> <span class="nav-text">5、TensorBoard可视化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6%E3%80%81%E4%BD%BF%E7%94%A8Relu%E5%87%BD%E6%95%B0%E6%97%B6%E5%B0%86%E8%BE%93%E5%85%A5%E6%98%A0%E5%B0%84%E5%88%B00-1%E5%8C%BA%E9%97%B4"><span class="nav-number">1.6.</span> <span class="nav-text">6、使用Relu函数时将输入映射到0-1区间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6%E3%80%81%E4%BD%BF%E7%94%A8Dropout%E9%98%B2%E6%AD%A2%E8%BF%87%E6%8B%9F%E5%90%88"><span class="nav-number">1.7.</span> <span class="nav-text">6、使用Dropout防止过拟合</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7%E3%80%81%E4%BD%BF%E7%94%A8L2%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-number">1.8.</span> <span class="nav-text">7、使用L2正则化</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8%E3%80%81Keras%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0"><span class="nav-number">1.9.</span> <span class="nav-text">8、Keras自定义损失函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9%E3%80%81%E4%BD%BF%E7%94%A8ResNet%E7%BD%91%E7%BB%9C"><span class="nav-number">1.10.</span> <span class="nav-text">9、使用ResNet网络</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10%E3%80%81%E8%AE%A1%E7%AE%97%E4%B8%A4%E4%B8%AA%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83%E7%9A%84KL-Divergence"><span class="nav-number">1.11.</span> <span class="nav-text">10、计算两个正态分布的KL-Divergence</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11%E3%80%81Transposed%E5%8D%B7%E7%A7%AF%E8%BE%93%E5%87%BA%E8%AE%A1%E7%AE%97%E5%85%AC%E5%BC%8F"><span class="nav-number">1.12.</span> <span class="nav-text">11、Transposed卷积输出计算公式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12%E3%80%81%E4%BD%BF%E7%94%A8GAN%E8%AE%AD%E7%BB%83%E6%97%B6%E7%9A%84%E6%8A%80%E5%B7%A7"><span class="nav-number">1.13.</span> <span class="nav-text">12、使用GAN训练时的技巧</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#13%E3%80%81%E5%8A%A0%E8%BD%BDKeras%E5%86%85%E7%BD%AE%E6%A8%A1%E5%9E%8B"><span class="nav-number">1.14.</span> <span class="nav-text">13、加载Keras内置模型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#14%E3%80%81%E5%8F%82%E8%80%83%E9%93%BE%E6%8E%A5"><span class="nav-number">1.15.</span> <span class="nav-text">14、参考链接</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E3%80%81TensorFlow%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C"><span class="nav-number">2.</span> <span class="nav-text">二、TensorFlow基础操作</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81Tensor%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B"><span class="nav-number">2.1.</span> <span class="nav-text">1、Tensor数据类型</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81Tensor%E7%9A%84%E5%88%9B%E5%BB%BA"><span class="nav-number">2.2.</span> <span class="nav-text">2、Tensor的创建</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E3%80%81Tensor%E7%9A%84%E7%B4%A2%E5%BC%95%E4%B8%8E%E5%88%87%E7%89%87"><span class="nav-number">2.3.</span> <span class="nav-text">3、Tensor的索引与切片</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4%E3%80%81Tensor%E7%9A%84%E9%AB%98%E7%BA%A7%E7%B4%A2%E5%BC%95%E5%92%8C%E5%88%87%E7%89%87"><span class="nav-number">2.4.</span> <span class="nav-text">4、Tensor的高级索引和切片</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5%E3%80%81Tensor%E7%9A%84%E7%BB%B4%E5%BA%A6%E5%8F%98%E6%8D%A2"><span class="nav-number">2.5.</span> <span class="nav-text">5、Tensor的维度变换</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6%E3%80%81TensorBroadcasting"><span class="nav-number">2.6.</span> <span class="nav-text">6、TensorBroadcasting</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7%E3%80%81Tensor%E7%9A%84%E5%90%88%E5%B9%B6%E4%B8%8E%E5%88%86%E5%89%B2"><span class="nav-number">2.7.</span> <span class="nav-text">7、Tensor的合并与分割</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8%E3%80%81Tensor%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1"><span class="nav-number">2.8.</span> <span class="nav-text">8、Tensor的数据统计</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#9%E3%80%81Tensor%E6%8E%92%E5%BA%8F"><span class="nav-number">2.9.</span> <span class="nav-text">9、Tensor排序</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#10%E3%80%81Tensor%E5%A1%AB%E5%85%85%E4%B8%8E%E5%A4%8D%E5%88%B6"><span class="nav-number">2.10.</span> <span class="nav-text">10、Tensor填充与复制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11%E3%80%81Tensor%E9%99%90%E5%B9%85"><span class="nav-number">2.11.</span> <span class="nav-text">11、Tensor限幅</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12%E3%80%81GradientDescending%E6%B1%82%E5%87%BD%E6%95%B0%E6%9E%81%E5%80%BC"><span class="nav-number">2.12.</span> <span class="nav-text">12、GradientDescending求函数极值</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#13%E3%80%81Mnist%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB"><span class="nav-number">2.13.</span> <span class="nav-text">13、Mnist手写数字识别</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#14%E3%80%81TensorBoard%E5%8F%AF%E8%A7%86%E5%8C%96"><span class="nav-number">2.14.</span> <span class="nav-text">14、TensorBoard可视化</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E3%80%81Keras%E9%AB%98%E5%B1%82API"><span class="nav-number">3.</span> <span class="nav-text">三、Keras高层API</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81Keras%E5%B8%B8%E7%94%A8API"><span class="nav-number">3.1.</span> <span class="nav-text">1、Keras常用API</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81KerasMetrics%E8%AE%A1%E7%AE%97%E5%9D%87%E5%80%BC%E5%92%8C%E5%87%86%E7%A1%AE%E5%BA%A6"><span class="nav-number">3.2.</span> <span class="nav-text">2、KerasMetrics计算均值和准确度</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E3%80%81%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%B1%82"><span class="nav-number">3.3.</span> <span class="nav-text">3、自定义模型和层</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4%E3%80%81CIFAR10%E5%88%86%E7%B1%BB"><span class="nav-number">3.4.</span> <span class="nav-text">4、CIFAR10分类</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9B%9B%E3%80%81%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">4.</span> <span class="nav-text">四、卷积神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81%E8%87%AA%E5%AE%9A%E4%B9%89VGG13%E7%BD%91%E7%BB%9CCIFAR100%E5%88%86%E7%B1%BB"><span class="nav-number">4.1.</span> <span class="nav-text">1、自定义VGG13网络CIFAR100分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81%E4%BD%BF%E7%94%A8ResNet%E7%BD%91%E7%BB%9C%E5%AF%B9CIFAR100%E5%88%86%E7%B1%BB"><span class="nav-number">4.2.</span> <span class="nav-text">2、使用ResNet网络对CIFAR100分类</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%94%E3%80%81%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">5.</span> <span class="nav-text">五、循环神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AF%B9IMDB%E8%AF%84%E8%AE%BA%E8%BF%9B%E8%A1%8C%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB"><span class="nav-number">5.1.</span> <span class="nav-text">1、循环神经网络对IMDB评论进行情感分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81%E4%BD%BF%E7%94%A8Keras%E5%86%85%E7%BD%AE%E7%9A%84RNN%E8%BF%9B%E8%A1%8CIMDB%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB"><span class="nav-number">5.2.</span> <span class="nav-text">2、使用Keras内置的RNN进行IMDB情感分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3%E3%80%81%E4%BD%BF%E7%94%A8LSTM%E5%AF%B9IMDB%E8%AF%84%E8%AE%BA%E8%BF%9B%E8%A1%8C%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB"><span class="nav-number">5.3.</span> <span class="nav-text">3、使用LSTM对IMDB评论进行情感分类</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4%E3%80%81%E4%BD%BF%E7%94%A8Keras%E5%86%85%E7%BD%AELSTM%E8%BF%9B%E8%A1%8CIMDB%E6%83%85%E6%84%9F%E5%88%86%E7%B1%BB"><span class="nav-number">5.4.</span> <span class="nav-text">4、使用Keras内置LSTM进行IMDB情感分类</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%AD%E3%80%81%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0"><span class="nav-number">6.</span> <span class="nav-text">六、迁移学习</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81%E4%BD%BF%E7%94%A8VGG19%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0CIFAR100"><span class="nav-number">6.1.</span> <span class="nav-text">1、使用VGG19迁移学习CIFAR100</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%83%E3%80%81%E8%87%AA%E7%BC%96%E7%A0%81%E5%99%A8"><span class="nav-number">7.</span> <span class="nav-text">七、自编码器</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81%E5%AF%B9MNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E8%BF%9B%E8%A1%8C%E8%87%AA%E7%BC%96%E7%A0%81"><span class="nav-number">7.1.</span> <span class="nav-text">1、对MNIST数据集进行自编码</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2%E3%80%81VariationalAutoEncoder"><span class="nav-number">7.2.</span> <span class="nav-text">2、VariationalAutoEncoder</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%AB%E3%80%81%E5%AF%B9%E6%8A%97%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="nav-number">8.</span> <span class="nav-text">八、对抗神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1%E3%80%81GAN"><span class="nav-number">8.1.</span> <span class="nav-text">1、GAN</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4%E3%80%81WGAN"><span class="nav-number">8.2.</span> <span class="nav-text">4、WGAN</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">cocofhu</p>
  <div class="site-description" itemprop="description">邪王真眼是最强的</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">12</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/cocofhu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;cocofhu" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:cocofhu@outlook.com" title="E-Mail → mailto:cocofhu@outlook.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://cocofhu.com/2019/02/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="cocofhu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小鸟游六花">
      <meta itemprop="description" content="邪王真眼是最强的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="深度学习常用笔记 | 小鸟游六花">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          深度学习常用笔记
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-02-14 17:01:34" itemprop="dateCreated datePublished" datetime="2019-02-14T17:01:34+00:00">2019-02-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-29 09:25:22" itemprop="dateModified" datetime="2024-05-29T09:25:22+00:00">2024-05-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><em>由于误操作导致丢失的文章，还好markdown有备份。</em></p>
<h3 id="一、优化手段和常用算法"><a href="#一、优化手段和常用算法" class="headerlink" title="一、优化手段和常用算法"></a>一、优化手段和常用算法</h3><h4 id="1、使用阿里云镜像加速"><a href="#1、使用阿里云镜像加速" class="headerlink" title="1、使用阿里云镜像加速"></a>1、使用阿里云镜像加速</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-i http://mirrors.aliyun.com/pypi/simple --trusted-host mirrors.aliyun.com</span><br></pre></td></tr></table></figure>

<h4 id="2、手写数字识别中初始化参数的问题"><a href="#2、手写数字识别中初始化参数的问题" class="headerlink" title="2、手写数字识别中初始化参数的问题"></a>2、手写数字识别中初始化参数的问题</h4><p>参看例子<code>2-13</code>，最开始我使用了标准的正态分布，收敛速度很慢。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>, <span class="number">256</span>], stddev=<span class="number">1</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">256</span>]))</span><br><span class="line">w2 = tf.Variable(tf.random.truncated_normal([<span class="number">256</span>, <span class="number">128</span>], stddev=<span class="number">1</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">128</span>]))</span><br><span class="line">w3 = tf.Variable(tf.random.truncated_normal([<span class="number">128</span>, <span class="number">10</span>], stddev=<span class="number">1</span>))</span><br><span class="line">b3 = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br></pre></td></tr></table></figure>

<p>将正态分布的方差降为<code>0.1</code>时，收敛速度非常快</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>, <span class="number">256</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">256</span>]))</span><br><span class="line">w2 = tf.Variable(tf.random.truncated_normal([<span class="number">256</span>, <span class="number">128</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">128</span>]))</span><br><span class="line">w3 = tf.Variable(tf.random.truncated_normal([<span class="number">128</span>, <span class="number">10</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b3 = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br></pre></td></tr></table></figure>

<p>可见，参数的初始化对神经网络的性能有着重要影响。</p>
<h4 id="3、计算Top-k-Accuracy"><a href="#3、计算Top-k-Accuracy" class="headerlink" title="3、计算Top-k Accuracy"></a>3、计算Top-k Accuracy</h4><p>具体例子在<code>2-9</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Top-k accuracy</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">output, target, topk=(<span class="params"><span class="number">1</span>,</span>)</span>):</span><br><span class="line">    maxk = <span class="built_in">max</span>(topk)</span><br><span class="line">    batch_size = target.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    pred = tf.math.top_k(output, maxk).indices</span><br><span class="line">    pred = tf.transpose(pred, perm=[<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">    target_ = tf.broadcast_to(target, pred.shape)</span><br><span class="line">    <span class="comment"># [10, b]</span></span><br><span class="line">    correct = tf.equal(pred, target_)</span><br><span class="line"></span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> topk:</span><br><span class="line">        correct_k = tf.cast(tf.reshape(correct[:k], [-<span class="number">1</span>]), dtype=tf.float32)</span><br><span class="line">        correct_k = tf.reduce_sum(correct_k)</span><br><span class="line">        acc = <span class="built_in">float</span>(correct_k* (<span class="number">100.0</span> / batch_size) )</span><br><span class="line">        res.append(acc)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>

<h4 id="4、TensorFlow在训练模型时突然假死"><a href="#4、TensorFlow在训练模型时突然假死" class="headerlink" title="4、TensorFlow在训练模型时突然假死"></a>4、TensorFlow在训练模型时突然假死</h4><p>经过测试，这种问题一般是显存不够，更改<code>batchsize</code>一般可以解决该问题。或者更新驱动程序。</p>
<h4 id="5、TensorBoard可视化"><a href="#5、TensorBoard可视化" class="headerlink" title="5、TensorBoard可视化"></a>5、TensorBoard可视化</h4><p>具体例子在<code>2-14</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">current_time = datetime.datetime.now().strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>)</span><br><span class="line">log_dir = <span class="string">&#x27;../logs/&#x27;</span> + current_time</span><br><span class="line">summary_writer = tf.summary.create_file_writer(log_dir)</span><br><span class="line"><span class="comment"># 可视化数据保存</span></span><br><span class="line"><span class="keyword">with</span> summary_writer.as_default():</span><br><span class="line">	tf.summary.scalar(<span class="string">&#x27;train-loss&#x27;</span>, <span class="built_in">float</span>(loss), step=step)</span><br></pre></td></tr></table></figure>

<h4 id="6、使用Relu函数时将输入映射到0-1区间"><a href="#6、使用Relu函数时将输入映射到0-1区间" class="headerlink" title="6、使用Relu函数时将输入映射到0-1区间"></a>6、使用Relu函数时将输入映射到0-1区间</h4><p>在做<code>CIFAR10</code>分类时，若采用如下的数据预处理，将导致收敛速度过慢，或者不收敛</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) </span><br><span class="line">    x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">32</span>*<span class="number">32</span>*<span class="number">3</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br></pre></td></tr></table></figure>

<p>将输入数据集映射到<code>0-1</code>区间是，模型性能较好</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = <span class="number">2</span> * tf.cast(x, dtype=tf.float32) / <span class="number">255</span> - <span class="number">1</span></span><br><span class="line">    x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">32</span>*<span class="number">32</span>*<span class="number">3</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br></pre></td></tr></table></figure>

<p>具体例子参见<code>3-4</code>.</p>
<h4 id="6、使用Dropout防止过拟合"><a href="#6、使用Dropout防止过拟合" class="headerlink" title="6、使用Dropout防止过拟合"></a>6、使用Dropout防止过拟合</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">layers.Dense(<span class="number">256</span>, activation=tf.nn.relu),</span><br><span class="line">layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">layers.Dense(<span class="number">128</span>, activation=tf.nn.relu),</span><br><span class="line">layers.Dropout(<span class="number">0.5</span>),</span><br></pre></td></tr></table></figure>

<h4 id="7、使用L2正则化"><a href="#7、使用L2正则化" class="headerlink" title="7、使用L2正则化"></a>7、使用L2正则化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">layers.Dense(<span class="number">256</span>, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(<span class="number">0.001</span>))</span><br></pre></td></tr></table></figure>

<h4 id="8、Keras自定义损失函数"><a href="#8、Keras自定义损失函数" class="headerlink" title="8、Keras自定义损失函数"></a>8、Keras自定义损失函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 继承Loss类 重写call方法</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DistanceLoss</span>(<span class="title class_ inherited__">Loss</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, y_true, y_pred</span>):</span><br><span class="line">        loss = tf.losses.categorical_crossentropy(y_true, y_pred, from_logits=<span class="literal">True</span>)</span><br><span class="line">        loss = tf.reduce_mean(loss)</span><br><span class="line">        loss = loss + (<span class="number">0.3</span>*loss - <span class="number">0.3</span>)**<span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.0001</span>),</span><br><span class="line">                  loss=DistanceLoss(),</span><br><span class="line">                  metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure>

<p>具体例子参见<code>4-1</code>,一开始发现<code>loss</code>到<code>1</code>的时候就会发生过拟合，所以想限制一下<code>loss</code>,结果并没有什么用。</p>
<h4 id="9、使用ResNet网络"><a href="#9、使用ResNet网络" class="headerlink" title="9、使用ResNet网络"></a>9、使用ResNet网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, listOfLayer, shortcuts=<span class="literal">None</span>, activation=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">        self.model = Sequential(listOfLayer)</span><br><span class="line">        self.activation = activation</span><br><span class="line">        <span class="keyword">if</span> shortcuts <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.shortcut = <span class="keyword">lambda</span> x: x</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.shortcut = Sequential(shortcuts)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, **kwargs</span>):</span><br><span class="line">        residual = self.shortcut(inputs)</span><br><span class="line">        out = self.model(inputs)</span><br><span class="line">        <span class="keyword">if</span> self.activation <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> layers.add([residual, out])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.activation(residual + out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resNet</span>(<span class="params">filter_num, strides</span>):</span><br><span class="line">    <span class="keyword">if</span> strides == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> ResNet(listOfLayer=[</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        ], activation=tf.nn.relu)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> ResNet(listOfLayer=[</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=strides, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        ], shortcuts=[</span><br><span class="line"></span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">1</span>, <span class="number">1</span>), strides=strides, padding=<span class="string">&quot;same&quot;</span>, kernel_regularizer=regularizers.l2(<span class="number">5e-5</span>),</span><br><span class="line">                          use_bias=<span class="literal">False</span>, kernel_initializer=<span class="string">&#x27;glorot_normal&#x27;</span>)</span><br><span class="line">        ], activation=tf.nn.relu)</span><br></pre></td></tr></table></figure>

<p>具体例子参见<code>4-2</code>.</p>
<h4 id="10、计算两个正态分布的KL-Divergence"><a href="#10、计算两个正态分布的KL-Divergence" class="headerlink" title="10、计算两个正态分布的KL-Divergence"></a>10、计算两个正态分布的KL-Divergence</h4><p>$$<br>\begin{alignedat}{1}<br>    KL(p,q) &amp;&#x3D; -\int p(x)logq(x)dx + \int p(x)logp(x)dx \<br>    &amp;&#x3D; \frac{1}{2}log(2\pi\sigma_{2}^2) + \frac{\sigma_{1}^2+(\mu_{1}-\mu_{2})^2}{2\sigma_2^2} - \frac{1}{2}(1+log2\pi\sigma_1^2) \<br>    &amp;&#x3D; log\frac{\sigma_2}{\sigma_1} + \frac{\sigma_{1}^2+(\mu_{1}-\mu_{2})^2}{2\sigma_2^2} - \frac{1}{2}<br>\end{alignedat}<br>$$</p>
<p>参考链接：<a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians">https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians</a></p>
<h4 id="11、Transposed卷积输出计算公式"><a href="#11、Transposed卷积输出计算公式" class="headerlink" title="11、Transposed卷积输出计算公式"></a>11、Transposed卷积输出计算公式</h4><p>$$<br>out &#x3D; s(i - 1) + k - 2p<br>$$</p>
<p>参考文章：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.07285v1.pdf">https://arxiv.org/pdf/1603.07285v1.pdf</a></p>
<h4 id="12、使用GAN训练时的技巧"><a href="#12、使用GAN训练时的技巧" class="headerlink" title="12、使用GAN训练时的技巧"></a>12、使用GAN训练时的技巧</h4><ul>
<li>使用<code>leak_relu</code></li>
<li>使用<code>tanh</code>作为激活函数</li>
<li>使用<code>WGAN</code>增强参数鲁棒性</li>
</ul>
<h4 id="13、加载Keras内置模型"><a href="#13、加载Keras内置模型" class="headerlink" title="13、加载Keras内置模型"></a>13、加载Keras内置模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载Keras已有网络</span></span><br><span class="line">vgg19 = keras.applications.VGG19(weights=<span class="string">&quot;imagenet&quot;</span>, include_top=<span class="literal">False</span>, pooling=<span class="string">&quot;max&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>具体例子参看<code>6-1</code></p>
<h4 id="14、参考链接"><a href="#14、参考链接" class="headerlink" title="14、参考链接"></a>14、参考链接</h4><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.07285v1.pdf" title="A guide to convolution arithmetic for deep learning">A guide to convolution arithmetic for deep learning</a></li>
<li><a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians" title="KL divergence between two univariate Gaussians">KL divergence between two univariate Gaussians</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1606.05908.pdf" title="Tutorial on Variational Autoencoders">Tutorial on Variational Autoencoders</a></li>
</ul>
<h3 id="二、TensorFlow基础操作"><a href="#二、TensorFlow基础操作" class="headerlink" title="二、TensorFlow基础操作"></a>二、TensorFlow基础操作</h3><h4 id="1、Tensor数据类型"><a href="#1、Tensor数据类型" class="headerlink" title="1、Tensor数据类型"></a>1、Tensor数据类型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入TensorFlow版本号</span></span><br><span class="line"><span class="built_in">print</span>(tf.version.VERSION)</span><br><span class="line"><span class="comment"># 创建Tensor int32</span></span><br><span class="line"><span class="built_in">print</span>(tf.constant(<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 创建Tensor float32</span></span><br><span class="line"><span class="built_in">print</span>(tf.constant(<span class="number">1.1</span>))</span><br><span class="line"><span class="comment"># 指定类型创建Tensor float64</span></span><br><span class="line"><span class="built_in">print</span>(tf.constant(<span class="number">2.2</span>, dtype=tf.float64))</span><br><span class="line"><span class="comment"># 创建Tensor bool</span></span><br><span class="line"><span class="built_in">print</span>(tf.constant([<span class="literal">True</span>, <span class="literal">False</span>]))</span><br><span class="line"><span class="comment"># 创建Tensor string 不推荐使用string类型的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.constant(<span class="string">&#x27;hello&#x27;</span>))</span><br><span class="line"></span><br><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 声明Tensor对象为变量</span></span><br><span class="line">b = tf.Variable(a)</span><br><span class="line">c = tf.Variable(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 是否监听梯度变化</span></span><br><span class="line"><span class="built_in">print</span>(b.trainable)</span><br><span class="line"><span class="built_in">print</span>(c.trainable)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2、Tensor的创建"><a href="#2、Tensor的创建" class="headerlink" title="2、Tensor的创建"></a>2、Tensor的创建</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从numpy创建Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.convert_to_tensor(np.ones([<span class="number">2</span>, <span class="number">3</span>])))</span><br><span class="line"><span class="built_in">print</span>(tf.convert_to_tensor(np.ones([<span class="number">2</span>, <span class="number">3</span>]), dtype=tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从List创建Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.constant([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line"><span class="built_in">print</span>(tf.convert_to_tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line"><span class="built_in">print</span>(tf.convert_to_tensor([[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建标量为0的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.zeros([]))</span><br><span class="line"><span class="comment"># 创建shape为1的标量为0的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.zeros([<span class="number">1</span>]))</span><br><span class="line"><span class="comment"># 创建2行2列的全0的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.zeros([<span class="number">2</span>, <span class="number">2</span>]))</span><br><span class="line">a = tf.zeros([<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">b = np.zeros([<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># 创建shape相同的全0的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.zeros_like(a))</span><br><span class="line"><span class="built_in">print</span>(tf.zeros_like(b))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建全1的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.ones([<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line"><span class="built_in">print</span>(tf.ones_like(a))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建全是指定值的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.fill([<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>], <span class="number">6</span>))</span><br><span class="line"><span class="built_in">print</span>(tf.fill(a.shape, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机初始化Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.random.normal([<span class="number">2</span>, <span class="number">2</span>], mean=<span class="number">0</span>, stddev=<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 截断正态分布 避免梯度消失</span></span><br><span class="line"><span class="comment"># 取值范围为 [ mean - 2 * stddev, mean + 2 * stddev ]</span></span><br><span class="line"><span class="built_in">print</span>(tf.random.truncated_normal([<span class="number">2</span>, <span class="number">2</span>], mean=<span class="number">0</span>, stddev=<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(tf.random.uniform([<span class="number">2</span>, <span class="number">2</span>], maxval=<span class="number">10</span>, minval=<span class="number">0</span>, dtype=tf.int32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机打散</span></span><br><span class="line">idx = tf.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">idx = tf.random.shuffle(idx)</span><br><span class="line"><span class="built_in">print</span>(idx)</span><br><span class="line">a = tf.random.normal([<span class="number">10</span>, <span class="number">784</span>])</span><br><span class="line">b = tf.random.uniform([<span class="number">10</span>], maxval=<span class="number">10</span>, minval=<span class="number">0</span>, dtype=tf.int32)</span><br><span class="line"><span class="comment"># 这里a和b满足原来的对应关系</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather(a, idx))</span><br><span class="line"><span class="built_in">print</span>(tf.gather(b, idx))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="3、Tensor的索引与切片"><a href="#3、Tensor的索引与切片" class="headerlink" title="3、Tensor的索引与切片"></a>3、Tensor的索引与切片</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 基本索引</span></span><br><span class="line">a = tf.ones([<span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>][<span class="number">0</span>][<span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>][<span class="number">0</span>][<span class="number">2</span>][<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Numpy风格索引</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># start:end 索引和切片</span></span><br><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 切片操作返回向量,索引操作返回数值</span></span><br><span class="line"><span class="built_in">print</span>(a[-<span class="number">1</span>])</span><br><span class="line"><span class="comment"># 取全部数据</span></span><br><span class="line"><span class="built_in">print</span>(a[:])</span><br><span class="line"><span class="comment"># 从倒数第一个元素开始切片[9]</span></span><br><span class="line"><span class="built_in">print</span>(a[-<span class="number">1</span>:])</span><br><span class="line"><span class="comment"># 从倒数第二个元素开始切片[8, 9]</span></span><br><span class="line"><span class="built_in">print</span>(a[-<span class="number">2</span>:])</span><br><span class="line"><span class="comment"># 一直取到最后一个元素,左闭右开区间</span></span><br><span class="line"><span class="built_in">print</span>(a[:-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># start:end:step 索引和切片</span></span><br><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 每隔两个取[0 2 4 6 8]</span></span><br><span class="line"><span class="built_in">print</span>(a[::<span class="number">2</span>])</span><br><span class="line"><span class="comment"># 倒序每隔两个取[9 7 5 3 1]</span></span><br><span class="line"><span class="built_in">print</span>(a[::-<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用...自动推导</span></span><br><span class="line">a = tf.ones([<span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, :, :, :])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, ...])</span><br><span class="line"><span class="built_in">print</span>(a[..., <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4、Tensor的高级索引和切片"><a href="#4、Tensor的高级索引和切片" class="headerlink" title="4、Tensor的高级索引和切片"></a>4、Tensor的高级索引和切片</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = tf.random.normal([<span class="number">8</span>, <span class="number">35</span>, <span class="number">8</span>])</span><br><span class="line"><span class="comment"># 取第1维度2、3索引</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather(a, axis=<span class="number">0</span>, indices=[<span class="number">2</span>, <span class="number">3</span>]).shape)</span><br><span class="line"><span class="comment"># 取第1维度1、4、5索引</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather(a, axis=<span class="number">0</span>, indices=[<span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>]).shape)</span><br><span class="line"><span class="comment"># 取第2维度1和32索引</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather(a, axis=<span class="number">1</span>, indices=[<span class="number">1</span>, <span class="number">32</span>]).shape)</span><br><span class="line"><span class="comment"># a[0]</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather_nd(a, [<span class="number">0</span>]).shape)</span><br><span class="line"><span class="comment"># a[0,1,2]</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather_nd(a, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]).shape)</span><br><span class="line"><span class="comment"># [a[1], a[2], a[5])]</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather_nd(a, [[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">5</span>]]).shape)</span><br><span class="line"><span class="comment"># [a[1, 2], a[2, 1], a[5, 3])]</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather_nd(a, [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">1</span>], [<span class="number">5</span>, <span class="number">3</span>]]).shape)</span><br><span class="line"><span class="comment"># a[0]</span></span><br><span class="line"><span class="built_in">print</span>(tf.boolean_mask(a, mask=[<span class="literal">True</span>, <span class="literal">False</span>]))</span><br><span class="line"><span class="comment"># a[:,:,0]</span></span><br><span class="line"><span class="built_in">print</span>(tf.boolean_mask(a, mask=[<span class="literal">True</span>, <span class="literal">False</span>], axis=<span class="number">3</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="5、Tensor的维度变换"><a href="#5、Tensor的维度变换" class="headerlink" title="5、Tensor的维度变换"></a>5、Tensor的维度变换</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = tf.random.normal([<span class="number">100</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># 改变维度, -1代表自动计算</span></span><br><span class="line"><span class="built_in">print</span>(tf.reshape(a, [<span class="number">100</span>, -<span class="number">1</span>, <span class="number">3</span>]).shape)</span><br><span class="line"></span><br><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">16</span>)</span><br><span class="line">a = tf.reshape(a, [<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line"><span class="comment"># 第0维度放原来的1维度,1维度放原来的0维度</span></span><br><span class="line">a = tf.transpose(a, perm=[<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Expand dim</span></span><br><span class="line">a = tf.random.normal([<span class="number">2</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(tf.expand_dims(a, axis=<span class="number">0</span>).shape)</span><br><span class="line"><span class="built_in">print</span>(tf.expand_dims(a, axis=-<span class="number">1</span>).shape)</span><br><span class="line"><span class="built_in">print</span>(tf.expand_dims(a, axis=-<span class="number">2</span>).shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Squeeze dim</span></span><br><span class="line">a = tf.random.normal([<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(tf.squeeze(a).shape)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="6、TensorBroadcasting"><a href="#6、TensorBroadcasting" class="headerlink" title="6、TensorBroadcasting"></a>6、TensorBroadcasting</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Broadcasting</span></span><br><span class="line">a = tf.ones([<span class="number">4</span>, <span class="number">1</span>])</span><br><span class="line">b = tf.ones([<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(a+b)</span><br><span class="line"><span class="comment"># 不会占用存储空间 运行时计算</span></span><br><span class="line"><span class="built_in">print</span>(tf.broadcast_to(a, [<span class="number">4</span>, <span class="number">4</span>]))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="7、Tensor的合并与分割"><a href="#7、Tensor的合并与分割" class="headerlink" title="7、Tensor的合并与分割"></a>7、Tensor的合并与分割</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并数据集合</span></span><br><span class="line">a = tf.ones([<span class="number">3</span>, <span class="number">35</span>, <span class="number">8</span>])</span><br><span class="line">b = tf.ones([<span class="number">6</span>, <span class="number">35</span>, <span class="number">8</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照第1维度合并, 不会产生新的维度 (9, 35, 8)</span></span><br><span class="line"><span class="built_in">print</span>(tf.concat([a, b], axis=<span class="number">0</span>).shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在最前面创建一个新的维度合并 (2, 6, 35, 8)</span></span><br><span class="line">a = tf.ones([<span class="number">6</span>, <span class="number">35</span>, <span class="number">8</span>])</span><br><span class="line">b = tf.ones([<span class="number">6</span>, <span class="number">35</span>, <span class="number">8</span>])</span><br><span class="line"><span class="built_in">print</span>(tf.stack([a, b], axis=<span class="number">0</span>).shape)</span><br><span class="line"><span class="comment"># 按照第一维度分开 分成6个(35, 8)</span></span><br><span class="line"><span class="built_in">print</span>(tf.unstack(a, axis=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照第一维度分开 分成(1, 35, 8)、(2, 35, 8)、(3, 35, 8)</span></span><br><span class="line"><span class="built_in">print</span>(tf.split(a, axis=<span class="number">0</span>, num_or_size_splits=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br></pre></td></tr></table></figure>

<h4 id="8、Tensor的数据统计"><a href="#8、Tensor的数据统计" class="headerlink" title="8、Tensor的数据统计"></a>8、Tensor的数据统计</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2范数, 求所有元素的均方</span></span><br><span class="line">a = tf.ones([<span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(tf.norm(a))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定维度2范数</span></span><br><span class="line"><span class="built_in">print</span>(tf.norm(a, axis=<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 指定维度1范数</span></span><br><span class="line"><span class="built_in">print</span>(tf.norm(a, axis=<span class="number">1</span>, <span class="built_in">ord</span>=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># reduce_min/max/mean argmax/argmin</span></span><br><span class="line">a = tf.random.normal([<span class="number">4</span>, <span class="number">10</span>])</span><br><span class="line"><span class="built_in">print</span>(tf.reduce_max(a, axis=<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(tf.argmax(a, axis=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># equal</span></span><br><span class="line">a = tf.constant([<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>])</span><br><span class="line">b = tf.<span class="built_in">range</span>(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(tf.equal(a, b))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算Accuracy</span></span><br><span class="line">a = tf.constant([[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.7</span>], [<span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">0.4</span>]])</span><br><span class="line"><span class="comment"># [2, 1]</span></span><br><span class="line">pred = tf.cast(tf.argmax(a, axis=<span class="number">1</span>), dtype=tf.int32)</span><br><span class="line"><span class="built_in">print</span>(pred)</span><br><span class="line">y = tf.constant([<span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line">correct = tf.equal(pred, y)</span><br><span class="line"><span class="built_in">print</span>(tf.reduce_mean(tf.cast(correct,dtype=tf.float32)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去除重复元素</span></span><br><span class="line">a = tf.constant([<span class="number">4</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>])</span><br><span class="line">ua, idx = tf.unique(a)</span><br><span class="line"><span class="built_in">print</span>(ua)</span><br><span class="line"><span class="built_in">print</span>(tf.gather(ua, axis=<span class="number">0</span>, indices=idx))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="9、Tensor排序"><a href="#9、Tensor排序" class="headerlink" title="9、Tensor排序"></a>9、Tensor排序</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">a = tf.random.shuffle(tf.<span class="built_in">range</span>(<span class="number">5</span>))</span><br><span class="line"><span class="comment"># 降序排列</span></span><br><span class="line"><span class="built_in">print</span>(tf.sort(a, direction=<span class="string">&quot;DESCENDING&quot;</span>))</span><br><span class="line"><span class="comment"># 降序排列</span></span><br><span class="line"><span class="built_in">print</span>(tf.argsort(a, direction=<span class="string">&quot;DESCENDING&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Top-k accuracy</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">output, target, topk=(<span class="params"><span class="number">1</span>,</span>)</span>):</span><br><span class="line">    maxk = <span class="built_in">max</span>(topk)</span><br><span class="line">    batch_size = target.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    pred = tf.math.top_k(output, maxk).indices</span><br><span class="line">    pred = tf.transpose(pred, perm=[<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">    target_ = tf.broadcast_to(target, pred.shape)</span><br><span class="line">    <span class="comment"># [10, b]</span></span><br><span class="line">    correct = tf.equal(pred, target_)</span><br><span class="line"></span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> topk:</span><br><span class="line">        correct_k = tf.cast(tf.reshape(correct[:k], [-<span class="number">1</span>]), dtype=tf.float32)</span><br><span class="line">        correct_k = tf.reduce_sum(correct_k)</span><br><span class="line">        acc = <span class="built_in">float</span>(correct_k* (<span class="number">100.0</span> / batch_size) )</span><br><span class="line">        res.append(acc)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="10、Tensor填充与复制"><a href="#10、Tensor填充与复制" class="headerlink" title="10、Tensor填充与复制"></a>10、Tensor填充与复制</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">9</span>)</span><br><span class="line">a = tf.reshape(a, [<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一维度前面填充1次0后面填充2次0</span></span><br><span class="line"><span class="comment"># [[0 0 0]</span></span><br><span class="line"><span class="comment">#  [0 1 2]</span></span><br><span class="line"><span class="comment">#  [3 4 5]</span></span><br><span class="line"><span class="comment">#  [6 7 8]</span></span><br><span class="line"><span class="comment">#  [0 0 0]]</span></span><br><span class="line">a = tf.pad(a, [[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="comment"># 第一维度不变 第二维度复制一次</span></span><br><span class="line"><span class="comment"># [[0 0 0 0 0 0]</span></span><br><span class="line"><span class="comment">#  [0 1 2 0 1 2]</span></span><br><span class="line"><span class="comment">#  [3 4 5 3 4 5]</span></span><br><span class="line"><span class="comment">#  [6 7 8 6 7 8]</span></span><br><span class="line"><span class="comment">#  [0 0 0 0 0 0]]</span></span><br><span class="line">a = tf.tile(a, [<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="11、Tensor限幅"><a href="#11、Tensor限幅" class="headerlink" title="11、Tensor限幅"></a>11、Tensor限幅</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">9</span>)</span><br><span class="line"><span class="comment"># 最小值限制在2 [2 2 2 3 4 5 6 7 8]</span></span><br><span class="line"><span class="built_in">print</span>(tf.maximum(a, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最大值限制在2 [0 1 2 2 2 2 2 2 2]</span></span><br><span class="line"><span class="built_in">print</span>(tf.minimum(a, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># 最小值限制在2和最大值限制在8 [2 2 2 3 4 5 6 7 8]</span></span><br><span class="line"><span class="built_in">print</span>(tf.clip_by_value(a, <span class="number">2</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line">a = tf.random.normal([<span class="number">2</span>, <span class="number">2</span>], mean=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 将2范数限制到15进行放缩 不改变方向</span></span><br><span class="line"><span class="built_in">print</span>(tf.clip_by_norm(a, <span class="number">15</span>))</span><br><span class="line"><span class="comment"># 全部norm求和放缩到25</span></span><br><span class="line"><span class="comment"># new_grads,total_norm = tf.clip_by_global_norm(grads, 25)</span></span><br></pre></td></tr></table></figure>

<h4 id="12、GradientDescending求函数极值"><a href="#12、GradientDescending求函数极值" class="headerlink" title="12、GradientDescending求函数极值"></a>12、GradientDescending求函数极值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> (x[<span class="number">0</span>] ** <span class="number">2</span> + x[<span class="number">1</span>] - <span class="number">11</span>)**<span class="number">2</span> + (x[<span class="number">0</span>] + x[<span class="number">1</span>]**<span class="number">2</span> - <span class="number">7</span>)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = np.arange(-<span class="number">6</span>, <span class="number">6</span>, <span class="number">0.1</span>)</span><br><span class="line">y = np.arange(-<span class="number">6</span>, <span class="number">6</span>, <span class="number">0.1</span>)</span><br><span class="line">X, Y = np.meshgrid(x, y)</span><br><span class="line">Z = f([X, Y])</span><br><span class="line"></span><br><span class="line">fig = plt.figure(<span class="string">&quot;&quot;</span>)</span><br><span class="line">ax = fig.gca(projection=<span class="string">&quot;3d&quot;</span>)</span><br><span class="line">ax.plot_surface(X, Y, Z)</span><br><span class="line">ax.view_init(<span class="number">60</span>, -<span class="number">30</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">x = tf.constant([-<span class="number">4.0</span>, <span class="number">0.0</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        tape.watch([x])</span><br><span class="line">        y = f(x)</span><br><span class="line">    grads = tape.gradient(y, [x])[<span class="number">0</span>]</span><br><span class="line">    x -= <span class="number">0.01</span> * grads</span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Step:&quot;</span>, step, <span class="string">&quot; X:&quot;</span>, x.numpy(), <span class="string">&quot;Y:&quot;</span>, y.numpy())</span><br></pre></td></tr></table></figure>

<h4 id="13、Mnist手写数字识别"><a href="#13、Mnist手写数字识别" class="headerlink" title="13、Mnist手写数字识别"></a>13、Mnist手写数字识别</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line"></span><br><span class="line">(x, y), (x_test, y_test) = datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">x = tf.convert_to_tensor(x, dtype=tf.float32)/<span class="number">255</span></span><br><span class="line">y = tf.convert_to_tensor(y, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">x_test = tf.convert_to_tensor(x_test, dtype=tf.float32)/<span class="number">255</span></span><br><span class="line">y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)</span><br><span class="line"><span class="comment"># print(tf.reduce_max(x))</span></span><br><span class="line"></span><br><span class="line">train_db = tf.data.Dataset.from_tensor_slices((x, y)).batch(<span class="number">128</span>)</span><br><span class="line">train_db.shuffle(x.shape[<span class="number">0</span>])</span><br><span class="line">train_iter = <span class="built_in">iter</span>(train_db)</span><br><span class="line"><span class="comment"># sample = next(train_iter)</span></span><br><span class="line"><span class="comment"># print(sample)</span></span><br><span class="line"></span><br><span class="line">test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>, <span class="number">256</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">256</span>]))</span><br><span class="line">w2 = tf.Variable(tf.random.truncated_normal([<span class="number">256</span>, <span class="number">128</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">128</span>]))</span><br><span class="line">w3 = tf.Variable(tf.random.truncated_normal([<span class="number">128</span>, <span class="number">10</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b3 = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line">lr = <span class="number">1e-2</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30</span>):</span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_db):</span><br><span class="line">        x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">        y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            h1 = x@w1 + b1</span><br><span class="line">            h1 = tf.nn.relu(h1)</span><br><span class="line">            h2 = h1@w2 + b2</span><br><span class="line">            h2 = tf.nn.relu(h2)</span><br><span class="line">            out = h2@w3 + b3</span><br><span class="line">            out = tf.nn.softmax(out)</span><br><span class="line">            loss = tf.losses.categorical_crossentropy(out, y, from_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># loss = tf.square(y - out)</span></span><br><span class="line">            <span class="comment"># loss = tf.reduce_mean(loss)</span></span><br><span class="line"></span><br><span class="line">        grads = tape.gradient(loss,[w1, b1, w2, b2, w3, b3])</span><br><span class="line">        <span class="comment"># print(grads)</span></span><br><span class="line">        <span class="comment"># w1.assign_sub(lr * grads[0])</span></span><br><span class="line">        w1 = tf.Variable(w1 - lr * grads[<span class="number">0</span>])</span><br><span class="line">        b1 = tf.Variable(b1 - lr * grads[<span class="number">1</span>])</span><br><span class="line">        w2 = tf.Variable(w2 - lr * grads[<span class="number">2</span>])</span><br><span class="line">        b2 = tf.Variable(b2 - lr * grads[<span class="number">3</span>])</span><br><span class="line">        w3 = tf.Variable(w3 - lr * grads[<span class="number">4</span>])</span><br><span class="line">        b3 = tf.Variable(b3 - lr * grads[<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            loss = tf.reduce_mean(loss)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch&quot;</span>, epoch, <span class="string">&quot;Step:&quot;</span>, step, <span class="string">&quot;Loss:&quot;</span>, <span class="built_in">float</span>(loss))</span><br><span class="line"></span><br><span class="line">    total_correct = <span class="number">0</span></span><br><span class="line">    total_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_db):</span><br><span class="line">        x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span>])</span><br><span class="line"></span><br><span class="line">        h1 = x @ w1 + b1</span><br><span class="line">        h1 = tf.nn.relu(h1)</span><br><span class="line">        h2 = h1 @ w2 + b2</span><br><span class="line">        h2 = tf.nn.relu(h2)</span><br><span class="line">        out = h2 @ w3 + b3</span><br><span class="line">        prob = tf.nn.softmax(out)</span><br><span class="line">        <span class="comment"># [b, 10]</span></span><br><span class="line">        pred = tf.argmax(prob, axis=<span class="number">1</span>)</span><br><span class="line">        pred = tf.cast(pred, dtype=tf.int32)</span><br><span class="line">        correct = tf.cast(tf.equal(pred, y),dtype=tf.int32)</span><br><span class="line">        correct = tf.reduce_sum(correct)</span><br><span class="line">        total_correct += <span class="built_in">int</span>(correct)</span><br><span class="line">        total_num += x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Acc:&quot;</span>, total_correct/total_num)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="14、TensorBoard可视化"><a href="#14、TensorBoard可视化" class="headerlink" title="14、TensorBoard可视化"></a>14、TensorBoard可视化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_to_image</span>(<span class="params">figure</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Converts the matplotlib plot specified by &#x27;figure&#x27; to a PNG image and</span></span><br><span class="line"><span class="string">    returns it. The supplied figure is closed and inaccessible after this call.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Save the plot to a PNG in memory.</span></span><br><span class="line">    buf = io.BytesIO()</span><br><span class="line">    plt.savefig(buf, <span class="built_in">format</span>=<span class="string">&#x27;png&#x27;</span>)</span><br><span class="line">    <span class="comment"># Closing the figure prevents it from being displayed directly inside</span></span><br><span class="line">    <span class="comment"># the notebook.</span></span><br><span class="line">    plt.close(figure)</span><br><span class="line">    buf.seek(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># Convert PNG buffer to TF image</span></span><br><span class="line">    image = tf.image.decode_png(buf.getvalue(), channels=<span class="number">4</span>)</span><br><span class="line">    <span class="comment"># Add the batch dimension</span></span><br><span class="line">    image = tf.expand_dims(image, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image_grid</span>(<span class="params">images</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return a 5x5 grid of the MNIST images as a matplotlib figure.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Create a figure to contain the plot.</span></span><br><span class="line">    figure = plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">25</span>):</span><br><span class="line">        <span class="comment"># Start next subplot.</span></span><br><span class="line">        plt.subplot(<span class="number">5</span>, <span class="number">5</span>, i + <span class="number">1</span>, title=<span class="string">&#x27;name&#x27;</span>)</span><br><span class="line">        plt.xticks([])</span><br><span class="line">        plt.yticks([])</span><br><span class="line">        plt.grid(<span class="literal">False</span>)</span><br><span class="line">        plt.imshow(images[i], cmap=plt.cm.binary)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> figure</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255</span></span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    layers.Dense(<span class="number">256</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">32</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.build(input_shape=[<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">model.summary()</span><br><span class="line">optimizer = optimizers.Adam(learning_rate=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">current_time = datetime.datetime.now().strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>)</span><br><span class="line">log_dir = <span class="string">&#x27;../logs/&#x27;</span> + current_time</span><br><span class="line">summary_writer = tf.summary.create_file_writer(log_dir)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(db_train):</span><br><span class="line">        x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">        y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            out = model(x)</span><br><span class="line">            <span class="comment"># loss = tf.reduce_mean(tf.losses.MSE(y, out))</span></span><br><span class="line">            loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y, out, from_logits=<span class="literal">True</span>))</span><br><span class="line">        grads = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">        optimizer.apply_gradients(<span class="built_in">zip</span>(grads, model.trainable_variables))</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch&quot;</span>, epoch, <span class="string">&quot;Step:&quot;</span>, step, <span class="string">&quot;Loss:&quot;</span>, <span class="built_in">float</span>(loss))</span><br><span class="line">            <span class="keyword">with</span> summary_writer.as_default():</span><br><span class="line">                tf.summary.scalar(<span class="string">&#x27;train-loss&#x27;</span>, <span class="built_in">float</span>(loss), step=step)</span><br><span class="line"></span><br><span class="line">    total_correct = <span class="number">0</span></span><br><span class="line">    total_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> (x, y) <span class="keyword">in</span> db_test:</span><br><span class="line">        x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">        y = tf.cast(y, tf.int32)</span><br><span class="line">        out = model(x)</span><br><span class="line">        prob = tf.nn.softmax(out)</span><br><span class="line">        pred = tf.argmax(prob, axis=<span class="number">1</span>)</span><br><span class="line">        pred = tf.cast(pred, dtype=tf.int32)</span><br><span class="line">        correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)</span><br><span class="line">        correct = tf.reduce_sum(correct)</span><br><span class="line">        total_correct += <span class="built_in">int</span>(correct)</span><br><span class="line">        total_num += x.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Acc:&quot;</span>, total_correct / total_num)</span><br><span class="line">    <span class="keyword">with</span> summary_writer.as_default():</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;test-acc&#x27;</span>, <span class="built_in">float</span>(total_correct / total_num), step=epoch)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="三、Keras高层API"><a href="#三、Keras高层API" class="headerlink" title="三、Keras高层API"></a>三、Keras高层API</h3><h4 id="1、Keras常用API"><a href="#1、Keras常用API" class="headerlink" title="1、Keras常用API"></a>1、Keras常用API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255</span></span><br><span class="line">    x = tf.reshape(x, [<span class="number">28</span> * <span class="number">28</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.<span class="built_in">map</span>(preprocess).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    layers.Dense(<span class="number">256</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">32</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.build(input_shape=[<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">              loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="comment"># 每隔两次验证测试数据集合 共训练5次</span></span><br><span class="line">model.fit(db_train, epochs=<span class="number">5</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<h4 id="2、KerasMetrics计算均值和准确度"><a href="#2、KerasMetrics计算均值和准确度" class="headerlink" title="2、KerasMetrics计算均值和准确度"></a>2、KerasMetrics计算均值和准确度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255</span></span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    layers.Dense(<span class="number">256</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">32</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.build(input_shape=[<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">model.summary()</span><br><span class="line">optimizer = optimizers.Adam(learning_rate=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">loss_meter = metrics.Mean()</span><br><span class="line">acc_meter = metrics.Accuracy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(db_train):</span><br><span class="line">        x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">        y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            out = model(x)</span><br><span class="line">            <span class="comment"># loss = tf.reduce_mean(tf.losses.MSE(y, out))</span></span><br><span class="line">            loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y, out, from_logits=<span class="literal">True</span>))</span><br><span class="line">        grads = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">        optimizer.apply_gradients(<span class="built_in">zip</span>(grads, model.trainable_variables))</span><br><span class="line">        loss_meter.update_state(loss)</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch&quot;</span>, epoch, <span class="string">&quot;Step:&quot;</span>, step, <span class="string">&quot;Loss:&quot;</span>, loss_meter.result().numpy())</span><br><span class="line">            loss_meter.reset_states()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (x, y) <span class="keyword">in</span> db_test:</span><br><span class="line">        x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">        y = tf.cast(y, tf.int32)</span><br><span class="line">        out = model(x)</span><br><span class="line">        prob = tf.nn.softmax(out)</span><br><span class="line">        pred = tf.argmax(prob, axis=<span class="number">1</span>)</span><br><span class="line">        pred = tf.cast(pred, dtype=tf.int32)</span><br><span class="line">        acc_meter.update_state(pred, y)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Acc:&quot;</span>, acc_meter.result().numpy())</span><br><span class="line">    acc_meter.reset_states()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="3、自定义模型和层"><a href="#3、自定义模型和层" class="headerlink" title="3、自定义模型和层"></a>3、自定义模型和层</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDense</span>(layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, out_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyDense, self).__init__()</span><br><span class="line">        self.kernel = self.add_weight(<span class="string">&quot;w&quot;</span>, [in_dim, out_dim])</span><br><span class="line">        self.bias = self.add_weight(<span class="string">&quot;b&quot;</span>, [out_dim])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span><br><span class="line">        out = inputs @ self.kernel + self.bias</span><br><span class="line">        <span class="keyword">return</span> tf.nn.relu(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModel</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModel, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.fc1 = MyDense(<span class="number">28</span> * <span class="number">28</span>, <span class="number">256</span>)</span><br><span class="line">        self.fc2 = MyDense(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.fc3 = MyDense(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        self.fc4 = MyDense(<span class="number">64</span>, <span class="number">32</span>)</span><br><span class="line">        self.fc5 = MyDense(<span class="number">32</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.fc1(inputs)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        x = self.fc4(x)</span><br><span class="line">        x = self.fc5(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255</span></span><br><span class="line">    x = tf.reshape(x, [<span class="number">28</span> * <span class="number">28</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.<span class="built_in">map</span>(preprocess).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">model = MyModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># model.build(input_shape=[None, 28*28])</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">              loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">5</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4、CIFAR10分类"><a href="#4、CIFAR10分类" class="headerlink" title="4、CIFAR10分类"></a>4、CIFAR10分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDense</span>(layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, out_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyDense, self).__init__()</span><br><span class="line">        self.kernel = self.add_weight(<span class="string">&quot;w&quot;</span>, [in_dim, out_dim])</span><br><span class="line">        self.bias = self.add_weight(<span class="string">&quot;b&quot;</span>, [out_dim])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">return</span> tf.nn.relu(inputs @ self.kernel )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyNetwork</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyNetwork, self).__init__()</span><br><span class="line">        self.fc1 = MyDense(<span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>, <span class="number">256</span>)</span><br><span class="line">        self.fc2 = MyDense(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.fc3 = MyDense(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        self.fc4 = MyDense(<span class="number">64</span>, <span class="number">32</span>)</span><br><span class="line">        self.fc5 = MyDense(<span class="number">32</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = tf.reshape(inputs, [-<span class="number">1</span>, <span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>])</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        x = self.fc4(x)</span><br><span class="line">        x = self.fc5(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = <span class="number">2</span> * tf.cast(x, dtype=tf.float32) / <span class="number">255</span> - <span class="number">1</span></span><br><span class="line">    x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">32</span>*<span class="number">32</span>*<span class="number">3</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.<span class="built_in">map</span>(preprocess).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">model = MyNetwork()</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.001</span>),</span><br><span class="line">              loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">15</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="四、卷积神经网络"><a href="#四、卷积神经网络" class="headerlink" title="四、卷积神经网络"></a>四、卷积神经网络</h3><h4 id="1、自定义VGG13网络CIFAR100分类"><a href="#1、自定义VGG13网络CIFAR100分类" class="headerlink" title="1、自定义VGG13网络CIFAR100分类"></a>1、自定义VGG13网络CIFAR100分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">from</span> tensorflow_core.python.keras.losses <span class="keyword">import</span> Loss</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line">vgg13 = [</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.BatchNormalization(</span><br><span class="line">        axis=-<span class="number">1</span>,</span><br><span class="line">        center=<span class="literal">True</span>,</span><br><span class="line">        scale=<span class="literal">True</span>,</span><br><span class="line">        trainable=<span class="literal">True</span></span><br><span class="line">    ),</span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line"></span><br><span class="line">layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">128</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">128</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">256</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">256</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(<span class="number">0.001</span>)),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(<span class="number">0.001</span>)),</span><br><span class="line">    layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line"></span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">256</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.Dropout(<span class="number">0.3</span>),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    layers.Dense(<span class="number">100</span>, activation=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = <span class="number">2</span> * tf.cast(x, dtype=tf.float32) / <span class="number">255</span> - <span class="number">1</span></span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.cifar100.load_data()</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.<span class="built_in">map</span>(preprocess).batch(<span class="number">128</span>)</span><br><span class="line"><span class="comment"># 自定义loss函数</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DistanceLoss</span>(<span class="title class_ inherited__">Loss</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, y_true, y_pred</span>):</span><br><span class="line">        loss = tf.losses.categorical_crossentropy(y_true, y_pred, from_logits=<span class="literal">True</span>)</span><br><span class="line">        loss = tf.reduce_mean(loss)</span><br><span class="line">        loss = loss + (<span class="number">0.3</span>*loss - <span class="number">0.3</span>)**<span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">model = Sequential(vgg13)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.0001</span>),</span><br><span class="line">              loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">105</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2、使用ResNet网络对CIFAR100分类"><a href="#2、使用ResNet网络对CIFAR100分类" class="headerlink" title="2、使用ResNet网络对CIFAR100分类"></a>2、使用ResNet网络对CIFAR100分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">from</span> tensorflow_core.python.keras <span class="keyword">import</span> regularizers</span><br><span class="line"><span class="keyword">from</span> tensorflow_core.python.keras.losses <span class="keyword">import</span> Loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 该类的层会自动与最后一层连接</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, listOfLayer, shortcuts=<span class="literal">None</span>, activation=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">        self.model = Sequential(listOfLayer)</span><br><span class="line">        self.activation = activation</span><br><span class="line">        <span class="keyword">if</span> shortcuts <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.shortcut = <span class="keyword">lambda</span> x: x</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.shortcut = Sequential(shortcuts)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, **kwargs</span>):</span><br><span class="line">        residual = self.shortcut(inputs)</span><br><span class="line">        out = self.model(inputs)</span><br><span class="line">        <span class="keyword">if</span> self.activation <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> layers.add([residual, out])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.activation(residual + out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resNet</span>(<span class="params">filter_num, strides</span>):</span><br><span class="line">    <span class="keyword">if</span> strides == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> ResNet(listOfLayer=[</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        ], activation=tf.nn.relu)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> ResNet(listOfLayer=[</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=strides, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        ], shortcuts=[</span><br><span class="line"></span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">1</span>, <span class="number">1</span>), strides=strides, padding=<span class="string">&quot;same&quot;</span>, kernel_regularizer=regularizers.l2(<span class="number">5e-5</span>),</span><br><span class="line">                          use_bias=<span class="literal">False</span>, kernel_initializer=<span class="string">&#x27;glorot_normal&#x27;</span>)</span><br><span class="line">        ], activation=tf.nn.relu)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line">network = [layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>), layers.BatchNormalization(), layers.Activation(<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">           layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>), resNet(<span class="number">64</span>, <span class="number">1</span>), resNet(<span class="number">64</span>, <span class="number">1</span>), resNet(<span class="number">128</span>, <span class="number">2</span>),</span><br><span class="line">           resNet(<span class="number">128</span>, <span class="number">1</span>), layers.GlobalAveragePooling2D(), layers.Dense(<span class="number">100</span>, activation=<span class="literal">None</span>)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">network.append(resNet(<span class="number">256</span>, <span class="number">2</span>))</span><br><span class="line">network.append(resNet(<span class="number">256</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">network.append(resNet(<span class="number">512</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">network.append(resNet(<span class="number">512</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img_mean = tf.constant([<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>])</span><br><span class="line">img_std = tf.constant([<span class="number">0.2023</span>, <span class="number">0.1994</span>, <span class="number">0.2010</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize</span>(<span class="params">x, mean=img_mean, std=img_std</span>):</span><br><span class="line">    <span class="comment"># x shape: [224, 224, 3]</span></span><br><span class="line">    <span class="comment"># mean：shape为1；这里用到了广播机制。我们安装好右边对齐的原则，可以得到如下；</span></span><br><span class="line">    <span class="comment"># mean : [1, 1, 3], std: [3]        先插入1</span></span><br><span class="line">    <span class="comment"># mean : [224, 224, 3], std: [3]    再变为224</span></span><br><span class="line">    x = (x - mean) / std</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理，仅仅是类型的转换。    [-1~1]</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.image.random_flip_left_right(x)</span><br><span class="line">    <span class="comment"># x: [0,255]=&gt; 0~1 或者-0.5~0.5   其次：normalizaion</span></span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    <span class="comment"># 0~1 =&gt; D(0,1) 调用函数；</span></span><br><span class="line">    x = normalize(x)</span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># def preprocess(x, y):</span></span><br><span class="line"><span class="comment">#     x = 2 * tf.cast(x, dtype=tf.float32) / 255 - 1</span></span><br><span class="line"><span class="comment">#     y = tf.cast(y, dtype=tf.int32)</span></span><br><span class="line"><span class="comment">#     y = tf.squeeze(y)</span></span><br><span class="line"><span class="comment">#     y = tf.one_hot(y, depth=100)</span></span><br><span class="line"><span class="comment">#     return x, y</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.cifar100.load_data()</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.<span class="built_in">map</span>(preprocess).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DistanceLoss</span>(<span class="title class_ inherited__">Loss</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, y_true, y_pred</span>):</span><br><span class="line">        loss = tf.losses.categorical_crossentropy(y_true, y_pred, from_logits=<span class="literal">True</span>)</span><br><span class="line">        loss = tf.reduce_mean(loss)</span><br><span class="line">        loss = loss + (<span class="number">0.3</span> * loss - <span class="number">0.3</span>) ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Sequential(network)</span><br><span class="line">model.build(input_shape=[<span class="literal">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>])</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">1e-4</span>),</span><br><span class="line">              loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">1000</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="五、循环神经网络"><a href="#五、循环神经网络" class="headerlink" title="五、循环神经网络"></a>五、循环神经网络</h3><h4 id="1、循环神经网络对IMDB评论进行情感分类"><a href="#1、循环神经网络对IMDB评论进行情感分类" class="headerlink" title="1、循环神经网络对IMDB评论进行情感分类"></a>1、循环神经网络对IMDB评论进行情感分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line">tf.compat.v1.disable_eager_execution()</span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=<span class="number">80</span>)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=<span class="number">80</span>)</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyRNN</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, units, batchSize</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyRNN, self).__init__()</span><br><span class="line">        self.state0 = [tf.zeros([batchSize, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batchSize, units])]</span><br><span class="line">        <span class="comment"># [b 80] =&gt; [b 80 100]</span></span><br><span class="line">        self.embedding = layers.Embedding(<span class="number">10000</span>, <span class="number">100</span>, input_length=<span class="number">80</span>)</span><br><span class="line">        self.rnn_cell0 = layers.SimpleRNNCell(units, dropout=<span class="number">0.2</span>)</span><br><span class="line">        self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=<span class="number">0.2</span>)</span><br><span class="line">        self.fc = layers.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.embedding(inputs)</span><br><span class="line">        state0 = self.state0</span><br><span class="line">        state1 = self.state1</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> tf.unstack(x, axis=<span class="number">1</span>):</span><br><span class="line">            out, state0 = self.rnn_cell0(word, state0, training)</span><br><span class="line">            out, state1 = self.rnn_cell1(out, state1, training)</span><br><span class="line">        x = self.fc(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MyRNN(<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.0001</span>),</span><br><span class="line">              loss=tf.losses.BinaryCrossentropy(),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">15</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2、使用Keras内置的RNN进行IMDB情感分类"><a href="#2、使用Keras内置的RNN进行IMDB情感分类" class="headerlink" title="2、使用Keras内置的RNN进行IMDB情感分类"></a>2、使用Keras内置的RNN进行IMDB情感分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line">tf.compat.v1.disable_eager_execution()</span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=<span class="number">80</span>)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=<span class="number">80</span>)</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyRNN</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, units, batchSize</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyRNN, self).__init__()</span><br><span class="line">        self.state0 = [tf.zeros([batchSize, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batchSize, units])]</span><br><span class="line">        <span class="comment"># [b 80] =&gt; [b 80 100]</span></span><br><span class="line">        self.embedding = layers.Embedding(<span class="number">10000</span>, <span class="number">100</span>, input_length=<span class="number">80</span>)</span><br><span class="line">        self.rnn = keras.Sequential([</span><br><span class="line">            layers.SimpleRNN(units, dropout=<span class="number">0.5</span>, return_sequences=<span class="literal">True</span>, unroll=<span class="literal">True</span>),</span><br><span class="line">            layers.SimpleRNN(units, dropout=<span class="number">0.5</span>, unroll=<span class="literal">True</span>)</span><br><span class="line">        ])</span><br><span class="line">        self.fc = layers.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.embedding(inputs)</span><br><span class="line">        x = self.rnn(x)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MyRNN(<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.0001</span>),</span><br><span class="line">              loss=tf.losses.BinaryCrossentropy(),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">15</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="3、使用LSTM对IMDB评论进行情感分类"><a href="#3、使用LSTM对IMDB评论进行情感分类" class="headerlink" title="3、使用LSTM对IMDB评论进行情感分类"></a>3、使用LSTM对IMDB评论进行情感分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line">tf.compat.v1.disable_eager_execution()</span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=<span class="number">80</span>)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=<span class="number">80</span>)</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyRNN</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, units, batchSize</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyRNN, self).__init__()</span><br><span class="line">        self.state0 = [tf.zeros([batchSize, units]), tf.zeros([batchSize, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batchSize, units]), tf.zeros([batchSize, units])]</span><br><span class="line">        <span class="comment"># [b 80] =&gt; [b 80 100]</span></span><br><span class="line">        self.embedding = layers.Embedding(<span class="number">10000</span>, <span class="number">100</span>, input_length=<span class="number">80</span>)</span><br><span class="line">        self.rnn_cell0 = layers.LSTMCell(units, dropout=<span class="number">0.2</span>)</span><br><span class="line">        self.rnn_cell1 = layers.LSTMCell(units, dropout=<span class="number">0.2</span>)</span><br><span class="line">        self.fc = layers.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.embedding(inputs)</span><br><span class="line">        state0 = self.state0</span><br><span class="line">        state1 = self.state1</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> tf.unstack(x, axis=<span class="number">1</span>):</span><br><span class="line">            out, state0 = self.rnn_cell0(word, state0, training)</span><br><span class="line">            out, state1 = self.rnn_cell1(out, state1, training)</span><br><span class="line">        x = self.fc(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MyRNN(<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.0001</span>),</span><br><span class="line">              loss=tf.losses.BinaryCrossentropy(),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">15</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4、使用Keras内置LSTM进行IMDB情感分类"><a href="#4、使用Keras内置LSTM进行IMDB情感分类" class="headerlink" title="4、使用Keras内置LSTM进行IMDB情感分类"></a>4、使用Keras内置LSTM进行IMDB情感分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line">tf.compat.v1.disable_eager_execution()</span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=<span class="number">80</span>)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=<span class="number">80</span>)</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyRNN</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, units, batchSize</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyRNN, self).__init__()</span><br><span class="line">        self.state0 = [tf.zeros([batchSize, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batchSize, units])]</span><br><span class="line">        <span class="comment"># [b 80] =&gt; [b 80 100]</span></span><br><span class="line">        self.embedding = layers.Embedding(<span class="number">10000</span>, <span class="number">100</span>, input_length=<span class="number">80</span>)</span><br><span class="line">        self.rnn = keras.Sequential([</span><br><span class="line">            layers.LSTM(units, dropout=<span class="number">0.5</span>, return_sequences=<span class="literal">True</span>, unroll=<span class="literal">True</span>),</span><br><span class="line">            layers.LSTM(units, dropout=<span class="number">0.5</span>, unroll=<span class="literal">True</span>)</span><br><span class="line">        ])</span><br><span class="line">        self.fc = layers.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.embedding(inputs)</span><br><span class="line">        x = self.rnn(x)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MyRNN(<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.0001</span>),</span><br><span class="line">              loss=tf.losses.BinaryCrossentropy(),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">15</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="六、迁移学习"><a href="#六、迁移学习" class="headerlink" title="六、迁移学习"></a>六、迁移学习</h3><h4 id="1、使用VGG19迁移学习CIFAR100"><a href="#1、使用VGG19迁移学习CIFAR100" class="headerlink" title="1、使用VGG19迁移学习CIFAR100"></a>1、使用VGG19迁移学习CIFAR100</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">from</span> tensorflow_core.python.keras <span class="keyword">import</span> regularizers</span><br><span class="line"></span><br><span class="line">img_mean = tf.constant([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>])</span><br><span class="line">img_std = tf.constant([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize</span>(<span class="params">x, mean=img_mean, std=img_std</span>):</span><br><span class="line">    <span class="comment"># x shape: [224, 224, 3]</span></span><br><span class="line">    <span class="comment"># mean：shape为1；这里用到了广播机制。我们安装好右边对齐的原则，可以得到如下；</span></span><br><span class="line">    <span class="comment"># mean : [1, 1, 3], std: [3]        先插入1</span></span><br><span class="line">    <span class="comment"># mean : [224, 224, 3], std: [3]    再变为224</span></span><br><span class="line">    x = (x - mean)/std</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.0</span></span><br><span class="line">    x = tf.image.random_flip_left_right(x)</span><br><span class="line">    <span class="comment"># x = tf.image.resize(x, [224, 224])</span></span><br><span class="line">    x = normalize(x)</span><br><span class="line">    <span class="comment"># x = tf.transpose(x, perm=[2,1,0])</span></span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载Keras已有网络</span></span><br><span class="line">vgg19 = keras.applications.VGG19(weights=<span class="string">&quot;imagenet&quot;</span>, include_top=<span class="literal">False</span>, pooling=<span class="string">&quot;max&quot;</span>)</span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.cifar100.load_data()</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.<span class="built_in">map</span>(preprocess).batch(<span class="number">128</span>)</span><br><span class="line">vgg19.trainable = <span class="literal">False</span></span><br><span class="line">model = Sequential([</span><br><span class="line">    vgg19,</span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">1000</span>, activation=tf.nn.relu, kernel_initializer=<span class="string">&#x27;glorot_normal&#x27;</span>),</span><br><span class="line">    layers.Dropout(<span class="number">0.3</span>),</span><br><span class="line">    layers.Dense(<span class="number">500</span>, activation=tf.nn.relu, kernel_initializer=<span class="string">&#x27;glorot_normal&#x27;</span>),</span><br><span class="line">    layers.Dropout(<span class="number">0.3</span>),</span><br><span class="line">    layers.Dense(<span class="number">200</span>, activation=tf.nn.relu, kernel_initializer=<span class="string">&#x27;glorot_normal&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">100</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(vgg19.input_shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.001</span>),</span><br><span class="line">              loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">40</span>):</span><br><span class="line">    model.fit(db_train, epochs=<span class="number">2</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line">    db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">    db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="七、自编码器"><a href="#七、自编码器" class="headerlink" title="七、自编码器"></a>七、自编码器</h3><h4 id="1、对MNIST数据集进行自编码"><a href="#1、对MNIST数据集进行自编码" class="headerlink" title="1、对MNIST数据集进行自编码"></a>1、对MNIST数据集进行自编码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_images</span>(<span class="params">imgs, name</span>):</span><br><span class="line">    new_im = Image.new(<span class="string">&#x27;L&#x27;</span>, (<span class="number">280</span>, <span class="number">280</span>))</span><br><span class="line"></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">280</span>, <span class="number">28</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">280</span>, <span class="number">28</span>):</span><br><span class="line">            im = imgs[index]</span><br><span class="line">            im = Image.fromarray(im, mode=<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">            new_im.paste(im, (i, j))</span><br><span class="line">            index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    new_im.save(name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">CODE_DIM = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">(x_train, _1), (x_test, _2) = datasets.fashion_mnist.load_data()</span><br><span class="line">x_train, x_test = x_train.astype(np.float32).reshape([-<span class="number">1</span>, <span class="number">784</span>]) / <span class="number">255.</span>, x_test.astype(np.float32).reshape([-<span class="number">1</span>, <span class="number">784</span>]) / <span class="number">255.</span></span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, x_train))</span><br><span class="line">db_train = db_train.shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, x_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AE</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(AE, self).__init__()</span><br><span class="line">        self.encoder = Sequential([</span><br><span class="line">            layers.Dense(<span class="number">256</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Dense(<span class="number">128</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Dense(CODE_DIM)</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">        self.decoder = Sequential([</span><br><span class="line">            layers.Dense(<span class="number">128</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Dense(<span class="number">256</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Dense(<span class="number">784</span>)</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.encoder(inputs)</span><br><span class="line">        x = self.decoder(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = AE()</span><br><span class="line">model.build(input_shape=(<span class="literal">None</span>, <span class="number">784</span>))</span><br><span class="line">model.summary()</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">              loss=<span class="string">&quot;mse&quot;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;===============================================&quot;</span>)</span><br><span class="line">    model.fit(db_train, epochs=<span class="number">10</span>)</span><br><span class="line">    x, y = <span class="built_in">next</span>(<span class="built_in">iter</span>(db_test))</span><br><span class="line">    y = tf.reshape(y, [-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">    out = model(tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>]))</span><br><span class="line">    out = tf.reshape(out, [-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line"></span><br><span class="line">    true_fake = tf.concat([y[<span class="number">0</span>:<span class="number">50</span>] ,out[<span class="number">0</span>:<span class="number">50</span>]], axis=<span class="number">0</span>)</span><br><span class="line">    true_fake = true_fake.numpy() * <span class="number">255</span></span><br><span class="line">    true_fake = true_fake.astype(np.uint8)</span><br><span class="line"></span><br><span class="line">    save_images(true_fake, <span class="built_in">str</span>(i)+<span class="string">&quot;test.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2、VariationalAutoEncoder"><a href="#2、VariationalAutoEncoder" class="headerlink" title="2、VariationalAutoEncoder"></a>2、VariationalAutoEncoder</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_images</span>(<span class="params">imgs, name</span>):</span><br><span class="line">    new_im = Image.new(<span class="string">&#x27;L&#x27;</span>, (<span class="number">280</span>, <span class="number">280</span>))</span><br><span class="line"></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">280</span>, <span class="number">28</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">280</span>, <span class="number">28</span>):</span><br><span class="line">            im = imgs[index]</span><br><span class="line">            im = Image.fromarray(im, mode=<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">            new_im.paste(im, (i, j))</span><br><span class="line">            index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    new_im.save(name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">128</span></span><br><span class="line">CODE_DIM = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">(x_train, _1), (x_test, _2) = datasets.mnist.load_data()</span><br><span class="line">x_train, x_test = x_train.astype(np.float32).reshape([-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>]) / <span class="number">255.</span>, x_test.astype(np.float32).reshape([-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>]) / <span class="number">255.</span></span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices(x_train)</span><br><span class="line">db_train = db_train.shuffle(<span class="number">10000</span>).batch(BATCH_SIZE)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices(x_test)</span><br><span class="line">db_test = db_test.batch(<span class="number">50</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reparameter</span>(<span class="params">mu, log_var</span>):</span><br><span class="line">    eps = tf.random.normal(log_var.shape)</span><br><span class="line"></span><br><span class="line">    std = tf.exp(log_var * <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    z = mu + std * eps</span><br><span class="line">    <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VariationalAutoEncoder</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(VariationalAutoEncoder, self).__init__()</span><br><span class="line">        self.encoder = Sequential([</span><br><span class="line">            layers.Conv2D(<span class="number">64</span>, strides=<span class="number">2</span>, kernel_size=[<span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Conv2D(<span class="number">128</span>, strides=<span class="number">2</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Conv2D(<span class="number">256</span>, strides=<span class="number">2</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Flatten(),</span><br><span class="line">            layers.Dense(<span class="number">500</span>, activation=tf.nn.relu)</span><br><span class="line">        ])</span><br><span class="line">        self.mean = Sequential([</span><br><span class="line">            layers.Dense(CODE_DIM, activation=tf.nn.relu)</span><br><span class="line">        ])</span><br><span class="line">        self.variance = Sequential([</span><br><span class="line">            layers.Dense(CODE_DIM, activation=tf.nn.relu)</span><br><span class="line">        ])</span><br><span class="line">        self.decoder = Sequential([</span><br><span class="line">            layers.Flatten(),</span><br><span class="line">            layers.Dense(<span class="number">1024</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Dense(<span class="number">900</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Dense(<span class="number">784</span>)</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.encoder(inputs)</span><br><span class="line">        mean = self.mean(x)</span><br><span class="line">        log_var = self.variance(x)</span><br><span class="line">        z = reparameter(mean, log_var)</span><br><span class="line">        out = self.decoder(z)</span><br><span class="line">        <span class="keyword">return</span> out, mean, log_var</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">VAE = VariationalAutoEncoder()</span><br><span class="line">optimizer = tf.optimizers.Adam(<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> step, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(db_train):</span><br><span class="line"></span><br><span class="line">        rx = tf.reshape(x, [-<span class="number">1</span>, <span class="number">784</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            out, mean, log_var = VAE(x)</span><br><span class="line"></span><br><span class="line">            rec_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=rx, logits=out)</span><br><span class="line">            rec_loss = tf.reduce_sum(rec_loss) / x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute kl divergence (mu, var) ~ N (0, 1)</span></span><br><span class="line">            <span class="comment"># https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians</span></span><br><span class="line">            kl_div = -<span class="number">0.5</span> * (log_var + <span class="number">1</span> - mean**<span class="number">2</span> - tf.exp(log_var))</span><br><span class="line">            kl_div = tf.reduce_sum(kl_div) / x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            loss = rec_loss + <span class="number">3.</span> * kl_div</span><br><span class="line"></span><br><span class="line">        grads = tape.gradient(loss, VAE.trainable_variables)</span><br><span class="line">        optimizer.apply_gradients(<span class="built_in">zip</span>(grads, VAE.trainable_variables))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(epoch, step, <span class="string">&#x27;kl div:&#x27;</span>, <span class="built_in">float</span>(kl_div), <span class="string">&#x27;rec loss:&#x27;</span>, <span class="built_in">float</span>(rec_loss))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    z = tf.random.normal((<span class="number">100</span>, CODE_DIM))</span><br><span class="line">    logits = VAE.decoder(z)</span><br><span class="line">    x_hat = tf.sigmoid(logits)</span><br><span class="line">    x_hat = tf.reshape(x_hat, [-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>]).numpy() * <span class="number">255.</span></span><br><span class="line">    x_hat = x_hat.astype(np.uint8)</span><br><span class="line">    save_images(x_hat, <span class="string">&#x27;vae_images/sampled_epoch%d.png&#x27;</span> % epoch)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="八、对抗神经网络"><a href="#八、对抗神经网络" class="headerlink" title="八、对抗神经网络"></a>八、对抗神经网络</h3><h4 id="1、GAN"><a href="#1、GAN" class="headerlink" title="1、GAN"></a>1、GAN</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">from</span> tensorflow_core.python.keras <span class="keyword">import</span> regularizers</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_anime_dataset</span>(<span class="params">img_paths, batch_size, resize=<span class="number">64</span>, drop_remainder=<span class="literal">True</span>, shuffle=<span class="literal">True</span>, repeat=<span class="number">1</span></span>):</span><br><span class="line"><span class="meta">    @tf.function</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_map_fn</span>(<span class="params">img</span>):</span><br><span class="line">        img = tf.image.resize(img, [resize, resize])</span><br><span class="line">        img = tf.clip_by_value(img, <span class="number">0</span>, <span class="number">255</span>)</span><br><span class="line">        img = img / <span class="number">127.5</span> - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">    dataset = disk_image_batch_dataset(img_paths,</span><br><span class="line">                                       batch_size,</span><br><span class="line">                                       drop_remainder=drop_remainder,</span><br><span class="line">                                       map_fn=_map_fn,</span><br><span class="line">                                       shuffle=shuffle,</span><br><span class="line">                                       repeat=repeat)</span><br><span class="line">    img_shape = (resize, resize, <span class="number">3</span>)</span><br><span class="line">    len_dataset = <span class="built_in">len</span>(img_paths) // batch_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset, img_shape, len_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">batch_dataset</span>(<span class="params">dataset,</span></span><br><span class="line"><span class="params">                  batch_size,</span></span><br><span class="line"><span class="params">                  drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                  n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                  filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                  shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                  shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># set defaults</span></span><br><span class="line">    <span class="keyword">if</span> n_map_threads <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        n_map_threads = multiprocessing.cpu_count()</span><br><span class="line">    <span class="keyword">if</span> shuffle <span class="keyword">and</span> shuffle_buffer_size <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        shuffle_buffer_size = <span class="built_in">max</span>(batch_size * <span class="number">128</span>, <span class="number">2048</span>)  <span class="comment"># set the minimum buffer size as 2048</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` is sometimes costly</span></span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        dataset = dataset.shuffle(shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> filter_after_map:</span><br><span class="line">        <span class="keyword">if</span> filter_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">filter</span>(filter_fn)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> map_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(map_fn, num_parallel_calls=n_map_threads)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># [*] this is slower</span></span><br><span class="line">        <span class="keyword">if</span> map_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(map_fn, num_parallel_calls=n_map_threads)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> filter_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">filter</span>(filter_fn)</span><br><span class="line"></span><br><span class="line">    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)</span><br><span class="line"></span><br><span class="line">    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">memory_data_batch_dataset</span>(<span class="params">memory_data,</span></span><br><span class="line"><span class="params">                              batch_size,</span></span><br><span class="line"><span class="params">                              drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                              n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                              filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                              shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                              shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Batch dataset of memory data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    memory_data : nested structure of tensors/ndarrays/lists</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dataset = tf.data.Dataset.from_tensor_slices(memory_data)</span><br><span class="line">    dataset = batch_dataset(dataset,</span><br><span class="line">                            batch_size,</span><br><span class="line">                            drop_remainder=drop_remainder,</span><br><span class="line">                            n_prefetch_batch=n_prefetch_batch,</span><br><span class="line">                            filter_fn=filter_fn,</span><br><span class="line">                            map_fn=map_fn,</span><br><span class="line">                            n_map_threads=n_map_threads,</span><br><span class="line">                            filter_after_map=filter_after_map,</span><br><span class="line">                            shuffle=shuffle,</span><br><span class="line">                            shuffle_buffer_size=shuffle_buffer_size,</span><br><span class="line">                            repeat=repeat)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">disk_image_batch_dataset</span>(<span class="params">img_paths,</span></span><br><span class="line"><span class="params">                             batch_size,</span></span><br><span class="line"><span class="params">                             labels=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                             n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                             filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                             shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                             shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Batch dataset of disk image for PNG and JPEG.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">        img_paths : 1d-tensor/ndarray/list of str</span></span><br><span class="line"><span class="string">        labels : nested structure of tensors/ndarrays/lists</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        memory_data = img_paths</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        memory_data = (img_paths, labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_fn</span>(<span class="params">path, *label</span>):</span><br><span class="line">        img = tf.io.read_file(path)</span><br><span class="line">        img = tf.image.decode_png(img, <span class="number">3</span>)  <span class="comment"># fix channels to 3</span></span><br><span class="line">        <span class="keyword">return</span> (img,) + label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> map_fn:  <span class="comment"># fuse `map_fn` and `parse_fn`</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">map_fn_</span>(<span class="params">*args</span>):</span><br><span class="line">            <span class="keyword">return</span> map_fn(*parse_fn(*args))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        map_fn_ = parse_fn</span><br><span class="line"></span><br><span class="line">    dataset = memory_data_batch_dataset(memory_data,</span><br><span class="line">                                        batch_size,</span><br><span class="line">                                        drop_remainder=drop_remainder,</span><br><span class="line">                                        n_prefetch_batch=n_prefetch_batch,</span><br><span class="line">                                        filter_fn=filter_fn,</span><br><span class="line">                                        map_fn=map_fn_,</span><br><span class="line">                                        n_map_threads=n_map_threads,</span><br><span class="line">                                        filter_after_map=filter_after_map,</span><br><span class="line">                                        shuffle=shuffle,</span><br><span class="line">                                        shuffle_buffer_size=shuffle_buffer_size,</span><br><span class="line">                                        repeat=repeat)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">discriminator = Sequential([</span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">3</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">128</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">3</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">256</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">3</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">32</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">1</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">generator = Sequential([</span><br><span class="line">    layers.Dense(<span class="number">3</span> * <span class="number">3</span> * <span class="number">512</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Reshape((<span class="number">3</span>, <span class="number">3</span>, <span class="number">512</span>)),</span><br><span class="line">    <span class="comment"># 9</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">256</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    <span class="comment"># (9-1)*2 + 5 = 21</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">128</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="string">&#x27;valid&#x27;</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    <span class="comment"># (21-1)*3 + 4 = 64</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>, activation=tf.tanh),</span><br><span class="line"></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_images</span>(<span class="params">imgs, name</span>):</span><br><span class="line">    new_im = Image.new(<span class="string">&#x27;RGB&#x27;</span>, (<span class="number">640</span>, <span class="number">640</span>))</span><br><span class="line"></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">640</span>, <span class="number">64</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">640</span>, <span class="number">64</span>):</span><br><span class="line">            im = imgs[index]</span><br><span class="line">            im = np.array(im)</span><br><span class="line">            im = ((im + <span class="number">1.0</span>) * <span class="number">127.5</span>).astype(np.uint8)</span><br><span class="line">            im = Image.fromarray(im, mode=<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">            new_im.paste(im, (i, j))</span><br><span class="line">            index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    new_im.save(name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">d_loss_fn</span>(<span class="params">generator, discriminator, batch_z, batch_x</span>):</span><br><span class="line">    fake_images = generator(batch_z)</span><br><span class="line">    fake_out = discriminator(fake_images)</span><br><span class="line">    real_out = discriminator(batch_x)</span><br><span class="line"></span><br><span class="line">    fake_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_out, labels=tf.zeros_like(fake_out))</span><br><span class="line">    real_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=real_out, labels=tf.ones_like(real_out))</span><br><span class="line"></span><br><span class="line">    fake_loss = tf.reduce_mean(fake_loss)</span><br><span class="line">    real_loss = tf.reduce_mean(real_loss)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fake_loss + real_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">512</span></span><br><span class="line">CODE_SIZE = <span class="number">100</span></span><br><span class="line">LEARNING_RATE = <span class="number">0.0002</span></span><br><span class="line">EPOCHS = <span class="number">20000</span></span><br><span class="line">img_path = glob.glob(<span class="string">r&quot;E:\BaiduNetdiskDownload\faces\*.jpg&quot;</span>)</span><br><span class="line">dataset, image_shape, _ = make_anime_dataset(img_path, BATCH_SIZE)</span><br><span class="line">dataset = dataset.repeat()</span><br><span class="line">db_iter = <span class="built_in">iter</span>(dataset)</span><br><span class="line"></span><br><span class="line">generator.build(input_shape=(<span class="literal">None</span>, CODE_SIZE))</span><br><span class="line">discriminator.build(input_shape=(<span class="literal">None</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>))</span><br><span class="line">g_optimizer = optimizers.Adam(LEARNING_RATE)</span><br><span class="line">d_optimizer = optimizers.Adam(LEARNING_RATE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">g_loss_fn</span>(<span class="params">generator, discriminator, batch_z</span>):</span><br><span class="line">    fake_images = generator(batch_z)</span><br><span class="line">    fake_out = discriminator(fake_images)</span><br><span class="line">    fake_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_out, labels=tf.ones_like(fake_out))</span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(fake_loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    batch_z = tf.random.uniform([BATCH_SIZE, CODE_SIZE], minval=-<span class="number">1</span>, maxval=<span class="number">1</span>)</span><br><span class="line">    batch_x = <span class="built_in">next</span>(db_iter)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x)</span><br><span class="line">    grads = tape.gradient(d_loss, discriminator.trainable_variables)</span><br><span class="line">    d_optimizer.apply_gradients(<span class="built_in">zip</span>(grads, discriminator.trainable_variables))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        g_loss = g_loss_fn(generator, discriminator, batch_z)</span><br><span class="line">    grads = tape.gradient(g_loss, generator.trainable_variables)</span><br><span class="line">    g_optimizer.apply_gradients(<span class="built_in">zip</span>(grads, generator.trainable_variables))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">30</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;d-loss:&quot;</span>, <span class="built_in">float</span>(d_loss), <span class="string">&quot;g-loss:&quot;</span>, <span class="built_in">float</span>(g_loss))</span><br><span class="line">        z = tf.random.uniform([<span class="number">100</span>, CODE_SIZE], minval=-<span class="number">1</span>, maxval=<span class="number">1</span>)</span><br><span class="line">        images = generator(z)</span><br><span class="line">        save_images(images, <span class="string">&#x27;dc-gan/sampled_epoch%d.png&#x27;</span> % epoch)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4、WGAN"><a href="#4、WGAN" class="headerlink" title="4、WGAN"></a>4、WGAN</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">from</span> tensorflow_core.python.keras <span class="keyword">import</span> regularizers</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">512</span></span><br><span class="line">CODE_SIZE = <span class="number">300</span></span><br><span class="line">LEARNING_RATE = <span class="number">0.0002</span></span><br><span class="line">EPOCHS = <span class="number">2000000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_anime_dataset</span>(<span class="params">img_paths, batch_size, resize=<span class="number">64</span>, drop_remainder=<span class="literal">True</span>, shuffle=<span class="literal">True</span>, repeat=<span class="number">1</span></span>):</span><br><span class="line"><span class="meta">    @tf.function</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_map_fn</span>(<span class="params">img</span>):</span><br><span class="line">        img = tf.image.resize(img, [resize, resize])</span><br><span class="line">        img = tf.clip_by_value(img, <span class="number">0</span>, <span class="number">255</span>)</span><br><span class="line">        img = img / <span class="number">127.5</span> - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">    dataset = disk_image_batch_dataset(img_paths,</span><br><span class="line">                                       batch_size,</span><br><span class="line">                                       drop_remainder=drop_remainder,</span><br><span class="line">                                       map_fn=_map_fn,</span><br><span class="line">                                       shuffle=shuffle,</span><br><span class="line">                                       repeat=repeat)</span><br><span class="line">    img_shape = (resize, resize, <span class="number">3</span>)</span><br><span class="line">    len_dataset = <span class="built_in">len</span>(img_paths) // batch_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset, img_shape, len_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">batch_dataset</span>(<span class="params">dataset,</span></span><br><span class="line"><span class="params">                  batch_size,</span></span><br><span class="line"><span class="params">                  drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                  n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                  filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                  shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                  shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># set defaults</span></span><br><span class="line">    <span class="keyword">if</span> n_map_threads <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        n_map_threads = multiprocessing.cpu_count()</span><br><span class="line">    <span class="keyword">if</span> shuffle <span class="keyword">and</span> shuffle_buffer_size <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        shuffle_buffer_size = <span class="built_in">max</span>(batch_size * <span class="number">128</span>, <span class="number">2048</span>)  <span class="comment"># set the minimum buffer size as 2048</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` is sometimes costly</span></span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        dataset = dataset.shuffle(shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> filter_after_map:</span><br><span class="line">        <span class="keyword">if</span> filter_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">filter</span>(filter_fn)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> map_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(map_fn, num_parallel_calls=n_map_threads)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># [*] this is slower</span></span><br><span class="line">        <span class="keyword">if</span> map_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(map_fn, num_parallel_calls=n_map_threads)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> filter_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">filter</span>(filter_fn)</span><br><span class="line"></span><br><span class="line">    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)</span><br><span class="line"></span><br><span class="line">    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">memory_data_batch_dataset</span>(<span class="params">memory_data,</span></span><br><span class="line"><span class="params">                              batch_size,</span></span><br><span class="line"><span class="params">                              drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                              n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                              filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                              shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                              shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Batch dataset of memory data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    memory_data : nested structure of tensors/ndarrays/lists</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dataset = tf.data.Dataset.from_tensor_slices(memory_data)</span><br><span class="line">    dataset = batch_dataset(dataset,</span><br><span class="line">                            batch_size,</span><br><span class="line">                            drop_remainder=drop_remainder,</span><br><span class="line">                            n_prefetch_batch=n_prefetch_batch,</span><br><span class="line">                            filter_fn=filter_fn,</span><br><span class="line">                            map_fn=map_fn,</span><br><span class="line">                            n_map_threads=n_map_threads,</span><br><span class="line">                            filter_after_map=filter_after_map,</span><br><span class="line">                            shuffle=shuffle,</span><br><span class="line">                            shuffle_buffer_size=shuffle_buffer_size,</span><br><span class="line">                            repeat=repeat)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">disk_image_batch_dataset</span>(<span class="params">img_paths,</span></span><br><span class="line"><span class="params">                             batch_size,</span></span><br><span class="line"><span class="params">                             labels=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                             n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                             filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                             shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                             shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Batch dataset of disk image for PNG and JPEG.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">        img_paths : 1d-tensor/ndarray/list of str</span></span><br><span class="line"><span class="string">        labels : nested structure of tensors/ndarrays/lists</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        memory_data = img_paths</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        memory_data = (img_paths, labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_fn</span>(<span class="params">path, *label</span>):</span><br><span class="line">        img = tf.io.read_file(path)</span><br><span class="line">        img = tf.image.decode_png(img, <span class="number">3</span>)  <span class="comment"># fix channels to 3</span></span><br><span class="line">        <span class="keyword">return</span> (img,) + label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> map_fn:  <span class="comment"># fuse `map_fn` and `parse_fn`</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">map_fn_</span>(<span class="params">*args</span>):</span><br><span class="line">            <span class="keyword">return</span> map_fn(*parse_fn(*args))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        map_fn_ = parse_fn</span><br><span class="line"></span><br><span class="line">    dataset = memory_data_batch_dataset(memory_data,</span><br><span class="line">                                        batch_size,</span><br><span class="line">                                        drop_remainder=drop_remainder,</span><br><span class="line">                                        n_prefetch_batch=n_prefetch_batch,</span><br><span class="line">                                        filter_fn=filter_fn,</span><br><span class="line">                                        map_fn=map_fn_,</span><br><span class="line">                                        n_map_threads=n_map_threads,</span><br><span class="line">                                        filter_after_map=filter_after_map,</span><br><span class="line">                                        shuffle=shuffle,</span><br><span class="line">                                        shuffle_buffer_size=shuffle_buffer_size,</span><br><span class="line">                                        repeat=repeat)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">discriminator = Sequential([</span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">3</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">128</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">3</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">256</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">3</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">32</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">1</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">generator = Sequential([</span><br><span class="line">    layers.Dense(<span class="number">3</span> * <span class="number">3</span> * <span class="number">512</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Reshape((<span class="number">3</span>, <span class="number">3</span>, <span class="number">512</span>)),</span><br><span class="line">    <span class="comment"># 9</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">256</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    <span class="comment"># (9-1)*2 + 5 = 21</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">128</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="string">&#x27;valid&#x27;</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    <span class="comment"># (21-1)*3 + 4 = 64</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>, activation=tf.tanh),</span><br><span class="line"></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_images</span>(<span class="params">imgs, name</span>):</span><br><span class="line">    new_im = Image.new(<span class="string">&#x27;RGB&#x27;</span>, (<span class="number">640</span>, <span class="number">640</span>))</span><br><span class="line"></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">640</span>, <span class="number">64</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">640</span>, <span class="number">64</span>):</span><br><span class="line">            im = imgs[index]</span><br><span class="line">            im = np.array(im)</span><br><span class="line">            im = ((im + <span class="number">1.0</span>) * <span class="number">127.5</span>).astype(np.uint8)</span><br><span class="line">            im = Image.fromarray(im, mode=<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">            new_im.paste(im, (i, j))</span><br><span class="line">            index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    new_im.save(name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算梯度惩罚项</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_penalty</span>(<span class="params">discriminator, batch_x, fake_images</span>):</span><br><span class="line">    t = tf.random.uniform([BATCH_SIZE, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    t = tf.broadcast_to(t, batch_x.shape)</span><br><span class="line">    <span class="comment"># 元素乘法</span></span><br><span class="line">    interplate = t * batch_x + (<span class="number">1</span> - t) * fake_images</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        tape.watch([interplate])</span><br><span class="line">        out = discriminator(interplate)</span><br><span class="line">    grads = tape.gradient(out, interplate)</span><br><span class="line">    grads = tf.reshape(grads, [BATCH_SIZE, -<span class="number">1</span>])</span><br><span class="line">    gp = tf.norm(grads, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean((gp-<span class="number">1</span>)**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">d_loss_fn</span>(<span class="params">generator, discriminator, batch_z, batch_x</span>):</span><br><span class="line">    fake_images = generator(batch_z)</span><br><span class="line">    fake_out = discriminator(fake_images)</span><br><span class="line">    real_out = discriminator(batch_x)</span><br><span class="line"></span><br><span class="line">    fake_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_out, labels=tf.zeros_like(fake_out))</span><br><span class="line">    real_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=real_out, labels=tf.ones_like(real_out))</span><br><span class="line"></span><br><span class="line">    fake_loss = tf.reduce_mean(fake_loss)</span><br><span class="line">    real_loss = tf.reduce_mean(real_loss)</span><br><span class="line"></span><br><span class="line">    gp = gradient_penalty(discriminator, batch_x, fake_images)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fake_loss + real_loss + gp, gp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img_path = glob.glob(<span class="string">r&quot;E:\BaiduNetdiskDownload\faces\*.jpg&quot;</span>)</span><br><span class="line">dataset, image_shape, _ = make_anime_dataset(img_path, BATCH_SIZE)</span><br><span class="line">dataset = dataset.repeat()</span><br><span class="line">db_iter = <span class="built_in">iter</span>(dataset)</span><br><span class="line"></span><br><span class="line">generator.build(input_shape=(<span class="literal">None</span>, CODE_SIZE))</span><br><span class="line">discriminator.build(input_shape=(<span class="literal">None</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>))</span><br><span class="line">g_optimizer = optimizers.Adam(LEARNING_RATE)</span><br><span class="line">d_optimizer = optimizers.Adam(LEARNING_RATE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">g_loss_fn</span>(<span class="params">generator, discriminator, batch_z</span>):</span><br><span class="line">    fake_images = generator(batch_z)</span><br><span class="line">    fake_out = discriminator(fake_images)</span><br><span class="line">    fake_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_out, labels=tf.ones_like(fake_out))</span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(fake_loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    batch_z = tf.random.uniform([BATCH_SIZE, CODE_SIZE], minval=-<span class="number">1</span>, maxval=<span class="number">1</span>)</span><br><span class="line">    batch_x = <span class="built_in">next</span>(db_iter)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        d_loss, gp = d_loss_fn(generator, discriminator, batch_z, batch_x)</span><br><span class="line">    grads = tape.gradient(d_loss, discriminator.trainable_variables)</span><br><span class="line">    d_optimizer.apply_gradients(<span class="built_in">zip</span>(grads, discriminator.trainable_variables))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        g_loss = g_loss_fn(generator, discriminator, batch_z)</span><br><span class="line">    grads = tape.gradient(g_loss, generator.trainable_variables)</span><br><span class="line">    g_optimizer.apply_gradients(<span class="built_in">zip</span>(grads, generator.trainable_variables))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">30</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;d-loss:&quot;</span>, <span class="built_in">float</span>(d_loss), <span class="string">&quot;g-loss:&quot;</span>, <span class="built_in">float</span>(g_loss), <span class="string">&quot;gp&quot;</span>, <span class="built_in">float</span>(gp))</span><br><span class="line">        z = tf.random.uniform([<span class="number">100</span>, CODE_SIZE], minval=-<span class="number">1</span>, maxval=<span class="number">1</span>)</span><br><span class="line">        images = generator(z)</span><br><span class="line">        save_images(images, <span class="string">&#x27;w-gan/sampled_epoch%d.png&#x27;</span> % epoch)</span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        discriminator.save_weights(<span class="string">&quot;model-wgan/w-gan-d&quot;</span>)</span><br><span class="line">        generator.save_weights(<span class="string">&quot;model-wgan/w-gan-g&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>










    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
            </div>
            <div class="post-nav-item">
                <a href="/2019/07/14/Gambler's%20Ruin%20Problem/" rel="next" title="Gambler's Ruin Problem">
                  Gambler's Ruin Problem <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">cocofhu</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
