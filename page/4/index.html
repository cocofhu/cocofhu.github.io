<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"cocofhu.com","root":"/","images":"/images","scheme":"Mist","darkmode":"ture","version":"8.18.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":"mac"},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="邪王真眼是最强的">
<meta property="og:type" content="website">
<meta property="og:title" content="小鸟游六花">
<meta property="og:url" content="http://cocofhu.com/page/4/index.html">
<meta property="og:site_name" content="小鸟游六花">
<meta property="og:description" content="邪王真眼是最强的">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="cocofhu">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://cocofhu.com/page/4/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/4/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>小鸟游六花</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">小鸟游六花</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">vanishment this world</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>







</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">cocofhu</p>
  <div class="site-description" itemprop="description">邪王真眼是最强的</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">12</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/cocofhu" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;cocofhu" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:cocofhu@outlook.com" title="E-Mail → mailto:cocofhu@outlook.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://cocofhu.com/2023/09/17/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="cocofhu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小鸟游六花">
      <meta itemprop="description" content="邪王真眼是最强的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 小鸟游六花">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/09/17/%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/" class="post-title-link" itemprop="url">树状数组</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2023-09-17 05:01:34" itemprop="dateCreated datePublished" datetime="2023-09-17T05:01:34+00:00">2023-09-17</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-29 09:25:22" itemprop="dateModified" datetime="2024-05-29T09:25:22+00:00">2024-05-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h3 id="一、常用模板"><a href="#一、常用模板" class="headerlink" title="一、常用模板"></a>一、常用模板</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 一维树状数组，单点修改区间求和</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> maxn = <span class="number">100015</span>;</span><br><span class="line"><span class="type">int</span> B[maxn];</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">lowbit</span><span class="params">(<span class="type">int</span> x)</span></span>&#123;<span class="keyword">return</span> x&amp;(-x);&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">zero</span><span class="params">()</span></span>&#123;<span class="built_in">memset</span>(B,<span class="number">0</span>,<span class="built_in">sizeof</span>(B));&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">update</span><span class="params">(<span class="type">int</span> i,<span class="type">int</span> d)</span></span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;maxn) B[i]+= d, i +=<span class="built_in">lowbit</span>(i);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">query</span><span class="params">(<span class="type">int</span> i)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> ret=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(i&gt;<span class="number">0</span>) ret+=B[i], i-=<span class="built_in">lowbit</span>(i);</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 二维树状数组，单点修改矩阵求和</span></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> maxn = <span class="number">1050</span>;</span><br><span class="line"><span class="type">int</span> B[maxn][maxn];</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">lowbit</span><span class="params">(<span class="type">int</span> x)</span></span>&#123;<span class="keyword">return</span> x&amp;(-x);&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">zero</span><span class="params">()</span></span>&#123;<span class="built_in">memset</span>(B,<span class="number">0</span>,<span class="built_in">sizeof</span>(B));&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">update</span><span class="params">(<span class="type">int</span> x,<span class="type">int</span> y,<span class="type">int</span> d)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = x; i &lt; maxn; i+=<span class="built_in">lowbit</span>(i))</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j = y; j &lt; maxn; j+=<span class="built_in">lowbit</span>(j)) B[i][j] += d;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">query</span><span class="params">(<span class="type">int</span> x,<span class="type">int</span> y)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(x &lt;= <span class="number">0</span> || y &lt;= <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> ans=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = x; i &gt; <span class="number">0</span>; i-=<span class="built_in">lowbit</span>(i))</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j = y; j &gt; <span class="number">0</span>; j-=<span class="built_in">lowbit</span>(j)) ans += B[i][j];</span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">query</span><span class="params">(<span class="type">int</span> x1,<span class="type">int</span> y1,<span class="type">int</span> x2,<span class="type">int</span> y2)</span></span>&#123; </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">query</span>(x2,y2) + <span class="built_in">query</span>(x1<span class="number">-1</span>,y1<span class="number">-1</span>) - <span class="built_in">query</span>(x2,y1<span class="number">-1</span>) - <span class="built_in">query</span>(x1<span class="number">-1</span>,y2);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>值得注意的是，树状数组也能在 $O(log(n))$ 复杂度内支持区间修改，区间求和操作,只需要将数据进行差分和对求和公式进行化简就好了(HDU1166)。</p>
<h4 id="二、相关简单题"><a href="#二、相关简单题" class="headerlink" title="二、相关简单题"></a>二、相关简单题</h4><h5 id="1、POJ2352"><a href="#1、POJ2352" class="headerlink" title="1、POJ2352"></a>1、POJ2352</h5><p>经典模板题，排序后直接套用数据结构，直接AC：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> _CRT_SECURE_NO_WARNINGS</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cstdio&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;iostream&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;algorithm&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cstring&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> MAX = <span class="number">1000010</span>;</span><br><span class="line"><span class="type">int</span> c[MAX] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">lowbit</span><span class="params">(<span class="type">const</span> <span class="type">int</span>&amp; x)</span></span>&#123; <span class="keyword">return</span> (x)&amp;(-x); &#125;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">zero</span><span class="params">()</span> </span>&#123; <span class="built_in">memset</span>(c, <span class="number">0</span>, <span class="built_in">sizeof</span>(c)); &#125;</span><br><span class="line"><span class="comment">// 一定要小心零的问题</span></span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">modify</span><span class="params">(<span class="type">int</span> i, <span class="type">const</span> <span class="type">int</span>&amp; d)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="keyword">while</span> (i &lt;= MAX)</span><br><span class="line">    &#123;</span><br><span class="line">        c[i] += d;</span><br><span class="line">        i += <span class="built_in">lowbit</span>(i);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">sum</span><span class="params">(<span class="type">int</span> i)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> ret = <span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span> (i) &#123;</span><br><span class="line">        ret += c[i];</span><br><span class="line">        i -= <span class="built_in">lowbit</span>(i);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">int</span> R[MAX] = &#123; <span class="number">0</span> &#125;;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> N,x,y;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;N);</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>, &amp;x, &amp;y); ++x;</span><br><span class="line">        ++R[<span class="built_in">sum</span>(x)];</span><br><span class="line">        <span class="built_in">modify</span>(x, <span class="number">1</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; N; ++i) &#123;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>,R[i]);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="2、POJ3067"><a href="#2、POJ3067" class="headerlink" title="2、POJ3067"></a>2、POJ3067</h5><p>画图观察规律，排序直接套用模板(看了其他题解，做的时候没注意就是求逆序对):</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;iostream&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cstring&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cstdlib&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;algorithm&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> maxn = <span class="number">1005</span>;</span><br><span class="line"><span class="type">int</span> B[maxn];</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">lowbit</span><span class="params">(<span class="type">int</span> x)</span></span>&#123;<span class="keyword">return</span> x&amp;(-x);&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">zero</span><span class="params">()</span></span>&#123;<span class="built_in">memset</span>(B,<span class="number">0</span>,<span class="built_in">sizeof</span>(B));&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">update</span><span class="params">(<span class="type">int</span> i,<span class="type">int</span> d)</span></span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;maxn) B[i]+= d, i +=<span class="built_in">lowbit</span>(i);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">query</span><span class="params">(<span class="type">int</span> i)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> ret=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(i&gt;<span class="number">0</span>) ret+=B[i], i-=<span class="built_in">lowbit</span>(i);</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">P</span>&#123;</span><br><span class="line">    <span class="type">int</span> a,b;</span><br><span class="line">    <span class="type">bool</span> <span class="keyword">operator</span> &lt;(<span class="type">const</span> P&amp; p) <span class="type">const</span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(p.a == a) <span class="keyword">return</span> b &lt; p.b;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> a &lt; p.a;</span><br><span class="line">    &#125;</span><br><span class="line">&#125; nodes[maxn*maxn];</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> T,kase = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;T);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>; i &lt;= T; ++i)&#123;</span><br><span class="line">        <span class="built_in">zero</span>();</span><br><span class="line">        <span class="type">int</span> m,n,k;<span class="type">long</span> <span class="type">long</span> <span class="type">int</span> ans=<span class="number">0</span>;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d%d%d&quot;</span>,&amp;m,&amp;n,&amp;k);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>; j&lt;k; ++j)&#123;</span><br><span class="line">            <span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>,&amp;nodes[j].a,&amp;nodes[j].b);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">sort</span>(nodes,nodes+k);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>; j&lt;k; ++j)&#123;</span><br><span class="line">            <span class="built_in">update</span>(nodes[j].b,<span class="number">1</span>);       </span><br><span class="line">            ans += <span class="built_in">query</span>(n) - <span class="built_in">query</span>(nodes[j].b);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Test case %d: %lld\n&quot;</span>, i,ans);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="3、⭐POJ3321"><a href="#3、⭐POJ3321" class="headerlink" title="3、⭐POJ3321"></a>3、⭐POJ3321</h5><p>可以使用DFS遍历这颗树将这棵树线性化，例如：考虑到一颗7节点的满二叉树,DFS的遍历顺序为：12445523667731，显然，求根节点的子树和只需要求中间这一段244552366773的区间和。另一方面，对于本题，我们需要用链表前向构造这颗树，因此在遍历的过程中可能会丢失原始结构的顺序，在这里我们可以用DFS顺序来替代原始的结构。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;iostream&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cstring&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cstdlib&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;algorithm&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> maxn = <span class="number">100015</span>;</span><br><span class="line"><span class="type">int</span> B[maxn];</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">lowbit</span><span class="params">(<span class="type">int</span> x)</span></span>&#123;<span class="keyword">return</span> x&amp;(-x);&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">zero</span><span class="params">()</span></span>&#123;<span class="built_in">memset</span>(B,<span class="number">0</span>,<span class="built_in">sizeof</span>(B));&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">update</span><span class="params">(<span class="type">int</span> i,<span class="type">int</span> d)</span></span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;maxn) B[i]+= d, i +=<span class="built_in">lowbit</span>(i);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">query</span><span class="params">(<span class="type">int</span> i)</span></span>&#123;</span><br><span class="line">    <span class="type">int</span> ret=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(i&gt;<span class="number">0</span>) ret+=B[i], i-=<span class="built_in">lowbit</span>(i);</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// edge</span></span><br><span class="line"><span class="keyword">struct</span> <span class="title class_">E</span>&#123;</span><br><span class="line">    <span class="type">int</span> next,to;</span><br><span class="line">&#125; edges[maxn];</span><br><span class="line"><span class="type">int</span> heads[maxn],I[maxn],O[maxn],T[maxn];</span><br><span class="line"><span class="type">int</span> order = <span class="number">0</span>;</span><br><span class="line"><span class="function"><span class="type">void</span> <span class="title">dfs</span><span class="params">(<span class="type">int</span> r)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    I[r] = ++order;<span class="built_in">update</span>(order,<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i= heads[r];i!=<span class="number">-1</span>;i=edges[i].next) <span class="built_in">dfs</span>(edges[i].to);</span><br><span class="line">    O[r] = order;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="built_in">zero</span>();</span><br><span class="line">    <span class="type">int</span> N,a,b,M;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;N);</span><br><span class="line">    <span class="built_in">memset</span>(heads,<span class="number">0xff</span>,<span class="built_in">sizeof</span>(heads));</span><br><span class="line">    <span class="built_in">fill</span>(T,T+N+<span class="number">5</span>,<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt; N; ++i) &#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>,&amp;a,&amp;b);</span><br><span class="line">        edges[i<span class="number">-1</span>].next = heads[a];</span><br><span class="line">        edges[i<span class="number">-1</span>].to = b;</span><br><span class="line">        heads[a] = i - <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    order = <span class="number">1</span>;<span class="built_in">dfs</span>(<span class="number">1</span>);</span><br><span class="line">    <span class="type">char</span> ops[<span class="number">10</span>];</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;M);</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; M; ++i)&#123;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%s%d&quot;</span>,ops, &amp;a);</span><br><span class="line">        <span class="keyword">if</span>(*ops == <span class="string">&#x27;Q&#x27;</span>) <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, <span class="built_in">query</span>(O[a]) - <span class="built_in">query</span>(I[a]<span class="number">-1</span>));</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(T[a]) <span class="built_in">update</span>(I[a],<span class="number">-1</span>),T[a]^=<span class="number">1</span>;</span><br><span class="line">        <span class="keyword">else</span> <span class="built_in">update</span>(I[a],<span class="number">1</span>),T[a]^=<span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="4、POJ1195"><a href="#4、POJ1195" class="headerlink" title="4、POJ1195"></a>4、POJ1195</h5><p>二维结构上的树状数组，非常简单，直接套用模板：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;iostream&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cstring&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cstdlib&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;algorithm&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> maxn = <span class="number">1050</span>;</span><br><span class="line"><span class="type">int</span> B[maxn][maxn];</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">lowbit</span><span class="params">(<span class="type">int</span> x)</span></span>&#123;<span class="keyword">return</span> x&amp;(-x);&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">zero</span><span class="params">()</span></span>&#123;<span class="built_in">memset</span>(B,<span class="number">0</span>,<span class="built_in">sizeof</span>(B));&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">update</span><span class="params">(<span class="type">int</span> x,<span class="type">int</span> y,<span class="type">int</span> d)</span></span>&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = x; i &lt; maxn; i+=<span class="built_in">lowbit</span>(i))</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j = y; j &lt; maxn; j+=<span class="built_in">lowbit</span>(j)) B[i][j] += d;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">query</span><span class="params">(<span class="type">int</span> x,<span class="type">int</span> y)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(x &lt;= <span class="number">0</span> || y &lt;= <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> ans=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> i = x; i &gt; <span class="number">0</span>; i-=<span class="built_in">lowbit</span>(i))</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j = y; j &gt; <span class="number">0</span>; j-=<span class="built_in">lowbit</span>(j)) ans += B[i][j];</span><br><span class="line">    <span class="keyword">return</span> ans;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">query</span><span class="params">(<span class="type">int</span> x1,<span class="type">int</span> y1,<span class="type">int</span> x2,<span class="type">int</span> y2)</span></span>&#123; </span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">query</span>(x2,y2) + <span class="built_in">query</span>(x1<span class="number">-1</span>,y1<span class="number">-1</span>) - <span class="built_in">query</span>(x2,y1<span class="number">-1</span>) - <span class="built_in">query</span>(x1<span class="number">-1</span>,y2);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> op,x1,y1,a,x2,y2;</span><br><span class="line">    <span class="keyword">while</span>(~<span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;op))&#123;</span><br><span class="line">        <span class="keyword">if</span>(op == <span class="number">0</span>) <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>,&amp;a),<span class="built_in">zero</span>();</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(op == <span class="number">1</span>) <span class="built_in">scanf</span>(<span class="string">&quot;%d%d%d&quot;</span>,&amp;x1,&amp;y1,&amp;a),<span class="built_in">update</span>(x1+<span class="number">2</span>,y1+<span class="number">2</span>,a);</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span>(op == <span class="number">2</span>) <span class="built_in">scanf</span>(<span class="string">&quot;%d%d%d%d&quot;</span>,&amp;x1,&amp;y1,&amp;x2,&amp;y2),<span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>,<span class="built_in">query</span>(x1+<span class="number">2</span>,y1+<span class="number">2</span>,x2+<span class="number">2</span>,y2+<span class="number">2</span>));</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h5 id="5、HDU1166"><a href="#5、HDU1166" class="headerlink" title="5、HDU1166"></a>5、HDU1166</h5><p>刷错了，这是个线段树的练习题，不过用树状数组也能做。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;iostream&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cstring&quot;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&quot;cstdlib&quot;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="type">const</span> <span class="type">int</span> maxn = <span class="number">50005</span>;</span><br><span class="line"><span class="type">int</span> B[maxn];</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">lowbit</span><span class="params">(<span class="type">int</span> x)</span></span>&#123;<span class="keyword">return</span> x&amp;(-x);&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">zero</span><span class="params">()</span></span>&#123;<span class="built_in">memset</span>(B,<span class="number">0</span>,<span class="built_in">sizeof</span>(B));&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">void</span> <span class="title">update</span><span class="params">(<span class="type">int</span> i,<span class="type">int</span> d)</span></span>&#123;</span><br><span class="line">    <span class="keyword">while</span>(i&lt;maxn) B[i]+= d, i +=<span class="built_in">lowbit</span>(i);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="type">int</span> <span class="title">query</span><span class="params">(<span class="type">int</span> i)</span></span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(i == <span class="number">0</span>) <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    <span class="type">int</span> ret=<span class="number">0</span>;</span><br><span class="line">    <span class="keyword">while</span>(i&gt;<span class="number">0</span>) ret+=B[i], i-=<span class="built_in">lowbit</span>(i);</span><br><span class="line">    <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">char</span> op[<span class="number">10</span>];</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    <span class="type">int</span> T,kase = <span class="number">0</span>;</span><br><span class="line">    <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;T);</span><br><span class="line">    <span class="keyword">while</span>(T--)&#123;</span><br><span class="line">        <span class="built_in">zero</span>();</span><br><span class="line">        <span class="type">int</span> n,t,a,b;</span><br><span class="line">        <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;n);</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">1</span>; i &lt;= n; ++i)&#123;</span><br><span class="line">            <span class="built_in">scanf</span>(<span class="string">&quot;%d&quot;</span>, &amp;t);</span><br><span class="line">            <span class="built_in">update</span>(i, t);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="built_in">printf</span>(<span class="string">&quot;Case %d:\n&quot;</span>, ++kase);</span><br><span class="line">        <span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">            <span class="built_in">scanf</span>(<span class="string">&quot;%s&quot;</span>, op);</span><br><span class="line">            <span class="keyword">if</span>(*op == <span class="string">&#x27;Q&#x27;</span>)&#123;</span><br><span class="line">                <span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>,&amp;a,&amp;b);</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;%d\n&quot;</span>, <span class="built_in">query</span>(b) - <span class="built_in">query</span>(a - <span class="number">1</span>));</span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span>(*op == <span class="string">&#x27;A&#x27;</span>)&#123;</span><br><span class="line">                <span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>,&amp;a,&amp;b);</span><br><span class="line">                <span class="built_in">update</span>(a,b);</span><br><span class="line">            &#125;<span class="keyword">else</span> <span class="keyword">if</span>(*op == <span class="string">&#x27;S&#x27;</span>)&#123;</span><br><span class="line">                <span class="built_in">scanf</span>(<span class="string">&quot;%d%d&quot;</span>,&amp;a,&amp;b);</span><br><span class="line">                <span class="built_in">update</span>(a,-b);</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                <span class="keyword">break</span>;   </span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://cocofhu.com/2019/07/14/Gambler's%20Ruin%20Problem/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="cocofhu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小鸟游六花">
      <meta itemprop="description" content="邪王真眼是最强的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 小鸟游六花">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/07/14/Gambler's%20Ruin%20Problem/" class="post-title-link" itemprop="url">Gambler's Ruin Problem</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-07-14 17:01:34" itemprop="dateCreated datePublished" datetime="2019-07-14T17:01:34+00:00">2019-07-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-29 09:25:22" itemprop="dateModified" datetime="2024-05-29T09:25:22+00:00">2024-05-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><em>看<a target="_blank" rel="noopener" href="https://bitcoin.org/bitcoin.pdf" title="比特币白皮书">比特币白皮书</a>看到的一个比较有意思的概率问题，比特币白皮书上的问题和这个类似，讨论的是比特币的安全性，回滚攻击的概率。</em></p>
<blockquote>
<p>庄家有n个筹码，每次有概率p赢得一个筹码，或者概率q（q&#x3D;1-p）输掉一个筹码。庄家输掉所有钱后，即终止游戏。假设各次赌博都是独立的，求庄家把所有筹码输光的概率。</p>
</blockquote>
<p>设概率为$f(n)$,显然我们有$	f(0) &#x3D; 1 $ 和 $f(+\infty) &#x3D; 0$，又根据题意和全概率公式，我们有如下递推方程</p>
<p>$$<br>\begin{alignedat}{1}<br>f(n) &amp;&#x3D; pf(n+1) + qf(n-1)<br>\end{alignedat}<br>$$</p>
<p>所以，特征方程为</p>
<p>$$<br>x &#x3D; px^2 + q<br>$$</p>
<p>解得</p>
<p>$$<br>\begin{alignedat}{1}<br>x &amp;&#x3D; \frac{1\pm\sqrt{1-4pq}}{2p}<br>\end{alignedat}<br>$$</p>
<p>注意到$q&#x3D;1-p$</p>
<p>$$<br>\begin{alignedat}{1}<br>x &amp;&#x3D; \frac{1\pm\sqrt{(2p-1)^2}}{2p}<br>\end{alignedat}<br>$$</p>
<p>考虑$p&gt;0.5$时$x_1&#x3D;1,x_2&#x3D;(1-p)&#x2F;p$，此时<br>$$<br>\begin{alignedat}{1}<br>f(n) &#x3D; A + B(\frac{1-p}{p})^n<br>\end{alignedat}<br>$$</p>
<p>注意到$p&gt;0.5$<br>$$<br>\displaystyle\lim_{n \to +\infty}(\frac{1-p}{p})^n &#x3D; 0<br>$$</p>
<p>代入$	f(0) &#x3D; 1 $ 和 $f(+\infty) &#x3D; 0$，我们立刻就能得到$	A&#x3D;0,B&#x3D;1 $</p>
<p>$$<br>\begin{alignedat}{1}<br>f(n) &#x3D; (\frac{1-p}{p})^n<br>\end{alignedat}<br>$$</p>
<p>另一方面，$p \le 0.5$时，$x_1&#x3D;1,x_2&#x3D;(1-p)&#x2F;p$(因为不影响结果，两个解交换了顺序)，我们惊奇的发现，两组情况下的解竟然如此一致<br>$$<br>\begin{alignedat}{1}<br>f(n) &#x3D; A + B(\frac{1-p}{p})^n<br>\end{alignedat}<br>$$<br>此时我们只需注意<br>$$<br>\displaystyle\lim_{n \to +\infty}(\frac{1-p}{p})^n &#x3D; +\infty<br>$$<br>代入$	f(0) &#x3D; 1 $和 $f(+\infty) &#x3D; 0$，就能得到$	A&#x3D;1,B&#x3D;0 $<br>$$<br>\begin{alignedat}{1}<br>f(n) &#x3D; 1<br>\end{alignedat}<br>$$<br>因此<br>$$<br>\begin{alignedat}{2}<br>f(n) &amp;&#x3D; (q&#x2F;p)^n ,\ \ &amp;p&gt;0.5\<br>f(n) &amp;&#x3D; 1,\ &amp;p \le 0.5<br>\end{alignedat}<br>$$</p>
<p>对此我又进一步的做了<a target="_blank" rel="noopener" href="http://www.combination.net.cn/wp-content/uploads/2019/12/Gamblers-Ruin-Problem-Probability.html" title="概率分析">概率分析</a>，输入的参数要在0.5~1之间，发现庄家基本不会输。</p>
<blockquote>
<p>You always said the cards would never do you wrong; The trick you said was never play the game too long.——Bob Seger</p>
</blockquote>
<blockquote>
<p>赌徒进去赌场后，在有钱的庄家面前，玩着不超过50%胜率的游戏，赢钱就只是一个美丽的泡沫。</p>
</blockquote>
<p>关于这个问题也很多种解法，这里有一个<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/7df33ae5fb56" title="构造差分方程">构造差分方程</a>解的，当然还有一个更为详细的<a target="_blank" rel="noopener" href="https://www.mathpages.com/home/kmath084/kmath084.htm" title="分析">分析</a>。但是我觉得使用特征方程来解才是计算机专业学生的一般做法。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://cocofhu.com/2019/02/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="cocofhu">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="小鸟游六花">
      <meta itemprop="description" content="邪王真眼是最强的">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | 小鸟游六花">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2019/02/14/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%B8%B8%E7%94%A8%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">深度学习常用笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2019-02-14 17:01:34" itemprop="dateCreated datePublished" datetime="2019-02-14T17:01:34+00:00">2019-02-14</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-05-29 09:25:22" itemprop="dateModified" datetime="2024-05-29T09:25:22+00:00">2024-05-29</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><em>由于误操作导致丢失的文章，还好markdown有备份。</em></p>
<h3 id="一、优化手段和常用算法"><a href="#一、优化手段和常用算法" class="headerlink" title="一、优化手段和常用算法"></a>一、优化手段和常用算法</h3><h4 id="1、使用阿里云镜像加速"><a href="#1、使用阿里云镜像加速" class="headerlink" title="1、使用阿里云镜像加速"></a>1、使用阿里云镜像加速</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-i http://mirrors.aliyun.com/pypi/simple --trusted-host mirrors.aliyun.com</span><br></pre></td></tr></table></figure>

<h4 id="2、手写数字识别中初始化参数的问题"><a href="#2、手写数字识别中初始化参数的问题" class="headerlink" title="2、手写数字识别中初始化参数的问题"></a>2、手写数字识别中初始化参数的问题</h4><p>参看例子<code>2-13</code>，最开始我使用了标准的正态分布，收敛速度很慢。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>, <span class="number">256</span>], stddev=<span class="number">1</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">256</span>]))</span><br><span class="line">w2 = tf.Variable(tf.random.truncated_normal([<span class="number">256</span>, <span class="number">128</span>], stddev=<span class="number">1</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">128</span>]))</span><br><span class="line">w3 = tf.Variable(tf.random.truncated_normal([<span class="number">128</span>, <span class="number">10</span>], stddev=<span class="number">1</span>))</span><br><span class="line">b3 = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br></pre></td></tr></table></figure>

<p>将正态分布的方差降为<code>0.1</code>时，收敛速度非常快</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>, <span class="number">256</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">256</span>]))</span><br><span class="line">w2 = tf.Variable(tf.random.truncated_normal([<span class="number">256</span>, <span class="number">128</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">128</span>]))</span><br><span class="line">w3 = tf.Variable(tf.random.truncated_normal([<span class="number">128</span>, <span class="number">10</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b3 = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br></pre></td></tr></table></figure>

<p>可见，参数的初始化对神经网络的性能有着重要影响。</p>
<h4 id="3、计算Top-k-Accuracy"><a href="#3、计算Top-k-Accuracy" class="headerlink" title="3、计算Top-k Accuracy"></a>3、计算Top-k Accuracy</h4><p>具体例子在<code>2-9</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Top-k accuracy</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">output, target, topk=(<span class="params"><span class="number">1</span>,</span>)</span>):</span><br><span class="line">    maxk = <span class="built_in">max</span>(topk)</span><br><span class="line">    batch_size = target.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    pred = tf.math.top_k(output, maxk).indices</span><br><span class="line">    pred = tf.transpose(pred, perm=[<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">    target_ = tf.broadcast_to(target, pred.shape)</span><br><span class="line">    <span class="comment"># [10, b]</span></span><br><span class="line">    correct = tf.equal(pred, target_)</span><br><span class="line"></span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> topk:</span><br><span class="line">        correct_k = tf.cast(tf.reshape(correct[:k], [-<span class="number">1</span>]), dtype=tf.float32)</span><br><span class="line">        correct_k = tf.reduce_sum(correct_k)</span><br><span class="line">        acc = <span class="built_in">float</span>(correct_k* (<span class="number">100.0</span> / batch_size) )</span><br><span class="line">        res.append(acc)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> res</span><br></pre></td></tr></table></figure>

<h4 id="4、TensorFlow在训练模型时突然假死"><a href="#4、TensorFlow在训练模型时突然假死" class="headerlink" title="4、TensorFlow在训练模型时突然假死"></a>4、TensorFlow在训练模型时突然假死</h4><p>经过测试，这种问题一般是显存不够，更改<code>batchsize</code>一般可以解决该问题。或者更新驱动程序。</p>
<h4 id="5、TensorBoard可视化"><a href="#5、TensorBoard可视化" class="headerlink" title="5、TensorBoard可视化"></a>5、TensorBoard可视化</h4><p>具体例子在<code>2-14</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">current_time = datetime.datetime.now().strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>)</span><br><span class="line">log_dir = <span class="string">&#x27;../logs/&#x27;</span> + current_time</span><br><span class="line">summary_writer = tf.summary.create_file_writer(log_dir)</span><br><span class="line"><span class="comment"># 可视化数据保存</span></span><br><span class="line"><span class="keyword">with</span> summary_writer.as_default():</span><br><span class="line">	tf.summary.scalar(<span class="string">&#x27;train-loss&#x27;</span>, <span class="built_in">float</span>(loss), step=step)</span><br></pre></td></tr></table></figure>

<h4 id="6、使用Relu函数时将输入映射到0-1区间"><a href="#6、使用Relu函数时将输入映射到0-1区间" class="headerlink" title="6、使用Relu函数时将输入映射到0-1区间"></a>6、使用Relu函数时将输入映射到0-1区间</h4><p>在做<code>CIFAR10</code>分类时，若采用如下的数据预处理，将导致收敛速度过慢，或者不收敛</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) </span><br><span class="line">    x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">32</span>*<span class="number">32</span>*<span class="number">3</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br></pre></td></tr></table></figure>

<p>将输入数据集映射到<code>0-1</code>区间是，模型性能较好</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = <span class="number">2</span> * tf.cast(x, dtype=tf.float32) / <span class="number">255</span> - <span class="number">1</span></span><br><span class="line">    x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">32</span>*<span class="number">32</span>*<span class="number">3</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br></pre></td></tr></table></figure>

<p>具体例子参见<code>3-4</code>.</p>
<h4 id="6、使用Dropout防止过拟合"><a href="#6、使用Dropout防止过拟合" class="headerlink" title="6、使用Dropout防止过拟合"></a>6、使用Dropout防止过拟合</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">layers.Dense(<span class="number">256</span>, activation=tf.nn.relu),</span><br><span class="line">layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">layers.Dense(<span class="number">128</span>, activation=tf.nn.relu),</span><br><span class="line">layers.Dropout(<span class="number">0.5</span>),</span><br></pre></td></tr></table></figure>

<h4 id="7、使用L2正则化"><a href="#7、使用L2正则化" class="headerlink" title="7、使用L2正则化"></a>7、使用L2正则化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">layers.Dense(<span class="number">256</span>, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(<span class="number">0.001</span>))</span><br></pre></td></tr></table></figure>

<h4 id="8、Keras自定义损失函数"><a href="#8、Keras自定义损失函数" class="headerlink" title="8、Keras自定义损失函数"></a>8、Keras自定义损失函数</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 继承Loss类 重写call方法</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DistanceLoss</span>(<span class="title class_ inherited__">Loss</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, y_true, y_pred</span>):</span><br><span class="line">        loss = tf.losses.categorical_crossentropy(y_true, y_pred, from_logits=<span class="literal">True</span>)</span><br><span class="line">        loss = tf.reduce_mean(loss)</span><br><span class="line">        loss = loss + (<span class="number">0.3</span>*loss - <span class="number">0.3</span>)**<span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.0001</span>),</span><br><span class="line">                  loss=DistanceLoss(),</span><br><span class="line">                  metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br></pre></td></tr></table></figure>

<p>具体例子参见<code>4-1</code>,一开始发现<code>loss</code>到<code>1</code>的时候就会发生过拟合，所以想限制一下<code>loss</code>,结果并没有什么用。</p>
<h4 id="9、使用ResNet网络"><a href="#9、使用ResNet网络" class="headerlink" title="9、使用ResNet网络"></a>9、使用ResNet网络</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, listOfLayer, shortcuts=<span class="literal">None</span>, activation=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">        self.model = Sequential(listOfLayer)</span><br><span class="line">        self.activation = activation</span><br><span class="line">        <span class="keyword">if</span> shortcuts <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.shortcut = <span class="keyword">lambda</span> x: x</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.shortcut = Sequential(shortcuts)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, **kwargs</span>):</span><br><span class="line">        residual = self.shortcut(inputs)</span><br><span class="line">        out = self.model(inputs)</span><br><span class="line">        <span class="keyword">if</span> self.activation <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> layers.add([residual, out])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.activation(residual + out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resNet</span>(<span class="params">filter_num, strides</span>):</span><br><span class="line">    <span class="keyword">if</span> strides == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> ResNet(listOfLayer=[</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        ], activation=tf.nn.relu)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> ResNet(listOfLayer=[</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=strides, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        ], shortcuts=[</span><br><span class="line"></span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">1</span>, <span class="number">1</span>), strides=strides, padding=<span class="string">&quot;same&quot;</span>, kernel_regularizer=regularizers.l2(<span class="number">5e-5</span>),</span><br><span class="line">                          use_bias=<span class="literal">False</span>, kernel_initializer=<span class="string">&#x27;glorot_normal&#x27;</span>)</span><br><span class="line">        ], activation=tf.nn.relu)</span><br></pre></td></tr></table></figure>

<p>具体例子参见<code>4-2</code>.</p>
<h4 id="10、计算两个正态分布的KL-Divergence"><a href="#10、计算两个正态分布的KL-Divergence" class="headerlink" title="10、计算两个正态分布的KL-Divergence"></a>10、计算两个正态分布的KL-Divergence</h4><p>$$<br>\begin{alignedat}{1}<br>    KL(p,q) &amp;&#x3D; -\int p(x)logq(x)dx + \int p(x)logp(x)dx \<br>    &amp;&#x3D; \frac{1}{2}log(2\pi\sigma_{2}^2) + \frac{\sigma_{1}^2+(\mu_{1}-\mu_{2})^2}{2\sigma_2^2} - \frac{1}{2}(1+log2\pi\sigma_1^2) \<br>    &amp;&#x3D; log\frac{\sigma_2}{\sigma_1} + \frac{\sigma_{1}^2+(\mu_{1}-\mu_{2})^2}{2\sigma_2^2} - \frac{1}{2}<br>\end{alignedat}<br>$$</p>
<p>参考链接：<a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians">https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians</a></p>
<h4 id="11、Transposed卷积输出计算公式"><a href="#11、Transposed卷积输出计算公式" class="headerlink" title="11、Transposed卷积输出计算公式"></a>11、Transposed卷积输出计算公式</h4><p>$$<br>out &#x3D; s(i - 1) + k - 2p<br>$$</p>
<p>参考文章：<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.07285v1.pdf">https://arxiv.org/pdf/1603.07285v1.pdf</a></p>
<h4 id="12、使用GAN训练时的技巧"><a href="#12、使用GAN训练时的技巧" class="headerlink" title="12、使用GAN训练时的技巧"></a>12、使用GAN训练时的技巧</h4><ul>
<li>使用<code>leak_relu</code></li>
<li>使用<code>tanh</code>作为激活函数</li>
<li>使用<code>WGAN</code>增强参数鲁棒性</li>
</ul>
<h4 id="13、加载Keras内置模型"><a href="#13、加载Keras内置模型" class="headerlink" title="13、加载Keras内置模型"></a>13、加载Keras内置模型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 加载Keras已有网络</span></span><br><span class="line">vgg19 = keras.applications.VGG19(weights=<span class="string">&quot;imagenet&quot;</span>, include_top=<span class="literal">False</span>, pooling=<span class="string">&quot;max&quot;</span>)</span><br></pre></td></tr></table></figure>

<p>具体例子参看<code>6-1</code></p>
<h4 id="14、参考链接"><a href="#14、参考链接" class="headerlink" title="14、参考链接"></a>14、参考链接</h4><ul>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1603.07285v1.pdf" title="A guide to convolution arithmetic for deep learning">A guide to convolution arithmetic for deep learning</a></li>
<li><a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians" title="KL divergence between two univariate Gaussians">KL divergence between two univariate Gaussians</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/pdf/1606.05908.pdf" title="Tutorial on Variational Autoencoders">Tutorial on Variational Autoencoders</a></li>
</ul>
<h3 id="二、TensorFlow基础操作"><a href="#二、TensorFlow基础操作" class="headerlink" title="二、TensorFlow基础操作"></a>二、TensorFlow基础操作</h3><h4 id="1、Tensor数据类型"><a href="#1、Tensor数据类型" class="headerlink" title="1、Tensor数据类型"></a>1、Tensor数据类型</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 输入TensorFlow版本号</span></span><br><span class="line"><span class="built_in">print</span>(tf.version.VERSION)</span><br><span class="line"><span class="comment"># 创建Tensor int32</span></span><br><span class="line"><span class="built_in">print</span>(tf.constant(<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 创建Tensor float32</span></span><br><span class="line"><span class="built_in">print</span>(tf.constant(<span class="number">1.1</span>))</span><br><span class="line"><span class="comment"># 指定类型创建Tensor float64</span></span><br><span class="line"><span class="built_in">print</span>(tf.constant(<span class="number">2.2</span>, dtype=tf.float64))</span><br><span class="line"><span class="comment"># 创建Tensor bool</span></span><br><span class="line"><span class="built_in">print</span>(tf.constant([<span class="literal">True</span>, <span class="literal">False</span>]))</span><br><span class="line"><span class="comment"># 创建Tensor string 不推荐使用string类型的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.constant(<span class="string">&#x27;hello&#x27;</span>))</span><br><span class="line"></span><br><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">5</span>)</span><br><span class="line"><span class="comment"># 声明Tensor对象为变量</span></span><br><span class="line">b = tf.Variable(a)</span><br><span class="line">c = tf.Variable(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 是否监听梯度变化</span></span><br><span class="line"><span class="built_in">print</span>(b.trainable)</span><br><span class="line"><span class="built_in">print</span>(c.trainable)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2、Tensor的创建"><a href="#2、Tensor的创建" class="headerlink" title="2、Tensor的创建"></a>2、Tensor的创建</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从numpy创建Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.convert_to_tensor(np.ones([<span class="number">2</span>, <span class="number">3</span>])))</span><br><span class="line"><span class="built_in">print</span>(tf.convert_to_tensor(np.ones([<span class="number">2</span>, <span class="number">3</span>]), dtype=tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 从List创建Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.constant([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line"><span class="built_in">print</span>(tf.convert_to_tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line"><span class="built_in">print</span>(tf.convert_to_tensor([[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">3</span>]]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建标量为0的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.zeros([]))</span><br><span class="line"><span class="comment"># 创建shape为1的标量为0的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.zeros([<span class="number">1</span>]))</span><br><span class="line"><span class="comment"># 创建2行2列的全0的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.zeros([<span class="number">2</span>, <span class="number">2</span>]))</span><br><span class="line">a = tf.zeros([<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">b = np.zeros([<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># 创建shape相同的全0的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.zeros_like(a))</span><br><span class="line"><span class="built_in">print</span>(tf.zeros_like(b))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建全1的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.ones([<span class="number">2</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line"><span class="built_in">print</span>(tf.ones_like(a))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建全是指定值的Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.fill([<span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>], <span class="number">6</span>))</span><br><span class="line"><span class="built_in">print</span>(tf.fill(a.shape, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机初始化Tensor</span></span><br><span class="line"><span class="built_in">print</span>(tf.random.normal([<span class="number">2</span>, <span class="number">2</span>], mean=<span class="number">0</span>, stddev=<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 截断正态分布 避免梯度消失</span></span><br><span class="line"><span class="comment"># 取值范围为 [ mean - 2 * stddev, mean + 2 * stddev ]</span></span><br><span class="line"><span class="built_in">print</span>(tf.random.truncated_normal([<span class="number">2</span>, <span class="number">2</span>], mean=<span class="number">0</span>, stddev=<span class="number">1</span>))</span><br><span class="line"><span class="built_in">print</span>(tf.random.uniform([<span class="number">2</span>, <span class="number">2</span>], maxval=<span class="number">10</span>, minval=<span class="number">0</span>, dtype=tf.int32))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随机打散</span></span><br><span class="line">idx = tf.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line">idx = tf.random.shuffle(idx)</span><br><span class="line"><span class="built_in">print</span>(idx)</span><br><span class="line">a = tf.random.normal([<span class="number">10</span>, <span class="number">784</span>])</span><br><span class="line">b = tf.random.uniform([<span class="number">10</span>], maxval=<span class="number">10</span>, minval=<span class="number">0</span>, dtype=tf.int32)</span><br><span class="line"><span class="comment"># 这里a和b满足原来的对应关系</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather(a, idx))</span><br><span class="line"><span class="built_in">print</span>(tf.gather(b, idx))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="3、Tensor的索引与切片"><a href="#3、Tensor的索引与切片" class="headerlink" title="3、Tensor的索引与切片"></a>3、Tensor的索引与切片</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 基本索引</span></span><br><span class="line">a = tf.ones([<span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>][<span class="number">0</span>][<span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>][<span class="number">0</span>][<span class="number">2</span>][<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Numpy风格索引</span></span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, <span class="number">0</span>, <span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># start:end 索引和切片</span></span><br><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 切片操作返回向量,索引操作返回数值</span></span><br><span class="line"><span class="built_in">print</span>(a[-<span class="number">1</span>])</span><br><span class="line"><span class="comment"># 取全部数据</span></span><br><span class="line"><span class="built_in">print</span>(a[:])</span><br><span class="line"><span class="comment"># 从倒数第一个元素开始切片[9]</span></span><br><span class="line"><span class="built_in">print</span>(a[-<span class="number">1</span>:])</span><br><span class="line"><span class="comment"># 从倒数第二个元素开始切片[8, 9]</span></span><br><span class="line"><span class="built_in">print</span>(a[-<span class="number">2</span>:])</span><br><span class="line"><span class="comment"># 一直取到最后一个元素,左闭右开区间</span></span><br><span class="line"><span class="built_in">print</span>(a[:-<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># start:end:step 索引和切片</span></span><br><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 每隔两个取[0 2 4 6 8]</span></span><br><span class="line"><span class="built_in">print</span>(a[::<span class="number">2</span>])</span><br><span class="line"><span class="comment"># 倒序每隔两个取[9 7 5 3 1]</span></span><br><span class="line"><span class="built_in">print</span>(a[::-<span class="number">2</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用...自动推导</span></span><br><span class="line">a = tf.ones([<span class="number">1</span>, <span class="number">5</span>, <span class="number">5</span>, <span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, :, :, :])</span><br><span class="line"><span class="built_in">print</span>(a[<span class="number">0</span>, ...])</span><br><span class="line"><span class="built_in">print</span>(a[..., <span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4、Tensor的高级索引和切片"><a href="#4、Tensor的高级索引和切片" class="headerlink" title="4、Tensor的高级索引和切片"></a>4、Tensor的高级索引和切片</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = tf.random.normal([<span class="number">8</span>, <span class="number">35</span>, <span class="number">8</span>])</span><br><span class="line"><span class="comment"># 取第1维度2、3索引</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather(a, axis=<span class="number">0</span>, indices=[<span class="number">2</span>, <span class="number">3</span>]).shape)</span><br><span class="line"><span class="comment"># 取第1维度1、4、5索引</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather(a, axis=<span class="number">0</span>, indices=[<span class="number">1</span>, <span class="number">4</span>, <span class="number">5</span>]).shape)</span><br><span class="line"><span class="comment"># 取第2维度1和32索引</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather(a, axis=<span class="number">1</span>, indices=[<span class="number">1</span>, <span class="number">32</span>]).shape)</span><br><span class="line"><span class="comment"># a[0]</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather_nd(a, [<span class="number">0</span>]).shape)</span><br><span class="line"><span class="comment"># a[0,1,2]</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather_nd(a, [<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]).shape)</span><br><span class="line"><span class="comment"># [a[1], a[2], a[5])]</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather_nd(a, [[<span class="number">1</span>], [<span class="number">2</span>], [<span class="number">5</span>]]).shape)</span><br><span class="line"><span class="comment"># [a[1, 2], a[2, 1], a[5, 3])]</span></span><br><span class="line"><span class="built_in">print</span>(tf.gather_nd(a, [[<span class="number">1</span>, <span class="number">2</span>], [<span class="number">2</span>, <span class="number">1</span>], [<span class="number">5</span>, <span class="number">3</span>]]).shape)</span><br><span class="line"><span class="comment"># a[0]</span></span><br><span class="line"><span class="built_in">print</span>(tf.boolean_mask(a, mask=[<span class="literal">True</span>, <span class="literal">False</span>]))</span><br><span class="line"><span class="comment"># a[:,:,0]</span></span><br><span class="line"><span class="built_in">print</span>(tf.boolean_mask(a, mask=[<span class="literal">True</span>, <span class="literal">False</span>], axis=<span class="number">3</span>))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="5、Tensor的维度变换"><a href="#5、Tensor的维度变换" class="headerlink" title="5、Tensor的维度变换"></a>5、Tensor的维度变换</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">a = tf.random.normal([<span class="number">100</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># 改变维度, -1代表自动计算</span></span><br><span class="line"><span class="built_in">print</span>(tf.reshape(a, [<span class="number">100</span>, -<span class="number">1</span>, <span class="number">3</span>]).shape)</span><br><span class="line"></span><br><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">16</span>)</span><br><span class="line">a = tf.reshape(a, [<span class="number">4</span>, <span class="number">4</span>])</span><br><span class="line"><span class="comment"># 第0维度放原来的1维度,1维度放原来的0维度</span></span><br><span class="line">a = tf.transpose(a, perm=[<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Expand dim</span></span><br><span class="line">a = tf.random.normal([<span class="number">2</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(tf.expand_dims(a, axis=<span class="number">0</span>).shape)</span><br><span class="line"><span class="built_in">print</span>(tf.expand_dims(a, axis=-<span class="number">1</span>).shape)</span><br><span class="line"><span class="built_in">print</span>(tf.expand_dims(a, axis=-<span class="number">2</span>).shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Squeeze dim</span></span><br><span class="line">a = tf.random.normal([<span class="number">2</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>])</span><br><span class="line"><span class="built_in">print</span>(tf.squeeze(a).shape)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="6、TensorBroadcasting"><a href="#6、TensorBroadcasting" class="headerlink" title="6、TensorBroadcasting"></a>6、TensorBroadcasting</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Broadcasting</span></span><br><span class="line">a = tf.ones([<span class="number">4</span>, <span class="number">1</span>])</span><br><span class="line">b = tf.ones([<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line"><span class="built_in">print</span>(a+b)</span><br><span class="line"><span class="comment"># 不会占用存储空间 运行时计算</span></span><br><span class="line"><span class="built_in">print</span>(tf.broadcast_to(a, [<span class="number">4</span>, <span class="number">4</span>]))</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="7、Tensor的合并与分割"><a href="#7、Tensor的合并与分割" class="headerlink" title="7、Tensor的合并与分割"></a>7、Tensor的合并与分割</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 合并数据集合</span></span><br><span class="line">a = tf.ones([<span class="number">3</span>, <span class="number">35</span>, <span class="number">8</span>])</span><br><span class="line">b = tf.ones([<span class="number">6</span>, <span class="number">35</span>, <span class="number">8</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照第1维度合并, 不会产生新的维度 (9, 35, 8)</span></span><br><span class="line"><span class="built_in">print</span>(tf.concat([a, b], axis=<span class="number">0</span>).shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在最前面创建一个新的维度合并 (2, 6, 35, 8)</span></span><br><span class="line">a = tf.ones([<span class="number">6</span>, <span class="number">35</span>, <span class="number">8</span>])</span><br><span class="line">b = tf.ones([<span class="number">6</span>, <span class="number">35</span>, <span class="number">8</span>])</span><br><span class="line"><span class="built_in">print</span>(tf.stack([a, b], axis=<span class="number">0</span>).shape)</span><br><span class="line"><span class="comment"># 按照第一维度分开 分成6个(35, 8)</span></span><br><span class="line"><span class="built_in">print</span>(tf.unstack(a, axis=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 按照第一维度分开 分成(1, 35, 8)、(2, 35, 8)、(3, 35, 8)</span></span><br><span class="line"><span class="built_in">print</span>(tf.split(a, axis=<span class="number">0</span>, num_or_size_splits=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>]))</span><br></pre></td></tr></table></figure>

<h4 id="8、Tensor的数据统计"><a href="#8、Tensor的数据统计" class="headerlink" title="8、Tensor的数据统计"></a>8、Tensor的数据统计</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2范数, 求所有元素的均方</span></span><br><span class="line">a = tf.ones([<span class="number">2</span>, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(tf.norm(a))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 指定维度2范数</span></span><br><span class="line"><span class="built_in">print</span>(tf.norm(a, axis=<span class="number">1</span>))</span><br><span class="line"><span class="comment"># 指定维度1范数</span></span><br><span class="line"><span class="built_in">print</span>(tf.norm(a, axis=<span class="number">1</span>, <span class="built_in">ord</span>=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># reduce_min/max/mean argmax/argmin</span></span><br><span class="line">a = tf.random.normal([<span class="number">4</span>, <span class="number">10</span>])</span><br><span class="line"><span class="built_in">print</span>(tf.reduce_max(a, axis=<span class="number">0</span>))</span><br><span class="line"><span class="built_in">print</span>(tf.argmax(a, axis=<span class="number">0</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># equal</span></span><br><span class="line">a = tf.constant([<span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>, <span class="number">5</span>])</span><br><span class="line">b = tf.<span class="built_in">range</span>(<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(tf.equal(a, b))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算Accuracy</span></span><br><span class="line">a = tf.constant([[<span class="number">0.1</span>, <span class="number">0.2</span>, <span class="number">0.7</span>], [<span class="number">0.1</span>, <span class="number">0.5</span>, <span class="number">0.4</span>]])</span><br><span class="line"><span class="comment"># [2, 1]</span></span><br><span class="line">pred = tf.cast(tf.argmax(a, axis=<span class="number">1</span>), dtype=tf.int32)</span><br><span class="line"><span class="built_in">print</span>(pred)</span><br><span class="line">y = tf.constant([<span class="number">2</span>, <span class="number">0</span>])</span><br><span class="line">correct = tf.equal(pred, y)</span><br><span class="line"><span class="built_in">print</span>(tf.reduce_mean(tf.cast(correct,dtype=tf.float32)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 去除重复元素</span></span><br><span class="line">a = tf.constant([<span class="number">4</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>])</span><br><span class="line">ua, idx = tf.unique(a)</span><br><span class="line"><span class="built_in">print</span>(ua)</span><br><span class="line"><span class="built_in">print</span>(tf.gather(ua, axis=<span class="number">0</span>, indices=idx))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="9、Tensor排序"><a href="#9、Tensor排序" class="headerlink" title="9、Tensor排序"></a>9、Tensor排序</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">a = tf.random.shuffle(tf.<span class="built_in">range</span>(<span class="number">5</span>))</span><br><span class="line"><span class="comment"># 降序排列</span></span><br><span class="line"><span class="built_in">print</span>(tf.sort(a, direction=<span class="string">&quot;DESCENDING&quot;</span>))</span><br><span class="line"><span class="comment"># 降序排列</span></span><br><span class="line"><span class="built_in">print</span>(tf.argsort(a, direction=<span class="string">&quot;DESCENDING&quot;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Top-k accuracy</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">accuracy</span>(<span class="params">output, target, topk=(<span class="params"><span class="number">1</span>,</span>)</span>):</span><br><span class="line">    maxk = <span class="built_in">max</span>(topk)</span><br><span class="line">    batch_size = target.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    pred = tf.math.top_k(output, maxk).indices</span><br><span class="line">    pred = tf.transpose(pred, perm=[<span class="number">1</span>, <span class="number">0</span>])</span><br><span class="line">    target_ = tf.broadcast_to(target, pred.shape)</span><br><span class="line">    <span class="comment"># [10, b]</span></span><br><span class="line">    correct = tf.equal(pred, target_)</span><br><span class="line"></span><br><span class="line">    res = []</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> topk:</span><br><span class="line">        correct_k = tf.cast(tf.reshape(correct[:k], [-<span class="number">1</span>]), dtype=tf.float32)</span><br><span class="line">        correct_k = tf.reduce_sum(correct_k)</span><br><span class="line">        acc = <span class="built_in">float</span>(correct_k* (<span class="number">100.0</span> / batch_size) )</span><br><span class="line">        res.append(acc)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> res</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="10、Tensor填充与复制"><a href="#10、Tensor填充与复制" class="headerlink" title="10、Tensor填充与复制"></a>10、Tensor填充与复制</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">9</span>)</span><br><span class="line">a = tf.reshape(a, [<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一维度前面填充1次0后面填充2次0</span></span><br><span class="line"><span class="comment"># [[0 0 0]</span></span><br><span class="line"><span class="comment">#  [0 1 2]</span></span><br><span class="line"><span class="comment">#  [3 4 5]</span></span><br><span class="line"><span class="comment">#  [6 7 8]</span></span><br><span class="line"><span class="comment">#  [0 0 0]]</span></span><br><span class="line">a = tf.pad(a, [[<span class="number">1</span>, <span class="number">1</span>], [<span class="number">0</span>, <span class="number">0</span>]])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"><span class="comment"># 第一维度不变 第二维度复制一次</span></span><br><span class="line"><span class="comment"># [[0 0 0 0 0 0]</span></span><br><span class="line"><span class="comment">#  [0 1 2 0 1 2]</span></span><br><span class="line"><span class="comment">#  [3 4 5 3 4 5]</span></span><br><span class="line"><span class="comment">#  [6 7 8 6 7 8]</span></span><br><span class="line"><span class="comment">#  [0 0 0 0 0 0]]</span></span><br><span class="line">a = tf.tile(a, [<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line"><span class="built_in">print</span>(a)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="11、Tensor限幅"><a href="#11、Tensor限幅" class="headerlink" title="11、Tensor限幅"></a>11、Tensor限幅</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">a = tf.<span class="built_in">range</span>(<span class="number">9</span>)</span><br><span class="line"><span class="comment"># 最小值限制在2 [2 2 2 3 4 5 6 7 8]</span></span><br><span class="line"><span class="built_in">print</span>(tf.maximum(a, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最大值限制在2 [0 1 2 2 2 2 2 2 2]</span></span><br><span class="line"><span class="built_in">print</span>(tf.minimum(a, <span class="number">2</span>))</span><br><span class="line"><span class="comment"># 最小值限制在2和最大值限制在8 [2 2 2 3 4 5 6 7 8]</span></span><br><span class="line"><span class="built_in">print</span>(tf.clip_by_value(a, <span class="number">2</span>, <span class="number">8</span>))</span><br><span class="line"></span><br><span class="line">a = tf.random.normal([<span class="number">2</span>, <span class="number">2</span>], mean=<span class="number">10</span>)</span><br><span class="line"><span class="comment"># 将2范数限制到15进行放缩 不改变方向</span></span><br><span class="line"><span class="built_in">print</span>(tf.clip_by_norm(a, <span class="number">15</span>))</span><br><span class="line"><span class="comment"># 全部norm求和放缩到25</span></span><br><span class="line"><span class="comment"># new_grads,total_norm = tf.clip_by_global_norm(grads, 25)</span></span><br></pre></td></tr></table></figure>

<h4 id="12、GradientDescending求函数极值"><a href="#12、GradientDescending求函数极值" class="headerlink" title="12、GradientDescending求函数极值"></a>12、GradientDescending求函数极值</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">f</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="keyword">return</span> (x[<span class="number">0</span>] ** <span class="number">2</span> + x[<span class="number">1</span>] - <span class="number">11</span>)**<span class="number">2</span> + (x[<span class="number">0</span>] + x[<span class="number">1</span>]**<span class="number">2</span> - <span class="number">7</span>)**<span class="number">2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = np.arange(-<span class="number">6</span>, <span class="number">6</span>, <span class="number">0.1</span>)</span><br><span class="line">y = np.arange(-<span class="number">6</span>, <span class="number">6</span>, <span class="number">0.1</span>)</span><br><span class="line">X, Y = np.meshgrid(x, y)</span><br><span class="line">Z = f([X, Y])</span><br><span class="line"></span><br><span class="line">fig = plt.figure(<span class="string">&quot;&quot;</span>)</span><br><span class="line">ax = fig.gca(projection=<span class="string">&quot;3d&quot;</span>)</span><br><span class="line">ax.plot_surface(X, Y, Z)</span><br><span class="line">ax.view_init(<span class="number">60</span>, -<span class="number">30</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">x = tf.constant([-<span class="number">4.0</span>, <span class="number">0.0</span>])</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> step <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">200</span>):</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        tape.watch([x])</span><br><span class="line">        y = f(x)</span><br><span class="line">    grads = tape.gradient(y, [x])[<span class="number">0</span>]</span><br><span class="line">    x -= <span class="number">0.01</span> * grads</span><br><span class="line">    <span class="keyword">if</span> step % <span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Step:&quot;</span>, step, <span class="string">&quot; X:&quot;</span>, x.numpy(), <span class="string">&quot;Y:&quot;</span>, y.numpy())</span><br></pre></td></tr></table></figure>

<h4 id="13、Mnist手写数字识别"><a href="#13、Mnist手写数字识别" class="headerlink" title="13、Mnist手写数字识别"></a>13、Mnist手写数字识别</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.environ[<span class="string">&#x27;TF_CPP_MIN_LOG_LEVEL&#x27;</span>] = <span class="string">&#x27;2&#x27;</span></span><br><span class="line"></span><br><span class="line">(x, y), (x_test, y_test) = datasets.mnist.load_data()</span><br><span class="line"></span><br><span class="line">x = tf.convert_to_tensor(x, dtype=tf.float32)/<span class="number">255</span></span><br><span class="line">y = tf.convert_to_tensor(y, dtype=tf.int32)</span><br><span class="line"></span><br><span class="line">x_test = tf.convert_to_tensor(x_test, dtype=tf.float32)/<span class="number">255</span></span><br><span class="line">y_test = tf.convert_to_tensor(y_test, dtype=tf.int32)</span><br><span class="line"><span class="comment"># print(tf.reduce_max(x))</span></span><br><span class="line"></span><br><span class="line">train_db = tf.data.Dataset.from_tensor_slices((x, y)).batch(<span class="number">128</span>)</span><br><span class="line">train_db.shuffle(x.shape[<span class="number">0</span>])</span><br><span class="line">train_iter = <span class="built_in">iter</span>(train_db)</span><br><span class="line"><span class="comment"># sample = next(train_iter)</span></span><br><span class="line"><span class="comment"># print(sample)</span></span><br><span class="line"></span><br><span class="line">test_db = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">w1 = tf.Variable(tf.random.truncated_normal([<span class="number">784</span>, <span class="number">256</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">256</span>]))</span><br><span class="line">w2 = tf.Variable(tf.random.truncated_normal([<span class="number">256</span>, <span class="number">128</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">128</span>]))</span><br><span class="line">w3 = tf.Variable(tf.random.truncated_normal([<span class="number">128</span>, <span class="number">10</span>], stddev=<span class="number">0.1</span>))</span><br><span class="line">b3 = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line">lr = <span class="number">1e-2</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">30</span>):</span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_db):</span><br><span class="line">        x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">        y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            h1 = x@w1 + b1</span><br><span class="line">            h1 = tf.nn.relu(h1)</span><br><span class="line">            h2 = h1@w2 + b2</span><br><span class="line">            h2 = tf.nn.relu(h2)</span><br><span class="line">            out = h2@w3 + b3</span><br><span class="line">            out = tf.nn.softmax(out)</span><br><span class="line">            loss = tf.losses.categorical_crossentropy(out, y, from_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># loss = tf.square(y - out)</span></span><br><span class="line">            <span class="comment"># loss = tf.reduce_mean(loss)</span></span><br><span class="line"></span><br><span class="line">        grads = tape.gradient(loss,[w1, b1, w2, b2, w3, b3])</span><br><span class="line">        <span class="comment"># print(grads)</span></span><br><span class="line">        <span class="comment"># w1.assign_sub(lr * grads[0])</span></span><br><span class="line">        w1 = tf.Variable(w1 - lr * grads[<span class="number">0</span>])</span><br><span class="line">        b1 = tf.Variable(b1 - lr * grads[<span class="number">1</span>])</span><br><span class="line">        w2 = tf.Variable(w2 - lr * grads[<span class="number">2</span>])</span><br><span class="line">        b2 = tf.Variable(b2 - lr * grads[<span class="number">3</span>])</span><br><span class="line">        w3 = tf.Variable(w3 - lr * grads[<span class="number">4</span>])</span><br><span class="line">        b3 = tf.Variable(b3 - lr * grads[<span class="number">5</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            loss = tf.reduce_mean(loss)</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch&quot;</span>, epoch, <span class="string">&quot;Step:&quot;</span>, step, <span class="string">&quot;Loss:&quot;</span>, <span class="built_in">float</span>(loss))</span><br><span class="line"></span><br><span class="line">    total_correct = <span class="number">0</span></span><br><span class="line">    total_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(test_db):</span><br><span class="line">        x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span> * <span class="number">28</span>])</span><br><span class="line"></span><br><span class="line">        h1 = x @ w1 + b1</span><br><span class="line">        h1 = tf.nn.relu(h1)</span><br><span class="line">        h2 = h1 @ w2 + b2</span><br><span class="line">        h2 = tf.nn.relu(h2)</span><br><span class="line">        out = h2 @ w3 + b3</span><br><span class="line">        prob = tf.nn.softmax(out)</span><br><span class="line">        <span class="comment"># [b, 10]</span></span><br><span class="line">        pred = tf.argmax(prob, axis=<span class="number">1</span>)</span><br><span class="line">        pred = tf.cast(pred, dtype=tf.int32)</span><br><span class="line">        correct = tf.cast(tf.equal(pred, y),dtype=tf.int32)</span><br><span class="line">        correct = tf.reduce_sum(correct)</span><br><span class="line">        total_correct += <span class="built_in">int</span>(correct)</span><br><span class="line">        total_num += x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Acc:&quot;</span>, total_correct/total_num)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="14、TensorBoard可视化"><a href="#14、TensorBoard可视化" class="headerlink" title="14、TensorBoard可视化"></a>14、TensorBoard可视化</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_to_image</span>(<span class="params">figure</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Converts the matplotlib plot specified by &#x27;figure&#x27; to a PNG image and</span></span><br><span class="line"><span class="string">    returns it. The supplied figure is closed and inaccessible after this call.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Save the plot to a PNG in memory.</span></span><br><span class="line">    buf = io.BytesIO()</span><br><span class="line">    plt.savefig(buf, <span class="built_in">format</span>=<span class="string">&#x27;png&#x27;</span>)</span><br><span class="line">    <span class="comment"># Closing the figure prevents it from being displayed directly inside</span></span><br><span class="line">    <span class="comment"># the notebook.</span></span><br><span class="line">    plt.close(figure)</span><br><span class="line">    buf.seek(<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># Convert PNG buffer to TF image</span></span><br><span class="line">    image = tf.image.decode_png(buf.getvalue(), channels=<span class="number">4</span>)</span><br><span class="line">    <span class="comment"># Add the batch dimension</span></span><br><span class="line">    image = tf.expand_dims(image, <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> image</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">image_grid</span>(<span class="params">images</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Return a 5x5 grid of the MNIST images as a matplotlib figure.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># Create a figure to contain the plot.</span></span><br><span class="line">    figure = plt.figure(figsize=(<span class="number">10</span>, <span class="number">10</span>))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">25</span>):</span><br><span class="line">        <span class="comment"># Start next subplot.</span></span><br><span class="line">        plt.subplot(<span class="number">5</span>, <span class="number">5</span>, i + <span class="number">1</span>, title=<span class="string">&#x27;name&#x27;</span>)</span><br><span class="line">        plt.xticks([])</span><br><span class="line">        plt.yticks([])</span><br><span class="line">        plt.grid(<span class="literal">False</span>)</span><br><span class="line">        plt.imshow(images[i], cmap=plt.cm.binary)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> figure</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255</span></span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    layers.Dense(<span class="number">256</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">32</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.build(input_shape=[<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">model.summary()</span><br><span class="line">optimizer = optimizers.Adam(learning_rate=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">current_time = datetime.datetime.now().strftime(<span class="string">&quot;%Y%m%d-%H%M%S&quot;</span>)</span><br><span class="line">log_dir = <span class="string">&#x27;../logs/&#x27;</span> + current_time</span><br><span class="line">summary_writer = tf.summary.create_file_writer(log_dir)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(db_train):</span><br><span class="line">        x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">        y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            out = model(x)</span><br><span class="line">            <span class="comment"># loss = tf.reduce_mean(tf.losses.MSE(y, out))</span></span><br><span class="line">            loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y, out, from_logits=<span class="literal">True</span>))</span><br><span class="line">        grads = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">        optimizer.apply_gradients(<span class="built_in">zip</span>(grads, model.trainable_variables))</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch&quot;</span>, epoch, <span class="string">&quot;Step:&quot;</span>, step, <span class="string">&quot;Loss:&quot;</span>, <span class="built_in">float</span>(loss))</span><br><span class="line">            <span class="keyword">with</span> summary_writer.as_default():</span><br><span class="line">                tf.summary.scalar(<span class="string">&#x27;train-loss&#x27;</span>, <span class="built_in">float</span>(loss), step=step)</span><br><span class="line"></span><br><span class="line">    total_correct = <span class="number">0</span></span><br><span class="line">    total_num = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> (x, y) <span class="keyword">in</span> db_test:</span><br><span class="line">        x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">        y = tf.cast(y, tf.int32)</span><br><span class="line">        out = model(x)</span><br><span class="line">        prob = tf.nn.softmax(out)</span><br><span class="line">        pred = tf.argmax(prob, axis=<span class="number">1</span>)</span><br><span class="line">        pred = tf.cast(pred, dtype=tf.int32)</span><br><span class="line">        correct = tf.cast(tf.equal(pred, y), dtype=tf.int32)</span><br><span class="line">        correct = tf.reduce_sum(correct)</span><br><span class="line">        total_correct += <span class="built_in">int</span>(correct)</span><br><span class="line">        total_num += x.shape[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Acc:&quot;</span>, total_correct / total_num)</span><br><span class="line">    <span class="keyword">with</span> summary_writer.as_default():</span><br><span class="line">        tf.summary.scalar(<span class="string">&#x27;test-acc&#x27;</span>, <span class="built_in">float</span>(total_correct / total_num), step=epoch)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="三、Keras高层API"><a href="#三、Keras高层API" class="headerlink" title="三、Keras高层API"></a>三、Keras高层API</h3><h4 id="1、Keras常用API"><a href="#1、Keras常用API" class="headerlink" title="1、Keras常用API"></a>1、Keras常用API</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255</span></span><br><span class="line">    x = tf.reshape(x, [<span class="number">28</span> * <span class="number">28</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.<span class="built_in">map</span>(preprocess).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    layers.Dense(<span class="number">256</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">32</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.build(input_shape=[<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">              loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="comment"># 每隔两次验证测试数据集合 共训练5次</span></span><br><span class="line">model.fit(db_train, epochs=<span class="number">5</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<h4 id="2、KerasMetrics计算均值和准确度"><a href="#2、KerasMetrics计算均值和准确度" class="headerlink" title="2、KerasMetrics计算均值和准确度"></a>2、KerasMetrics计算均值和准确度</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255</span></span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential([</span><br><span class="line">    layers.Dense(<span class="number">256</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">32</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">    layers.Dense(<span class="number">10</span>, activation=<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.build(input_shape=[<span class="literal">None</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">model.summary()</span><br><span class="line">optimizer = optimizers.Adam(learning_rate=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">loss_meter = metrics.Mean()</span><br><span class="line">acc_meter = metrics.Accuracy()</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">for</span> step, (x, y) <span class="keyword">in</span> <span class="built_in">enumerate</span>(db_train):</span><br><span class="line">        x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">        y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            out = model(x)</span><br><span class="line">            <span class="comment"># loss = tf.reduce_mean(tf.losses.MSE(y, out))</span></span><br><span class="line">            loss = tf.reduce_mean(tf.losses.categorical_crossentropy(y, out, from_logits=<span class="literal">True</span>))</span><br><span class="line">        grads = tape.gradient(loss, model.trainable_variables)</span><br><span class="line">        optimizer.apply_gradients(<span class="built_in">zip</span>(grads, model.trainable_variables))</span><br><span class="line">        loss_meter.update_state(loss)</span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;Epoch&quot;</span>, epoch, <span class="string">&quot;Step:&quot;</span>, step, <span class="string">&quot;Loss:&quot;</span>, loss_meter.result().numpy())</span><br><span class="line">            loss_meter.reset_states()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (x, y) <span class="keyword">in</span> db_test:</span><br><span class="line">        x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>])</span><br><span class="line">        y = tf.cast(y, tf.int32)</span><br><span class="line">        out = model(x)</span><br><span class="line">        prob = tf.nn.softmax(out)</span><br><span class="line">        pred = tf.argmax(prob, axis=<span class="number">1</span>)</span><br><span class="line">        pred = tf.cast(pred, dtype=tf.int32)</span><br><span class="line">        acc_meter.update_state(pred, y)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;Acc:&quot;</span>, acc_meter.result().numpy())</span><br><span class="line">    acc_meter.reset_states()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="3、自定义模型和层"><a href="#3、自定义模型和层" class="headerlink" title="3、自定义模型和层"></a>3、自定义模型和层</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDense</span>(layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, out_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyDense, self).__init__()</span><br><span class="line">        self.kernel = self.add_weight(<span class="string">&quot;w&quot;</span>, [in_dim, out_dim])</span><br><span class="line">        self.bias = self.add_weight(<span class="string">&quot;b&quot;</span>, [out_dim])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span><br><span class="line">        out = inputs @ self.kernel + self.bias</span><br><span class="line">        <span class="keyword">return</span> tf.nn.relu(out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyModel</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyModel, self).__init__()</span><br><span class="line"></span><br><span class="line">        self.fc1 = MyDense(<span class="number">28</span> * <span class="number">28</span>, <span class="number">256</span>)</span><br><span class="line">        self.fc2 = MyDense(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.fc3 = MyDense(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        self.fc4 = MyDense(<span class="number">64</span>, <span class="number">32</span>)</span><br><span class="line">        self.fc5 = MyDense(<span class="number">32</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.fc1(inputs)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        x = self.fc4(x)</span><br><span class="line">        x = self.fc5(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255</span></span><br><span class="line">    x = tf.reshape(x, [<span class="number">28</span> * <span class="number">28</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()</span><br><span class="line"></span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.<span class="built_in">map</span>(preprocess).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">model = MyModel()</span><br><span class="line"></span><br><span class="line"><span class="comment"># model.build(input_shape=[None, 28*28])</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">              loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">5</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4、CIFAR10分类"><a href="#4、CIFAR10分类" class="headerlink" title="4、CIFAR10分类"></a>4、CIFAR10分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyDense</span>(layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, in_dim, out_dim</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyDense, self).__init__()</span><br><span class="line">        self.kernel = self.add_weight(<span class="string">&quot;w&quot;</span>, [in_dim, out_dim])</span><br><span class="line">        self.bias = self.add_weight(<span class="string">&quot;b&quot;</span>, [out_dim])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="keyword">return</span> tf.nn.relu(inputs @ self.kernel )</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyNetwork</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyNetwork, self).__init__()</span><br><span class="line">        self.fc1 = MyDense(<span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>, <span class="number">256</span>)</span><br><span class="line">        self.fc2 = MyDense(<span class="number">256</span>, <span class="number">128</span>)</span><br><span class="line">        self.fc3 = MyDense(<span class="number">128</span>, <span class="number">64</span>)</span><br><span class="line">        self.fc4 = MyDense(<span class="number">64</span>, <span class="number">32</span>)</span><br><span class="line">        self.fc5 = MyDense(<span class="number">32</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = tf.reshape(inputs, [-<span class="number">1</span>, <span class="number">32</span> * <span class="number">32</span> * <span class="number">3</span>])</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        x = self.fc4(x)</span><br><span class="line">        x = self.fc5(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = <span class="number">2</span> * tf.cast(x, dtype=tf.float32) / <span class="number">255</span> - <span class="number">1</span></span><br><span class="line">    x = tf.reshape(x, [-<span class="number">1</span>, <span class="number">32</span>*<span class="number">32</span>*<span class="number">3</span>])</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">10</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.cifar10.load_data()</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.<span class="built_in">map</span>(preprocess).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">model = MyNetwork()</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.001</span>),</span><br><span class="line">              loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">15</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="四、卷积神经网络"><a href="#四、卷积神经网络" class="headerlink" title="四、卷积神经网络"></a>四、卷积神经网络</h3><h4 id="1、自定义VGG13网络CIFAR100分类"><a href="#1、自定义VGG13网络CIFAR100分类" class="headerlink" title="1、自定义VGG13网络CIFAR100分类"></a>1、自定义VGG13网络CIFAR100分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">from</span> tensorflow_core.python.keras.losses <span class="keyword">import</span> Loss</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line">vgg13 = [</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.BatchNormalization(</span><br><span class="line">        axis=-<span class="number">1</span>,</span><br><span class="line">        center=<span class="literal">True</span>,</span><br><span class="line">        scale=<span class="literal">True</span>,</span><br><span class="line">        trainable=<span class="literal">True</span></span><br><span class="line">    ),</span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line"></span><br><span class="line">layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">128</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">128</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">256</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">256</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(<span class="number">0.001</span>)),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">512</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu, kernel_regularizer=keras.regularizers.l2(<span class="number">0.001</span>)),</span><br><span class="line">    layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">2</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line"></span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">256</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.Dropout(<span class="number">0.3</span>),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=tf.nn.relu),</span><br><span class="line">    layers.Dropout(<span class="number">0.5</span>),</span><br><span class="line">    layers.Dense(<span class="number">100</span>, activation=<span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = <span class="number">2</span> * tf.cast(x, dtype=tf.float32) / <span class="number">255</span> - <span class="number">1</span></span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.cifar100.load_data()</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.<span class="built_in">map</span>(preprocess).batch(<span class="number">128</span>)</span><br><span class="line"><span class="comment"># 自定义loss函数</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DistanceLoss</span>(<span class="title class_ inherited__">Loss</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, y_true, y_pred</span>):</span><br><span class="line">        loss = tf.losses.categorical_crossentropy(y_true, y_pred, from_logits=<span class="literal">True</span>)</span><br><span class="line">        loss = tf.reduce_mean(loss)</span><br><span class="line">        loss = loss + (<span class="number">0.3</span>*loss - <span class="number">0.3</span>)**<span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line">model = Sequential(vgg13)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.0001</span>),</span><br><span class="line">              loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">105</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2、使用ResNet网络对CIFAR100分类"><a href="#2、使用ResNet网络对CIFAR100分类" class="headerlink" title="2、使用ResNet网络对CIFAR100分类"></a>2、使用ResNet网络对CIFAR100分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">from</span> tensorflow_core.python.keras <span class="keyword">import</span> regularizers</span><br><span class="line"><span class="keyword">from</span> tensorflow_core.python.keras.losses <span class="keyword">import</span> Loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 该类的层会自动与最后一层连接</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">ResNet</span>(layers.Layer):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, listOfLayer, shortcuts=<span class="literal">None</span>, activation=<span class="literal">None</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(ResNet, self).__init__()</span><br><span class="line">        self.model = Sequential(listOfLayer)</span><br><span class="line">        self.activation = activation</span><br><span class="line">        <span class="keyword">if</span> shortcuts <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            self.shortcut = <span class="keyword">lambda</span> x: x</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.shortcut = Sequential(shortcuts)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, **kwargs</span>):</span><br><span class="line">        residual = self.shortcut(inputs)</span><br><span class="line">        out = self.model(inputs)</span><br><span class="line">        <span class="keyword">if</span> self.activation <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">return</span> layers.add([residual, out])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> self.activation(residual + out)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resNet</span>(<span class="params">filter_num, strides</span>):</span><br><span class="line">    <span class="keyword">if</span> strides == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> ResNet(listOfLayer=[</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        ], activation=tf.nn.relu)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> ResNet(listOfLayer=[</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=strides, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>),</span><br><span class="line">            layers.BatchNormalization(),</span><br><span class="line">            layers.Activation(<span class="string">&quot;relu&quot;</span>)</span><br><span class="line">        ], shortcuts=[</span><br><span class="line"></span><br><span class="line">            layers.Conv2D(filter_num, (<span class="number">1</span>, <span class="number">1</span>), strides=strides, padding=<span class="string">&quot;same&quot;</span>, kernel_regularizer=regularizers.l2(<span class="number">5e-5</span>),</span><br><span class="line">                          use_bias=<span class="literal">False</span>, kernel_initializer=<span class="string">&#x27;glorot_normal&#x27;</span>)</span><br><span class="line">        ], activation=tf.nn.relu)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line">network = [layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>), layers.BatchNormalization(), layers.Activation(<span class="string">&quot;relu&quot;</span>),</span><br><span class="line">           layers.MaxPool2D(pool_size=[<span class="number">2</span>, <span class="number">2</span>], strides=<span class="number">1</span>, padding=<span class="string">&quot;same&quot;</span>), resNet(<span class="number">64</span>, <span class="number">1</span>), resNet(<span class="number">64</span>, <span class="number">1</span>), resNet(<span class="number">128</span>, <span class="number">2</span>),</span><br><span class="line">           resNet(<span class="number">128</span>, <span class="number">1</span>), layers.GlobalAveragePooling2D(), layers.Dense(<span class="number">100</span>, activation=<span class="literal">None</span>)]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">network.append(resNet(<span class="number">256</span>, <span class="number">2</span>))</span><br><span class="line">network.append(resNet(<span class="number">256</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">network.append(resNet(<span class="number">512</span>, <span class="number">2</span>))</span><br><span class="line"></span><br><span class="line">network.append(resNet(<span class="number">512</span>, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img_mean = tf.constant([<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>])</span><br><span class="line">img_std = tf.constant([<span class="number">0.2023</span>, <span class="number">0.1994</span>, <span class="number">0.2010</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize</span>(<span class="params">x, mean=img_mean, std=img_std</span>):</span><br><span class="line">    <span class="comment"># x shape: [224, 224, 3]</span></span><br><span class="line">    <span class="comment"># mean：shape为1；这里用到了广播机制。我们安装好右边对齐的原则，可以得到如下；</span></span><br><span class="line">    <span class="comment"># mean : [1, 1, 3], std: [3]        先插入1</span></span><br><span class="line">    <span class="comment"># mean : [224, 224, 3], std: [3]    再变为224</span></span><br><span class="line">    x = (x - mean) / std</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 数据预处理，仅仅是类型的转换。    [-1~1]</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.image.random_flip_left_right(x)</span><br><span class="line">    <span class="comment"># x: [0,255]=&gt; 0~1 或者-0.5~0.5   其次：normalizaion</span></span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.</span></span><br><span class="line">    <span class="comment"># 0~1 =&gt; D(0,1) 调用函数；</span></span><br><span class="line">    x = normalize(x)</span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># def preprocess(x, y):</span></span><br><span class="line"><span class="comment">#     x = 2 * tf.cast(x, dtype=tf.float32) / 255 - 1</span></span><br><span class="line"><span class="comment">#     y = tf.cast(y, dtype=tf.int32)</span></span><br><span class="line"><span class="comment">#     y = tf.squeeze(y)</span></span><br><span class="line"><span class="comment">#     y = tf.one_hot(y, depth=100)</span></span><br><span class="line"><span class="comment">#     return x, y</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.cifar100.load_data()</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.<span class="built_in">map</span>(preprocess).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">DistanceLoss</span>(<span class="title class_ inherited__">Loss</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, y_true, y_pred</span>):</span><br><span class="line">        loss = tf.losses.categorical_crossentropy(y_true, y_pred, from_logits=<span class="literal">True</span>)</span><br><span class="line">        loss = tf.reduce_mean(loss)</span><br><span class="line">        loss = loss + (<span class="number">0.3</span> * loss - <span class="number">0.3</span>) ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Sequential(network)</span><br><span class="line">model.build(input_shape=[<span class="literal">None</span>, <span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>])</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">1e-4</span>),</span><br><span class="line">              loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">1000</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="五、循环神经网络"><a href="#五、循环神经网络" class="headerlink" title="五、循环神经网络"></a>五、循环神经网络</h3><h4 id="1、循环神经网络对IMDB评论进行情感分类"><a href="#1、循环神经网络对IMDB评论进行情感分类" class="headerlink" title="1、循环神经网络对IMDB评论进行情感分类"></a>1、循环神经网络对IMDB评论进行情感分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line">tf.compat.v1.disable_eager_execution()</span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=<span class="number">80</span>)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=<span class="number">80</span>)</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyRNN</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, units, batchSize</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyRNN, self).__init__()</span><br><span class="line">        self.state0 = [tf.zeros([batchSize, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batchSize, units])]</span><br><span class="line">        <span class="comment"># [b 80] =&gt; [b 80 100]</span></span><br><span class="line">        self.embedding = layers.Embedding(<span class="number">10000</span>, <span class="number">100</span>, input_length=<span class="number">80</span>)</span><br><span class="line">        self.rnn_cell0 = layers.SimpleRNNCell(units, dropout=<span class="number">0.2</span>)</span><br><span class="line">        self.rnn_cell1 = layers.SimpleRNNCell(units, dropout=<span class="number">0.2</span>)</span><br><span class="line">        self.fc = layers.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.embedding(inputs)</span><br><span class="line">        state0 = self.state0</span><br><span class="line">        state1 = self.state1</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> tf.unstack(x, axis=<span class="number">1</span>):</span><br><span class="line">            out, state0 = self.rnn_cell0(word, state0, training)</span><br><span class="line">            out, state1 = self.rnn_cell1(out, state1, training)</span><br><span class="line">        x = self.fc(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MyRNN(<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.0001</span>),</span><br><span class="line">              loss=tf.losses.BinaryCrossentropy(),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">15</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2、使用Keras内置的RNN进行IMDB情感分类"><a href="#2、使用Keras内置的RNN进行IMDB情感分类" class="headerlink" title="2、使用Keras内置的RNN进行IMDB情感分类"></a>2、使用Keras内置的RNN进行IMDB情感分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line">tf.compat.v1.disable_eager_execution()</span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=<span class="number">80</span>)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=<span class="number">80</span>)</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyRNN</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, units, batchSize</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyRNN, self).__init__()</span><br><span class="line">        self.state0 = [tf.zeros([batchSize, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batchSize, units])]</span><br><span class="line">        <span class="comment"># [b 80] =&gt; [b 80 100]</span></span><br><span class="line">        self.embedding = layers.Embedding(<span class="number">10000</span>, <span class="number">100</span>, input_length=<span class="number">80</span>)</span><br><span class="line">        self.rnn = keras.Sequential([</span><br><span class="line">            layers.SimpleRNN(units, dropout=<span class="number">0.5</span>, return_sequences=<span class="literal">True</span>, unroll=<span class="literal">True</span>),</span><br><span class="line">            layers.SimpleRNN(units, dropout=<span class="number">0.5</span>, unroll=<span class="literal">True</span>)</span><br><span class="line">        ])</span><br><span class="line">        self.fc = layers.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.embedding(inputs)</span><br><span class="line">        x = self.rnn(x)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MyRNN(<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.0001</span>),</span><br><span class="line">              loss=tf.losses.BinaryCrossentropy(),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">15</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="3、使用LSTM对IMDB评论进行情感分类"><a href="#3、使用LSTM对IMDB评论进行情感分类" class="headerlink" title="3、使用LSTM对IMDB评论进行情感分类"></a>3、使用LSTM对IMDB评论进行情感分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line">tf.compat.v1.disable_eager_execution()</span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=<span class="number">80</span>)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=<span class="number">80</span>)</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyRNN</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, units, batchSize</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyRNN, self).__init__()</span><br><span class="line">        self.state0 = [tf.zeros([batchSize, units]), tf.zeros([batchSize, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batchSize, units]), tf.zeros([batchSize, units])]</span><br><span class="line">        <span class="comment"># [b 80] =&gt; [b 80 100]</span></span><br><span class="line">        self.embedding = layers.Embedding(<span class="number">10000</span>, <span class="number">100</span>, input_length=<span class="number">80</span>)</span><br><span class="line">        self.rnn_cell0 = layers.LSTMCell(units, dropout=<span class="number">0.2</span>)</span><br><span class="line">        self.rnn_cell1 = layers.LSTMCell(units, dropout=<span class="number">0.2</span>)</span><br><span class="line">        self.fc = layers.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.embedding(inputs)</span><br><span class="line">        state0 = self.state0</span><br><span class="line">        state1 = self.state1</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> tf.unstack(x, axis=<span class="number">1</span>):</span><br><span class="line">            out, state0 = self.rnn_cell0(word, state0, training)</span><br><span class="line">            out, state1 = self.rnn_cell1(out, state1, training)</span><br><span class="line">        x = self.fc(out)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MyRNN(<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.0001</span>),</span><br><span class="line">              loss=tf.losses.BinaryCrossentropy(),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">15</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4、使用Keras内置LSTM进行IMDB情感分类"><a href="#4、使用Keras内置LSTM进行IMDB情感分类" class="headerlink" title="4、使用Keras内置LSTM进行IMDB情感分类"></a>4、使用Keras内置LSTM进行IMDB情感分类</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line">tf.compat.v1.disable_eager_execution()</span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.imdb.load_data(num_words=<span class="number">10000</span>)</span><br><span class="line">x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=<span class="number">80</span>)</span><br><span class="line">x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=<span class="number">80</span>)</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">MyRNN</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, units, batchSize</span>):</span><br><span class="line">        <span class="built_in">super</span>(MyRNN, self).__init__()</span><br><span class="line">        self.state0 = [tf.zeros([batchSize, units])]</span><br><span class="line">        self.state1 = [tf.zeros([batchSize, units])]</span><br><span class="line">        <span class="comment"># [b 80] =&gt; [b 80 100]</span></span><br><span class="line">        self.embedding = layers.Embedding(<span class="number">10000</span>, <span class="number">100</span>, input_length=<span class="number">80</span>)</span><br><span class="line">        self.rnn = keras.Sequential([</span><br><span class="line">            layers.LSTM(units, dropout=<span class="number">0.5</span>, return_sequences=<span class="literal">True</span>, unroll=<span class="literal">True</span>),</span><br><span class="line">            layers.LSTM(units, dropout=<span class="number">0.5</span>, unroll=<span class="literal">True</span>)</span><br><span class="line">        ])</span><br><span class="line">        self.fc = layers.Dense(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.embedding(inputs)</span><br><span class="line">        x = self.rnn(x)</span><br><span class="line">        x = self.fc(x)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> tf.nn.sigmoid(x)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MyRNN(<span class="number">128</span>, <span class="number">128</span>)</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.0001</span>),</span><br><span class="line">              loss=tf.losses.BinaryCrossentropy(),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line">model.fit(db_train, epochs=<span class="number">15</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="六、迁移学习"><a href="#六、迁移学习" class="headerlink" title="六、迁移学习"></a>六、迁移学习</h3><h4 id="1、使用VGG19迁移学习CIFAR100"><a href="#1、使用VGG19迁移学习CIFAR100" class="headerlink" title="1、使用VGG19迁移学习CIFAR100"></a>1、使用VGG19迁移学习CIFAR100</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">from</span> tensorflow_core.python.keras <span class="keyword">import</span> regularizers</span><br><span class="line"></span><br><span class="line">img_mean = tf.constant([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>])</span><br><span class="line">img_std = tf.constant([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>])</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">normalize</span>(<span class="params">x, mean=img_mean, std=img_std</span>):</span><br><span class="line">    <span class="comment"># x shape: [224, 224, 3]</span></span><br><span class="line">    <span class="comment"># mean：shape为1；这里用到了广播机制。我们安装好右边对齐的原则，可以得到如下；</span></span><br><span class="line">    <span class="comment"># mean : [1, 1, 3], std: [3]        先插入1</span></span><br><span class="line">    <span class="comment"># mean : [224, 224, 3], std: [3]    再变为224</span></span><br><span class="line">    x = (x - mean)/std</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">x, y</span>):</span><br><span class="line">    x = tf.cast(x, dtype=tf.float32) / <span class="number">255.0</span></span><br><span class="line">    x = tf.image.random_flip_left_right(x)</span><br><span class="line">    <span class="comment"># x = tf.image.resize(x, [224, 224])</span></span><br><span class="line">    x = normalize(x)</span><br><span class="line">    <span class="comment"># x = tf.transpose(x, perm=[2,1,0])</span></span><br><span class="line">    y = tf.cast(y, dtype=tf.int32)</span><br><span class="line">    y = tf.squeeze(y)</span><br><span class="line">    y = tf.one_hot(y, depth=<span class="number">100</span>)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载Keras已有网络</span></span><br><span class="line">vgg19 = keras.applications.VGG19(weights=<span class="string">&quot;imagenet&quot;</span>, include_top=<span class="literal">False</span>, pooling=<span class="string">&quot;max&quot;</span>)</span><br><span class="line">(x_train, y_train), (x_test, y_test) = datasets.cifar100.load_data()</span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, y_test))</span><br><span class="line">db_test = db_test.<span class="built_in">map</span>(preprocess).batch(<span class="number">128</span>)</span><br><span class="line">vgg19.trainable = <span class="literal">False</span></span><br><span class="line">model = Sequential([</span><br><span class="line">    vgg19,</span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">1000</span>, activation=tf.nn.relu, kernel_initializer=<span class="string">&#x27;glorot_normal&#x27;</span>),</span><br><span class="line">    layers.Dropout(<span class="number">0.3</span>),</span><br><span class="line">    layers.Dense(<span class="number">500</span>, activation=tf.nn.relu, kernel_initializer=<span class="string">&#x27;glorot_normal&#x27;</span>),</span><br><span class="line">    layers.Dropout(<span class="number">0.3</span>),</span><br><span class="line">    layers.Dense(<span class="number">200</span>, activation=tf.nn.relu, kernel_initializer=<span class="string">&#x27;glorot_normal&#x27;</span>),</span><br><span class="line">    layers.Dense(<span class="number">100</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(vgg19.input_shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.001</span>),</span><br><span class="line">              loss=tf.losses.CategoricalCrossentropy(from_logits=<span class="literal">True</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">40</span>):</span><br><span class="line">    model.fit(db_train, epochs=<span class="number">2</span>, validation_data=db_test, validation_freq=<span class="number">2</span>)</span><br><span class="line">    db_train = tf.data.Dataset.from_tensor_slices((x_train, y_train))</span><br><span class="line">    db_train = db_train.<span class="built_in">map</span>(preprocess).shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="七、自编码器"><a href="#七、自编码器" class="headerlink" title="七、自编码器"></a>七、自编码器</h3><h4 id="1、对MNIST数据集进行自编码"><a href="#1、对MNIST数据集进行自编码" class="headerlink" title="1、对MNIST数据集进行自编码"></a>1、对MNIST数据集进行自编码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_images</span>(<span class="params">imgs, name</span>):</span><br><span class="line">    new_im = Image.new(<span class="string">&#x27;L&#x27;</span>, (<span class="number">280</span>, <span class="number">280</span>))</span><br><span class="line"></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">280</span>, <span class="number">28</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">280</span>, <span class="number">28</span>):</span><br><span class="line">            im = imgs[index]</span><br><span class="line">            im = Image.fromarray(im, mode=<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">            new_im.paste(im, (i, j))</span><br><span class="line">            index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    new_im.save(name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">CODE_DIM = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">(x_train, _1), (x_test, _2) = datasets.fashion_mnist.load_data()</span><br><span class="line">x_train, x_test = x_train.astype(np.float32).reshape([-<span class="number">1</span>, <span class="number">784</span>]) / <span class="number">255.</span>, x_test.astype(np.float32).reshape([-<span class="number">1</span>, <span class="number">784</span>]) / <span class="number">255.</span></span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices((x_train, x_train))</span><br><span class="line">db_train = db_train.shuffle(<span class="number">10000</span>).batch(<span class="number">128</span>)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices((x_test, x_test))</span><br><span class="line">db_test = db_test.batch(<span class="number">128</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AE</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(AE, self).__init__()</span><br><span class="line">        self.encoder = Sequential([</span><br><span class="line">            layers.Dense(<span class="number">256</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Dense(<span class="number">128</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Dense(CODE_DIM)</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">        self.decoder = Sequential([</span><br><span class="line">            layers.Dense(<span class="number">128</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Dense(<span class="number">256</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Dense(<span class="number">784</span>)</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.encoder(inputs)</span><br><span class="line">        x = self.decoder(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = AE()</span><br><span class="line">model.build(input_shape=(<span class="literal">None</span>, <span class="number">784</span>))</span><br><span class="line">model.summary()</span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=optimizers.Adam(lr=<span class="number">0.01</span>),</span><br><span class="line">              loss=<span class="string">&quot;mse&quot;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;===============================================&quot;</span>)</span><br><span class="line">    model.fit(db_train, epochs=<span class="number">10</span>)</span><br><span class="line">    x, y = <span class="built_in">next</span>(<span class="built_in">iter</span>(db_test))</span><br><span class="line">    y = tf.reshape(y, [-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line">    out = model(tf.reshape(x, [-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>]))</span><br><span class="line">    out = tf.reshape(out, [-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>])</span><br><span class="line"></span><br><span class="line">    true_fake = tf.concat([y[<span class="number">0</span>:<span class="number">50</span>] ,out[<span class="number">0</span>:<span class="number">50</span>]], axis=<span class="number">0</span>)</span><br><span class="line">    true_fake = true_fake.numpy() * <span class="number">255</span></span><br><span class="line">    true_fake = true_fake.astype(np.uint8)</span><br><span class="line"></span><br><span class="line">    save_images(true_fake, <span class="built_in">str</span>(i)+<span class="string">&quot;test.jpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="2、VariationalAutoEncoder"><a href="#2、VariationalAutoEncoder" class="headerlink" title="2、VariationalAutoEncoder"></a>2、VariationalAutoEncoder</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> datetime</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">tf.random.set_seed(<span class="number">2345</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_images</span>(<span class="params">imgs, name</span>):</span><br><span class="line">    new_im = Image.new(<span class="string">&#x27;L&#x27;</span>, (<span class="number">280</span>, <span class="number">280</span>))</span><br><span class="line"></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">280</span>, <span class="number">28</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">280</span>, <span class="number">28</span>):</span><br><span class="line">            im = imgs[index]</span><br><span class="line">            im = Image.fromarray(im, mode=<span class="string">&#x27;L&#x27;</span>)</span><br><span class="line">            new_im.paste(im, (i, j))</span><br><span class="line">            index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    new_im.save(name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">128</span></span><br><span class="line">CODE_DIM = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">(x_train, _1), (x_test, _2) = datasets.mnist.load_data()</span><br><span class="line">x_train, x_test = x_train.astype(np.float32).reshape([-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>]) / <span class="number">255.</span>, x_test.astype(np.float32).reshape([-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>]) / <span class="number">255.</span></span><br><span class="line">db_train = tf.data.Dataset.from_tensor_slices(x_train)</span><br><span class="line">db_train = db_train.shuffle(<span class="number">10000</span>).batch(BATCH_SIZE)</span><br><span class="line">db_test = tf.data.Dataset.from_tensor_slices(x_test)</span><br><span class="line">db_test = db_test.batch(<span class="number">50</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">reparameter</span>(<span class="params">mu, log_var</span>):</span><br><span class="line">    eps = tf.random.normal(log_var.shape)</span><br><span class="line"></span><br><span class="line">    std = tf.exp(log_var * <span class="number">0.5</span>)</span><br><span class="line"></span><br><span class="line">    z = mu + std * eps</span><br><span class="line">    <span class="keyword">return</span> z</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VariationalAutoEncoder</span>(keras.Model):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(VariationalAutoEncoder, self).__init__()</span><br><span class="line">        self.encoder = Sequential([</span><br><span class="line">            layers.Conv2D(<span class="number">64</span>, strides=<span class="number">2</span>, kernel_size=[<span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Conv2D(<span class="number">128</span>, strides=<span class="number">2</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Conv2D(<span class="number">256</span>, strides=<span class="number">2</span>, kernel_size=[<span class="number">3</span>, <span class="number">3</span>], padding=<span class="string">&quot;same&quot;</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Flatten(),</span><br><span class="line">            layers.Dense(<span class="number">500</span>, activation=tf.nn.relu)</span><br><span class="line">        ])</span><br><span class="line">        self.mean = Sequential([</span><br><span class="line">            layers.Dense(CODE_DIM, activation=tf.nn.relu)</span><br><span class="line">        ])</span><br><span class="line">        self.variance = Sequential([</span><br><span class="line">            layers.Dense(CODE_DIM, activation=tf.nn.relu)</span><br><span class="line">        ])</span><br><span class="line">        self.decoder = Sequential([</span><br><span class="line">            layers.Flatten(),</span><br><span class="line">            layers.Dense(<span class="number">1024</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Dense(<span class="number">900</span>, activation=tf.nn.relu),</span><br><span class="line">            layers.Dense(<span class="number">784</span>)</span><br><span class="line">        ])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, inputs, training=<span class="literal">None</span>, mask=<span class="literal">None</span></span>):</span><br><span class="line">        x = self.encoder(inputs)</span><br><span class="line">        mean = self.mean(x)</span><br><span class="line">        log_var = self.variance(x)</span><br><span class="line">        z = reparameter(mean, log_var)</span><br><span class="line">        out = self.decoder(z)</span><br><span class="line">        <span class="keyword">return</span> out, mean, log_var</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">VAE = VariationalAutoEncoder()</span><br><span class="line">optimizer = tf.optimizers.Adam(<span class="number">1e-3</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1000</span>):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> step, x <span class="keyword">in</span> <span class="built_in">enumerate</span>(db_train):</span><br><span class="line"></span><br><span class="line">        rx = tf.reshape(x, [-<span class="number">1</span>, <span class="number">784</span>])</span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">            out, mean, log_var = VAE(x)</span><br><span class="line"></span><br><span class="line">            rec_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=rx, logits=out)</span><br><span class="line">            rec_loss = tf.reduce_sum(rec_loss) / x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># compute kl divergence (mu, var) ~ N (0, 1)</span></span><br><span class="line">            <span class="comment"># https://stats.stackexchange.com/questions/7440/kl-divergence-between-two-univariate-gaussians</span></span><br><span class="line">            kl_div = -<span class="number">0.5</span> * (log_var + <span class="number">1</span> - mean**<span class="number">2</span> - tf.exp(log_var))</span><br><span class="line">            kl_div = tf.reduce_sum(kl_div) / x.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">            loss = rec_loss + <span class="number">3.</span> * kl_div</span><br><span class="line"></span><br><span class="line">        grads = tape.gradient(loss, VAE.trainable_variables)</span><br><span class="line">        optimizer.apply_gradients(<span class="built_in">zip</span>(grads, VAE.trainable_variables))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> step % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(epoch, step, <span class="string">&#x27;kl div:&#x27;</span>, <span class="built_in">float</span>(kl_div), <span class="string">&#x27;rec loss:&#x27;</span>, <span class="built_in">float</span>(rec_loss))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    z = tf.random.normal((<span class="number">100</span>, CODE_DIM))</span><br><span class="line">    logits = VAE.decoder(z)</span><br><span class="line">    x_hat = tf.sigmoid(logits)</span><br><span class="line">    x_hat = tf.reshape(x_hat, [-<span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>]).numpy() * <span class="number">255.</span></span><br><span class="line">    x_hat = x_hat.astype(np.uint8)</span><br><span class="line">    save_images(x_hat, <span class="string">&#x27;vae_images/sampled_epoch%d.png&#x27;</span> % epoch)</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="八、对抗神经网络"><a href="#八、对抗神经网络" class="headerlink" title="八、对抗神经网络"></a>八、对抗神经网络</h3><h4 id="1、GAN"><a href="#1、GAN" class="headerlink" title="1、GAN"></a>1、GAN</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">from</span> tensorflow_core.python.keras <span class="keyword">import</span> regularizers</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_anime_dataset</span>(<span class="params">img_paths, batch_size, resize=<span class="number">64</span>, drop_remainder=<span class="literal">True</span>, shuffle=<span class="literal">True</span>, repeat=<span class="number">1</span></span>):</span><br><span class="line"><span class="meta">    @tf.function</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_map_fn</span>(<span class="params">img</span>):</span><br><span class="line">        img = tf.image.resize(img, [resize, resize])</span><br><span class="line">        img = tf.clip_by_value(img, <span class="number">0</span>, <span class="number">255</span>)</span><br><span class="line">        img = img / <span class="number">127.5</span> - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">    dataset = disk_image_batch_dataset(img_paths,</span><br><span class="line">                                       batch_size,</span><br><span class="line">                                       drop_remainder=drop_remainder,</span><br><span class="line">                                       map_fn=_map_fn,</span><br><span class="line">                                       shuffle=shuffle,</span><br><span class="line">                                       repeat=repeat)</span><br><span class="line">    img_shape = (resize, resize, <span class="number">3</span>)</span><br><span class="line">    len_dataset = <span class="built_in">len</span>(img_paths) // batch_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset, img_shape, len_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">batch_dataset</span>(<span class="params">dataset,</span></span><br><span class="line"><span class="params">                  batch_size,</span></span><br><span class="line"><span class="params">                  drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                  n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                  filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                  shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                  shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># set defaults</span></span><br><span class="line">    <span class="keyword">if</span> n_map_threads <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        n_map_threads = multiprocessing.cpu_count()</span><br><span class="line">    <span class="keyword">if</span> shuffle <span class="keyword">and</span> shuffle_buffer_size <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        shuffle_buffer_size = <span class="built_in">max</span>(batch_size * <span class="number">128</span>, <span class="number">2048</span>)  <span class="comment"># set the minimum buffer size as 2048</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` is sometimes costly</span></span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        dataset = dataset.shuffle(shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> filter_after_map:</span><br><span class="line">        <span class="keyword">if</span> filter_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">filter</span>(filter_fn)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> map_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(map_fn, num_parallel_calls=n_map_threads)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># [*] this is slower</span></span><br><span class="line">        <span class="keyword">if</span> map_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(map_fn, num_parallel_calls=n_map_threads)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> filter_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">filter</span>(filter_fn)</span><br><span class="line"></span><br><span class="line">    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)</span><br><span class="line"></span><br><span class="line">    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">memory_data_batch_dataset</span>(<span class="params">memory_data,</span></span><br><span class="line"><span class="params">                              batch_size,</span></span><br><span class="line"><span class="params">                              drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                              n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                              filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                              shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                              shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Batch dataset of memory data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    memory_data : nested structure of tensors/ndarrays/lists</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dataset = tf.data.Dataset.from_tensor_slices(memory_data)</span><br><span class="line">    dataset = batch_dataset(dataset,</span><br><span class="line">                            batch_size,</span><br><span class="line">                            drop_remainder=drop_remainder,</span><br><span class="line">                            n_prefetch_batch=n_prefetch_batch,</span><br><span class="line">                            filter_fn=filter_fn,</span><br><span class="line">                            map_fn=map_fn,</span><br><span class="line">                            n_map_threads=n_map_threads,</span><br><span class="line">                            filter_after_map=filter_after_map,</span><br><span class="line">                            shuffle=shuffle,</span><br><span class="line">                            shuffle_buffer_size=shuffle_buffer_size,</span><br><span class="line">                            repeat=repeat)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">disk_image_batch_dataset</span>(<span class="params">img_paths,</span></span><br><span class="line"><span class="params">                             batch_size,</span></span><br><span class="line"><span class="params">                             labels=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                             n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                             filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                             shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                             shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Batch dataset of disk image for PNG and JPEG.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">        img_paths : 1d-tensor/ndarray/list of str</span></span><br><span class="line"><span class="string">        labels : nested structure of tensors/ndarrays/lists</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        memory_data = img_paths</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        memory_data = (img_paths, labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_fn</span>(<span class="params">path, *label</span>):</span><br><span class="line">        img = tf.io.read_file(path)</span><br><span class="line">        img = tf.image.decode_png(img, <span class="number">3</span>)  <span class="comment"># fix channels to 3</span></span><br><span class="line">        <span class="keyword">return</span> (img,) + label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> map_fn:  <span class="comment"># fuse `map_fn` and `parse_fn`</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">map_fn_</span>(<span class="params">*args</span>):</span><br><span class="line">            <span class="keyword">return</span> map_fn(*parse_fn(*args))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        map_fn_ = parse_fn</span><br><span class="line"></span><br><span class="line">    dataset = memory_data_batch_dataset(memory_data,</span><br><span class="line">                                        batch_size,</span><br><span class="line">                                        drop_remainder=drop_remainder,</span><br><span class="line">                                        n_prefetch_batch=n_prefetch_batch,</span><br><span class="line">                                        filter_fn=filter_fn,</span><br><span class="line">                                        map_fn=map_fn_,</span><br><span class="line">                                        n_map_threads=n_map_threads,</span><br><span class="line">                                        filter_after_map=filter_after_map,</span><br><span class="line">                                        shuffle=shuffle,</span><br><span class="line">                                        shuffle_buffer_size=shuffle_buffer_size,</span><br><span class="line">                                        repeat=repeat)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">discriminator = Sequential([</span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">3</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">128</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">3</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">256</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">3</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">32</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">1</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">generator = Sequential([</span><br><span class="line">    layers.Dense(<span class="number">3</span> * <span class="number">3</span> * <span class="number">512</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Reshape((<span class="number">3</span>, <span class="number">3</span>, <span class="number">512</span>)),</span><br><span class="line">    <span class="comment"># 9</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">256</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    <span class="comment"># (9-1)*2 + 5 = 21</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">128</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="string">&#x27;valid&#x27;</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    <span class="comment"># (21-1)*3 + 4 = 64</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>, activation=tf.tanh),</span><br><span class="line"></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_images</span>(<span class="params">imgs, name</span>):</span><br><span class="line">    new_im = Image.new(<span class="string">&#x27;RGB&#x27;</span>, (<span class="number">640</span>, <span class="number">640</span>))</span><br><span class="line"></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">640</span>, <span class="number">64</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">640</span>, <span class="number">64</span>):</span><br><span class="line">            im = imgs[index]</span><br><span class="line">            im = np.array(im)</span><br><span class="line">            im = ((im + <span class="number">1.0</span>) * <span class="number">127.5</span>).astype(np.uint8)</span><br><span class="line">            im = Image.fromarray(im, mode=<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">            new_im.paste(im, (i, j))</span><br><span class="line">            index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    new_im.save(name)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">d_loss_fn</span>(<span class="params">generator, discriminator, batch_z, batch_x</span>):</span><br><span class="line">    fake_images = generator(batch_z)</span><br><span class="line">    fake_out = discriminator(fake_images)</span><br><span class="line">    real_out = discriminator(batch_x)</span><br><span class="line"></span><br><span class="line">    fake_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_out, labels=tf.zeros_like(fake_out))</span><br><span class="line">    real_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=real_out, labels=tf.ones_like(real_out))</span><br><span class="line"></span><br><span class="line">    fake_loss = tf.reduce_mean(fake_loss)</span><br><span class="line">    real_loss = tf.reduce_mean(real_loss)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fake_loss + real_loss</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">512</span></span><br><span class="line">CODE_SIZE = <span class="number">100</span></span><br><span class="line">LEARNING_RATE = <span class="number">0.0002</span></span><br><span class="line">EPOCHS = <span class="number">20000</span></span><br><span class="line">img_path = glob.glob(<span class="string">r&quot;E:\BaiduNetdiskDownload\faces\*.jpg&quot;</span>)</span><br><span class="line">dataset, image_shape, _ = make_anime_dataset(img_path, BATCH_SIZE)</span><br><span class="line">dataset = dataset.repeat()</span><br><span class="line">db_iter = <span class="built_in">iter</span>(dataset)</span><br><span class="line"></span><br><span class="line">generator.build(input_shape=(<span class="literal">None</span>, CODE_SIZE))</span><br><span class="line">discriminator.build(input_shape=(<span class="literal">None</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>))</span><br><span class="line">g_optimizer = optimizers.Adam(LEARNING_RATE)</span><br><span class="line">d_optimizer = optimizers.Adam(LEARNING_RATE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">g_loss_fn</span>(<span class="params">generator, discriminator, batch_z</span>):</span><br><span class="line">    fake_images = generator(batch_z)</span><br><span class="line">    fake_out = discriminator(fake_images)</span><br><span class="line">    fake_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_out, labels=tf.ones_like(fake_out))</span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(fake_loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    batch_z = tf.random.uniform([BATCH_SIZE, CODE_SIZE], minval=-<span class="number">1</span>, maxval=<span class="number">1</span>)</span><br><span class="line">    batch_x = <span class="built_in">next</span>(db_iter)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        d_loss = d_loss_fn(generator, discriminator, batch_z, batch_x)</span><br><span class="line">    grads = tape.gradient(d_loss, discriminator.trainable_variables)</span><br><span class="line">    d_optimizer.apply_gradients(<span class="built_in">zip</span>(grads, discriminator.trainable_variables))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        g_loss = g_loss_fn(generator, discriminator, batch_z)</span><br><span class="line">    grads = tape.gradient(g_loss, generator.trainable_variables)</span><br><span class="line">    g_optimizer.apply_gradients(<span class="built_in">zip</span>(grads, generator.trainable_variables))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">30</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;d-loss:&quot;</span>, <span class="built_in">float</span>(d_loss), <span class="string">&quot;g-loss:&quot;</span>, <span class="built_in">float</span>(g_loss))</span><br><span class="line">        z = tf.random.uniform([<span class="number">100</span>, CODE_SIZE], minval=-<span class="number">1</span>, maxval=<span class="number">1</span>)</span><br><span class="line">        images = generator(z)</span><br><span class="line">        save_images(images, <span class="string">&#x27;dc-gan/sampled_epoch%d.png&#x27;</span> % epoch)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h4 id="4、WGAN"><a href="#4、WGAN" class="headerlink" title="4、WGAN"></a>4、WGAN</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> tensorflow <span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> datasets, layers, optimizers, Sequential, metrics</span><br><span class="line"><span class="keyword">from</span> tensorflow_core.python.keras <span class="keyword">import</span> regularizers</span><br><span class="line"><span class="keyword">import</span> multiprocessing</span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">512</span></span><br><span class="line">CODE_SIZE = <span class="number">300</span></span><br><span class="line">LEARNING_RATE = <span class="number">0.0002</span></span><br><span class="line">EPOCHS = <span class="number">2000000</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_anime_dataset</span>(<span class="params">img_paths, batch_size, resize=<span class="number">64</span>, drop_remainder=<span class="literal">True</span>, shuffle=<span class="literal">True</span>, repeat=<span class="number">1</span></span>):</span><br><span class="line"><span class="meta">    @tf.function</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_map_fn</span>(<span class="params">img</span>):</span><br><span class="line">        img = tf.image.resize(img, [resize, resize])</span><br><span class="line">        img = tf.clip_by_value(img, <span class="number">0</span>, <span class="number">255</span>)</span><br><span class="line">        img = img / <span class="number">127.5</span> - <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> img</span><br><span class="line"></span><br><span class="line">    dataset = disk_image_batch_dataset(img_paths,</span><br><span class="line">                                       batch_size,</span><br><span class="line">                                       drop_remainder=drop_remainder,</span><br><span class="line">                                       map_fn=_map_fn,</span><br><span class="line">                                       shuffle=shuffle,</span><br><span class="line">                                       repeat=repeat)</span><br><span class="line">    img_shape = (resize, resize, <span class="number">3</span>)</span><br><span class="line">    len_dataset = <span class="built_in">len</span>(img_paths) // batch_size</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset, img_shape, len_dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">batch_dataset</span>(<span class="params">dataset,</span></span><br><span class="line"><span class="params">                  batch_size,</span></span><br><span class="line"><span class="params">                  drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                  n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                  filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                  shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                  shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                  repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="comment"># set defaults</span></span><br><span class="line">    <span class="keyword">if</span> n_map_threads <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        n_map_threads = multiprocessing.cpu_count()</span><br><span class="line">    <span class="keyword">if</span> shuffle <span class="keyword">and</span> shuffle_buffer_size <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        shuffle_buffer_size = <span class="built_in">max</span>(batch_size * <span class="number">128</span>, <span class="number">2048</span>)  <span class="comment"># set the minimum buffer size as 2048</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># [*] it is efficient to conduct `shuffle` before `map`/`filter` because `map`/`filter` is sometimes costly</span></span><br><span class="line">    <span class="keyword">if</span> shuffle:</span><br><span class="line">        dataset = dataset.shuffle(shuffle_buffer_size)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> filter_after_map:</span><br><span class="line">        <span class="keyword">if</span> filter_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">filter</span>(filter_fn)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> map_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(map_fn, num_parallel_calls=n_map_threads)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">else</span>:  <span class="comment"># [*] this is slower</span></span><br><span class="line">        <span class="keyword">if</span> map_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">map</span>(map_fn, num_parallel_calls=n_map_threads)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> filter_fn:</span><br><span class="line">            dataset = dataset.<span class="built_in">filter</span>(filter_fn)</span><br><span class="line"></span><br><span class="line">    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)</span><br><span class="line"></span><br><span class="line">    dataset = dataset.repeat(repeat).prefetch(n_prefetch_batch)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">memory_data_batch_dataset</span>(<span class="params">memory_data,</span></span><br><span class="line"><span class="params">                              batch_size,</span></span><br><span class="line"><span class="params">                              drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                              n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                              filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                              shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                              shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                              repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Batch dataset of memory data.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    memory_data : nested structure of tensors/ndarrays/lists</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dataset = tf.data.Dataset.from_tensor_slices(memory_data)</span><br><span class="line">    dataset = batch_dataset(dataset,</span><br><span class="line">                            batch_size,</span><br><span class="line">                            drop_remainder=drop_remainder,</span><br><span class="line">                            n_prefetch_batch=n_prefetch_batch,</span><br><span class="line">                            filter_fn=filter_fn,</span><br><span class="line">                            map_fn=map_fn,</span><br><span class="line">                            n_map_threads=n_map_threads,</span><br><span class="line">                            filter_after_map=filter_after_map,</span><br><span class="line">                            shuffle=shuffle,</span><br><span class="line">                            shuffle_buffer_size=shuffle_buffer_size,</span><br><span class="line">                            repeat=repeat)</span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">disk_image_batch_dataset</span>(<span class="params">img_paths,</span></span><br><span class="line"><span class="params">                             batch_size,</span></span><br><span class="line"><span class="params">                             labels=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             drop_remainder=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                             n_prefetch_batch=<span class="number">1</span>,</span></span><br><span class="line"><span class="params">                             filter_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             map_fn=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             n_map_threads=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             filter_after_map=<span class="literal">False</span>,</span></span><br><span class="line"><span class="params">                             shuffle=<span class="literal">True</span>,</span></span><br><span class="line"><span class="params">                             shuffle_buffer_size=<span class="literal">None</span>,</span></span><br><span class="line"><span class="params">                             repeat=<span class="literal">None</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Batch dataset of disk image for PNG and JPEG.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">        img_paths : 1d-tensor/ndarray/list of str</span></span><br><span class="line"><span class="string">        labels : nested structure of tensors/ndarrays/lists</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> labels <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">        memory_data = img_paths</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        memory_data = (img_paths, labels)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">parse_fn</span>(<span class="params">path, *label</span>):</span><br><span class="line">        img = tf.io.read_file(path)</span><br><span class="line">        img = tf.image.decode_png(img, <span class="number">3</span>)  <span class="comment"># fix channels to 3</span></span><br><span class="line">        <span class="keyword">return</span> (img,) + label</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> map_fn:  <span class="comment"># fuse `map_fn` and `parse_fn`</span></span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">map_fn_</span>(<span class="params">*args</span>):</span><br><span class="line">            <span class="keyword">return</span> map_fn(*parse_fn(*args))</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        map_fn_ = parse_fn</span><br><span class="line"></span><br><span class="line">    dataset = memory_data_batch_dataset(memory_data,</span><br><span class="line">                                        batch_size,</span><br><span class="line">                                        drop_remainder=drop_remainder,</span><br><span class="line">                                        n_prefetch_batch=n_prefetch_batch,</span><br><span class="line">                                        filter_fn=filter_fn,</span><br><span class="line">                                        map_fn=map_fn_,</span><br><span class="line">                                        n_map_threads=n_map_threads,</span><br><span class="line">                                        filter_after_map=filter_after_map,</span><br><span class="line">                                        shuffle=shuffle,</span><br><span class="line">                                        shuffle_buffer_size=shuffle_buffer_size,</span><br><span class="line">                                        repeat=repeat)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> dataset</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">discriminator = Sequential([</span><br><span class="line">    layers.Conv2D(<span class="number">64</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">3</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">128</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">3</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Conv2D(<span class="number">256</span>, kernel_size=[<span class="number">5</span>, <span class="number">5</span>], padding=<span class="string">&quot;same&quot;</span>, strides=<span class="number">3</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    layers.Flatten(),</span><br><span class="line">    layers.Dense(<span class="number">128</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">64</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">32</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">16</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Dense(<span class="number">1</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">generator = Sequential([</span><br><span class="line">    layers.Dense(<span class="number">3</span> * <span class="number">3</span> * <span class="number">512</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.Reshape((<span class="number">3</span>, <span class="number">3</span>, <span class="number">512</span>)),</span><br><span class="line">    <span class="comment"># 9</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">256</span>, <span class="number">3</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    <span class="comment"># (9-1)*2 + 5 = 21</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">128</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="string">&#x27;valid&#x27;</span>, activation=tf.nn.leaky_relu),</span><br><span class="line">    layers.BatchNormalization(),</span><br><span class="line">    <span class="comment"># (21-1)*3 + 4 = 64</span></span><br><span class="line">    layers.Conv2DTranspose(<span class="number">3</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="string">&#x27;valid&#x27;</span>, activation=tf.tanh),</span><br><span class="line"></span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_images</span>(<span class="params">imgs, name</span>):</span><br><span class="line">    new_im = Image.new(<span class="string">&#x27;RGB&#x27;</span>, (<span class="number">640</span>, <span class="number">640</span>))</span><br><span class="line"></span><br><span class="line">    index = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">640</span>, <span class="number">64</span>):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>, <span class="number">640</span>, <span class="number">64</span>):</span><br><span class="line">            im = imgs[index]</span><br><span class="line">            im = np.array(im)</span><br><span class="line">            im = ((im + <span class="number">1.0</span>) * <span class="number">127.5</span>).astype(np.uint8)</span><br><span class="line">            im = Image.fromarray(im, mode=<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">            new_im.paste(im, (i, j))</span><br><span class="line">            index += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    new_im.save(name)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算梯度惩罚项</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">gradient_penalty</span>(<span class="params">discriminator, batch_x, fake_images</span>):</span><br><span class="line">    t = tf.random.uniform([BATCH_SIZE, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    t = tf.broadcast_to(t, batch_x.shape)</span><br><span class="line">    <span class="comment"># 元素乘法</span></span><br><span class="line">    interplate = t * batch_x + (<span class="number">1</span> - t) * fake_images</span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        tape.watch([interplate])</span><br><span class="line">        out = discriminator(interplate)</span><br><span class="line">    grads = tape.gradient(out, interplate)</span><br><span class="line">    grads = tf.reshape(grads, [BATCH_SIZE, -<span class="number">1</span>])</span><br><span class="line">    gp = tf.norm(grads, axis=<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean((gp-<span class="number">1</span>)**<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">d_loss_fn</span>(<span class="params">generator, discriminator, batch_z, batch_x</span>):</span><br><span class="line">    fake_images = generator(batch_z)</span><br><span class="line">    fake_out = discriminator(fake_images)</span><br><span class="line">    real_out = discriminator(batch_x)</span><br><span class="line"></span><br><span class="line">    fake_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_out, labels=tf.zeros_like(fake_out))</span><br><span class="line">    real_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=real_out, labels=tf.ones_like(real_out))</span><br><span class="line"></span><br><span class="line">    fake_loss = tf.reduce_mean(fake_loss)</span><br><span class="line">    real_loss = tf.reduce_mean(real_loss)</span><br><span class="line"></span><br><span class="line">    gp = gradient_penalty(discriminator, batch_x, fake_images)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> fake_loss + real_loss + gp, gp</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">img_path = glob.glob(<span class="string">r&quot;E:\BaiduNetdiskDownload\faces\*.jpg&quot;</span>)</span><br><span class="line">dataset, image_shape, _ = make_anime_dataset(img_path, BATCH_SIZE)</span><br><span class="line">dataset = dataset.repeat()</span><br><span class="line">db_iter = <span class="built_in">iter</span>(dataset)</span><br><span class="line"></span><br><span class="line">generator.build(input_shape=(<span class="literal">None</span>, CODE_SIZE))</span><br><span class="line">discriminator.build(input_shape=(<span class="literal">None</span>, <span class="number">64</span>, <span class="number">64</span>, <span class="number">3</span>))</span><br><span class="line">g_optimizer = optimizers.Adam(LEARNING_RATE)</span><br><span class="line">d_optimizer = optimizers.Adam(LEARNING_RATE)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">g_loss_fn</span>(<span class="params">generator, discriminator, batch_z</span>):</span><br><span class="line">    fake_images = generator(batch_z)</span><br><span class="line">    fake_out = discriminator(fake_images)</span><br><span class="line">    fake_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_out, labels=tf.ones_like(fake_out))</span><br><span class="line">    <span class="keyword">return</span> tf.reduce_mean(fake_loss)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    batch_z = tf.random.uniform([BATCH_SIZE, CODE_SIZE], minval=-<span class="number">1</span>, maxval=<span class="number">1</span>)</span><br><span class="line">    batch_x = <span class="built_in">next</span>(db_iter)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        d_loss, gp = d_loss_fn(generator, discriminator, batch_z, batch_x)</span><br><span class="line">    grads = tape.gradient(d_loss, discriminator.trainable_variables)</span><br><span class="line">    d_optimizer.apply_gradients(<span class="built_in">zip</span>(grads, discriminator.trainable_variables))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">        g_loss = g_loss_fn(generator, discriminator, batch_z)</span><br><span class="line">    grads = tape.gradient(g_loss, generator.trainable_variables)</span><br><span class="line">    g_optimizer.apply_gradients(<span class="built_in">zip</span>(grads, generator.trainable_variables))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">30</span> == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;d-loss:&quot;</span>, <span class="built_in">float</span>(d_loss), <span class="string">&quot;g-loss:&quot;</span>, <span class="built_in">float</span>(g_loss), <span class="string">&quot;gp&quot;</span>, <span class="built_in">float</span>(gp))</span><br><span class="line">        z = tf.random.uniform([<span class="number">100</span>, CODE_SIZE], minval=-<span class="number">1</span>, maxval=<span class="number">1</span>)</span><br><span class="line">        images = generator(z)</span><br><span class="line">        save_images(images, <span class="string">&#x27;w-gan/sampled_epoch%d.png&#x27;</span> % epoch)</span><br><span class="line">    <span class="keyword">if</span> epoch % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">        discriminator.save_weights(<span class="string">&quot;model-wgan/w-gan-d&quot;</span>)</span><br><span class="line">        generator.save_weights(<span class="string">&quot;model-wgan/w-gan-g&quot;</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>










      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/3/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">cocofhu</span>
  </div>
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/mist/" rel="noopener" target="_blank">NexT.Mist</a> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
